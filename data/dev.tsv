	input_text	target_text	indexes
10245	Factor analysis is a statistical method used to describe variability among observed, correlated variables in terms of a potentially lower number of unobserved variables called factors.  Factor analysis aims to find independent latent variables.	What does a factor analysis tell you	10245
3681	In qualitative research no hypotheses or relationships of variables are tested. Because variables must be defined numerically in hypothesis-testing research, they cannot reflect subjective experience. This leads to hypothesis-generating research using the grounded theory method to study subjective experience directly.	Does a qualitative study have variables	3681
6860	Explain the difference between descriptive and inferential statistics. Descriptive statistics describes sets of data. Inferential statistics draws conclusions about the sets of data based on sampling.  A population is a set of units of interest to a study.	What is the difference between descriptive and inferential statistics quizlet	6860
5617	Exponential Smoothing is one of the more popular smoothing techniques due to its flexibility, ease in calculation, and good performance. Exponential Smoothing uses a simple average calculation to assign exponentially decreasing weights starting with the most recent observations.	Which method is best for smoothing of data	5617
8618	Basically, there are three methods to solve a multi-label classification problem, namely: Problem Transformation. Adapted Algorithm.1 Binary Relevance. This is the simplest technique, which basically treats each label as a separate single class classification problem.  2 Classifier Chains.  3 Label Powerset.	How do you handle multi label classification	8618
8534	Five Common Types of Sampling ErrorsPopulation Specification Error—This error occurs when the researcher does not understand who they should survey.  Sample Frame Error—A frame error occurs when the wrong sub-population is used to select a sample.More items	What are the types of sampling errors	8534
3716	The Word2Vec Model This model was created by Google in 2013 and is a predictive deep learning based model to compute and generate high quality, distributed and continuous dense vector representations of words, which capture contextual and semantic similarity.	Is Word2Vec deep learning	3716
2131	The law of averages is not a mathematical principle, whereas the law of large numbers is.  According to the law, the average of the results obtained from a large number of trials should be close to the expected value, and will tend to become closer as more trials are performed.	What is the difference between the law of large numbers and the law of averages	2131
1536	Bias can enter into algorithmic systems as a result of pre-existing cultural, social, or institutional expectations; because of technical limitations of their design; or by being used in unanticipated contexts or by audiences who are not considered in the software's initial design.	Why AI algorithms are biased	1536
8342	: to aim an attack at someone or something. : to direct an action, message, etc., at someone or something.	What does it mean to target someone	8342
5659	"1: The number of observations n is fixed. 2: Each observation is independent. 3: Each observation represents one of two outcomes (""success"" or ""failure""). 4: The probability of ""success"" p is the same for each outcome."	What are the 4 characteristics of a binomial distribution	5659
5473	The number of neurons in the input layer equals the number of input variables in the data being processed. The number of neurons in the output layer equals the number of outputs associated with each input.	How do you determine the number of neurons in the input layer	5473
3523	If two random variables X and Y are independent, then their covariance Cov(X, Y) = E(XY) − E(X)E(Y) = 0, that is, they are uncorrelated.	When X and Y are statistically independent then I xy is	3523
9314	Artificial intelligence is imparting a cognitive ability to a machine.  The idea behind machine learning is that the machine can learn without human intervention. The machine needs to find a way to learn how to solve a task given the data. Deep learning is the breakthrough in the field of artificial intelligence.	What is artificial intelligence machine learning and deep learning	9314
10816	Counterintuitive as it may be, supervised algorithms (particularly logistic regression and random forest) tend to outperform unsupervised ones on discrete classification and categorization tasks, where data is relatively structured and well-labeled.	Is it possible for unsupervised learning algorithms to outperform supervised ones	10816
4280	You should put it after the non-linearity (eg. relu layer). If you are using dropout remember to use it before.	Where should I insert batch normalization	4280
2821	For example, if n = 100 and p = 0.25 then we are justified in using the normal approximation. This is because np = 25 and n(1 - p) = 75. Since both of these numbers are greater than 10, the appropriate normal distribution will do a fairly good job of estimating binomial probabilities.	What is an example of the normal approximation of the binomial distribution	2821
3524	Hierarchical clustering outputs a hierarchy, ie a structure that is more informa ve than the unstructured set of flat clusters returned by k-‐means. Therefore, it is easier to decide on the number of clusters by looking at the dendrogram (see sugges on on how to cut a dendrogram in lab8).	What are the benefits of hierarchical clustering over K means clustering	3524
2794	The monty hall problem has 3 doors instead of 100. It is still more likely that you pick a goat.  If a person picks door 1 which is wrong the Monty Hall will close door 3 and give you chance to switch to the right answer, so it means they want always people win the prize.	How does the Monty Hall problem work	2794
8338	To calculate how much weight you need, divide the known population percentage by the percent in the sample. For this example: Known population females (51) / Sample Females (41) = 51/41 = 1.24. Known population males (49) / Sample males (59) = 49/59 = .	How do you do weightage to a variable	8338
3770	A variable is said to be continuous if it can assume an infinite number of real values. Examples of a continuous variable are distance, age and temperature. The measurement of a continuous variable is restricted by the methods used, or by the accuracy of the measuring instruments.	Is age a continuous variable	3770
7437	The lower quartile, or first quartile, is denoted as Q1 and is the middle number that falls between the smallest value of the dataset and the median. The second quartile, Q2, is also the median.	Is median the same with second quartile	7437
472	Residual analysis is used to assess the appropriateness of a linear regression model by defining residuals and examining the residual plot graphs.	What is residual analysis used for	472
4783	If you want a representative sample of a particular population, you need to ensure that:The sample source includes all the target population.The selected data collection method (online, phone, paper, in person) can reach individuals that represent that target population.More items•	How do you know if a sample size is representative	4783
5416	"The main difference between stratified sampling and cluster sampling is that with cluster sampling, you have natural groups separating your population.  With stratified random sampling, these breaks may not exist*, so you divide your target population into groups (more formally called ""strata"")."	What is the difference between stratified random sampling and cluster sampling	5416
5430	The standard score (more commonly referred to as a z-score) is a very useful statistic because it (a) allows us to calculate the probability of a score occurring within our normal distribution and (b) enables us to compare two scores that are from different normal distributions.	In what setting are z scores useful	5430
10279	CONCLUSION. There are three primary goals of survival analysis, to estimate and interpret survival and / or hazard functions from the survival data; to compare survival and / or hazard functions, and to assess the relationship of explanatory variables to survival time.	Why is survival analysis used	10279
10157	Every parametric test has the assumption that the sample means are following a normal distribution. This is the case if the sample itself is normal distributed or if approximately if the sample size is big enough.	Why does data need to be normally distributed in parametric tests	10157
7817	A Seq2Seq model is a model that takes a sequence of items (words, letters, time series, etc) and outputs another sequence of items.  The encoder captures the context of the input sequence in the form of a hidden state vector and sends it to the decoder, which then produces the output sequence.	What is Seq2Seq model	7817
2767	Divide the number of subjects by 2, and round down. In the example 5 ÷ 2 = 2.5 and rounding down gives 2. Find the first-ordered survival time that is greater than this number. This is the median survival time.	How do you find the median in survival time	2767
10472	While regular gradient boosting uses the loss function of our base model (e.g. decision tree) as a proxy for minimizing the error of the overall model, XGBoost uses the 2nd order derivative as an approximation.	How is XGBoost different from gradient boosting	10472
6173	The reason n-1 is used is because that is the number of degrees of freedom in the sample. The sum of each value in a sample minus the mean must equal 0, so if you know what all the values except one are, you can calculate the value of the final one.	Why is there a degree of freedom of n 1 for sample standard deviation	6173
9485	Statistical knowledge helps you use the proper methods to collect the data, employ the correct analyses, and effectively present the results. Statistics is a crucial process behind how we make discoveries in science, make decisions based on data, and make predictions.	What are the advantages of statistics	9485
1930	Linear regression can only be used when one has two continuous variables—an independent variable and a dependent variable. The independent variable is the parameter that is used to calculate the dependent variable or outcome. A multiple regression model extends to several explanatory variables.	What data is used for multiple linear regression	1930
10990	The four elements of a descriptive statistics problem include population/sample, tables/graphs, identifying patterns, and A. data.	What are the four elements of a descriptive statistics problem	10990
7369	The mass density (ρ) of a substance is the mass of one unit volume of the substance.  The relative density is the ratio of the mass of the substance in air at 20 °C to that of an equal volume of water at the same temperature.	What is density and relative density	7369
2427	The Paired Samples t Test compares two means that are from the same individual, object, or related units. The two means can represent things like: A measurement taken at two different times (e.g., pre-test and post-test with an intervention administered between the two time points)5 päivää sitten	What is the comparison mean for a paired sample t test	2427
3456	Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.	What is a gradient in deep learning	3456
5494	The prior distribution is a distribution for the parameters whereas the prior predictive distribution is a distribution for the observations.  The last line is based on the assumption that the upcoming observation is independent of X given θ.	Differences between prior distribution and prior predictive distribution	5494
1205	Decision trees: Are popular among non-statisticians as they produce a model that is very easy to interpret. Each leaf node is presented as an if/then rule.	Is a decision tree a model	1205
7736	Competitive learning is a form of unsupervised learning in artificial neural networks, in which nodes compete for the right to respond to a subset of the input data.  Models and algorithms based on the principle of competitive learning include vector quantization and self-organizing maps (Kohonen maps).	What is competitive learning algorithm in neural network	7736
7188	Answer. True is the answer of Restricted Boltzmann Machine expect data to be labeled for Training as because there are two process for training one which is called as pre-training and training. In pre-training one don't need labeled data.	Does Restricted Boltzmann Machine expect the data to be labeled for training	7188
4489	Sampling is a statistical procedure that is concerned with the selection of the individual observation; it helps us to make statistical inferences about the population. In sampling, we assume that samples are drawn from the population and sample means and population means are equal.	What are the importance of sampling in statistics	4489
6430	AI programs can provide automation for low-value tasks freeing up engineers to perform higher-value tasks. By using machine learning to discover patterns in the data, machines will be incredibly important to help with engineering judgment.	How is AI used in engineering	6430
8526	Bootstrap aggregating, also called bagging (from bootstrap aggregating), is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting.	Is bootstrapping the same as bagging	8526
2098	Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks. For example, NLP makes it possible for computers to read text, hear speech, interpret it, measure sentiment and determine which parts are important.	What is NLP used for	2098
5572	Fundamentally, classification is about predicting a label and regression is about predicting a quantity.  That classification is the problem of predicting a discrete class label output for an example. That regression is the problem of predicting a continuous quantity output for an example.	What is regression and classification	5572
8222	A) (ii) Disadvantages of Mohr Method  Mohr's method is suitable only for titration of chloride, bromide and cyanide alone.  Errors can be introduced due to the need of excess titrant before the endpoint colour is visible.	What are the limitations of Mohr's method	8222
3462	This article lists out 10 comprehensive data mining tools widely used in the big data industry.Rapid Miner.  Oracle Data Mining.  IBM SPSS Modeler.  KNIME.  Python.  Orange.  Kaggle.  Rattle.More items•	What are the data mining tools	3462
7005	We can compute the p-value corresponding to the absolute value of the t-test statistics (|t|) for the degrees of freedom (df): df=n−1. If the p-value is inferior or equal to 0.05, we can conclude that the difference between the two paired samples are significantly different.	How do you find the degrees of freedom for a t test	7005
2524	Batch normalization (also known as batch norm) is a method used to make artificial neural networks faster and more stable through normalization of the input layer by re-centering and re-scaling.  Others sustain that batch normalization achieves length-direction decoupling, and thereby accelerates neural networks.	What does batch normalization do	2524
1125	Robust statistics are statistics with good performance for data drawn from a wide range of probability distributions, especially for distributions that are not normal. Robust statistical methods have been developed for many common problems, such as estimating location, scale, and regression parameters.	What does it mean robust in statistics	1125
9367	So, for 10% error, you need 100 hash functions. For 1% error, you need 10,000 hash functions. Yick. That's friggin expensive, and if that's all there were to MinHash, I'd simply go with the O(n log(n)) algorithm.	How many hash functions are required in a minhash algorithm	9367
6040	Genetic algorithms are important in machine learning for three reasons. First, they act on discrete spaces, where gradient-based methods cannot be used. They can be used to search rule sets, neural network architectures, cellular automata computers, and so forth.	Are genetic algorithms machine learning	6040
2057	Given an image or a video stream, an object detection model can identify which of a known set of objects might be present and provide information about their positions within the image.	What is an object detection model	2057
4784	Here are applications of Reinforcement Learning:Robotics for industrial automation.Business strategy planning.Machine learning and data processing.It helps you to create training systems that provide custom instruction and materials according to the requirement of students.Aircraft control and robot motion control.	What are the applications of reinforcement learning	4784
2791	Definition: Stratified sampling is a type of sampling method in which the total population is divided into smaller groups or strata to complete the sampling process.  Stratified sampling is used when the researcher wants to understand the existing relationship between two groups.	What is meant by stratified sampling	2791
8208	"Backtracking is a general algorithm for finding all (or some) solutions to some computational problems, notably constraint satisfaction problems, that incrementally builds candidates to the solutions, and abandons a candidate (""backtracks"") as soon as it determines that the candidate cannot possibly be completed to a"	What is backtracking algorithm	8208
10054	Micro-level adaptive instruction: The main feature of this approach is to utilize on-task rather than pre-task measurement to diagnose the students' learning behaviors and performance so as to adapt the instruction at the micro-level. Typical examples include one-on-one tutoring and intelligent tutoring systems.	Which is an example of adaptive instruction	10054
3436	"The distributional hypothesis in linguistics is derived from the semantic theory of language usage, i.e. words that are used and occur in the same contexts tend to purport similar meanings. The underlying idea that ""a word is characterized by the company it keeps"" was popularized by Firth in the 1950s."	What is distributional information	3436
7564	The false positive rate is calculated as FP/FP+TN, where FP is the number of false positives and TN is the number of true negatives (FP+TN being the total number of negatives). It's the probability that a false alarm will be raised: that a positive result will be given when the true value is negative.	How do you calculate false positives and negatives	7564
1358	The input() function accepts an optional string argument called prompt and returns a string. Note that the input() function always returns a string even if you entered a number. To convert it to an integer you can use int() or eval() functions.	What is the datatype of the output for the function input ()	1358
13	Time series regression is a statistical method for predicting a future response based on the response history (known as autoregressive dynamics) and the transfer of dynamics from relevant predictors.  Time series regression is commonly used for modeling and forecasting of economic, financial, and biological systems.	What are some methods of time series regression analysis	13
2445	Bayesian hyperparameter tuning allows us to do so by building a probabilistic model for the objective function we are trying to minimize/maximize in order to train our machine learning model. Examples of such objective functions are not scary - accuracy, root mean squared error and so on.	What is Bayesian Hyperparameter optimization	2445
6130	Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities.	What is modality in machine learning	6130
7684	An operating system (OS) is a set of functions or programs that coordinate a user program's access to the computer's resources (i.e. memory and CPU).  These functions are called the MicroStamp11's kernel functions.	How kernel functions are called	7684
612	As regards the normality of group data, the one-way ANOVA can tolerate data that is non-normal (skewed or kurtotic distributions) with only a small effect on the Type I error rate. However, platykurtosis can have a profound effect when your group sizes are small.	Can you use Anova if data is not normally distributed	612
10252	Sample size refers to the number of participants or observations included in a study. This number is usually represented by n. The size of a sample influences two statistical properties: 1) the precision of our estimates and 2) the power of the study to draw conclusions.	What is sample and sample size	10252
9560	Analysis of variance (ANOVA) is a statistical technique that is used to check if the means of two or more groups are significantly different from each other. ANOVA checks the impact of one or more factors by comparing the means of different samples.  Another measure to compare the samples is called a t-test.	How does Anova work in statistics	9560
7307	• Model capacity is ability to fit variety of functions. – Model with Low capacity struggles to fit training set. – A High capacity model can overfit by memorizing. properties of training set not useful on test set. • When model has higher capacity, it overfits.	What is model capacity in machine learning	7307
1961	A marginal distribution is the percentages out of totals, and conditional distribution is the percentages out of some column.  Conditional distribution, on the other hand, is the probability distribution of certain values in the table expressed as percentages out of sums (or local totals) of certain rows or columns.	What is marginal and conditional distribution	1961
9811	communalities is calculated sum of square factor loadings. Generally, an item factor loading is recommended higher than 0.30 or 0.33 cut value. So if an item load only one factor its communality will be 0.30*0.30 = 0.09.	What is the cutoff for loading factors using factor analysis	9811
8466	5. Image Processing Using Machine LearningFeature mapping using the scale-invariant feature transform (SIFT) algorithm.Image registration using the random sample consensus (RANSAC) algorithm.Image Classification using artificial neural networks.Image classification using convolutional neural networks (CNNs)Image Classification using machine learning.More items	How is image processing used in machine learning	8466
3841	As the df increase, the chi square distribution approaches a normal distribution. The mean of a chi square distribution is its df. The mode is df - 2 and the median is approximately df - 0 .	How do you find the mode of a chi square distribution	3841
8108	Unsupervised learning is a type of machine learning algorithm used to draw inferences from datasets consisting of input data without labeled responses. The most common unsupervised learning method is cluster analysis, which is used for exploratory data analysis to find hidden patterns or grouping in data.	Which algorithm falls under unsupervised learning	8108
868	Matrix factorization is a class of collaborative filtering algorithms used in recommender systems. Matrix factorization algorithms work by decomposing the user-item interaction matrix into the product of two lower dimensionality rectangular matrices.	Is matrix factorization collaborative filtering	868
5454	The theorem and its generalizations can be used to prove results and solve problems in combinatorics, algebra, calculus, and many other areas of mathematics. The binomial theorem also helps explore probability in an organized way: A friend says that she will flip a coin 5 times.	Why is the binomial theorem useful	5454
1310	"Linear least squares regression is by far the most widely used modeling method. It is what most people mean when they say they have used ""regression"", ""linear regression"" or ""least squares"" to fit a model to their data."	Is linear regression A least squares	1310
693	0:1110:28المقطع المقترح · 110 ثانيةLambda Measure of Association for Two Nominal Variables in SPSS YouTubeبداية المقطع المقترَحنهاية المقطع المقترَح	How do you interpret lambda in SPSS	693
10571	A random variable can be either discrete (having specific values) or continuous (any value in a continuous range). The use of random variables is most common in probability and statistics, where they are used to quantify outcomes of random occurrences.	Why are statistics random variables	10571
1490	KNN algorithm is one of the simplest classification algorithm and it is one of the most used learning algorithms.  KNN is a non-parametric, lazy learning algorithm. Its purpose is to use a database in which the data points are separated into several classes to predict the classification of a new sample point.	Why do we use KNN algorithm	1490
7332	A null hypothesis is a type of hypothesis used in statistics that proposes that there is no difference between certain characteristics of a population (or data-generating process). For example, a gambler may be interested in whether a game of chance is fair.	What is a null hypothesis example	7332
10115	Non-hierarchical clustering is frequently referred to as k-means clustering. This type of clustering does not require all possible distances to be computed in a large data set. This technique is primarily used for the analysis of clusters in data mining.	Is frequently referred to as K means clustering	10115
5084	Artificial intelligence is generally divided into two types – narrow (or weak) AI and general AI, also known as AGI or strong AI.	What are the 2 types of AI	5084
9546	The goal of lasso regression is to obtain the subset of predictors that minimizes prediction error for a quantitative response variable. The lasso does this by imposing a constraint on the model parameters that causes regression coefficients for some variables to shrink toward zero.	What is the purpose of Lasso regression	9546
10050	In a nutshell, hierarchical linear modeling is used when you have nested data; hierarchical regression is used to add or remove variables from your model in multiple steps. Knowing the difference between these two seemingly similar terms can help you determine the most appropriate analysis for your study.	When should we use hierarchical linear models	10050
587	The chief difference between MEMM and CRF is that MEMM is locally renormalized and suffers from the label bias problem, while CRFs are globally renormalized.	How do Conditional Random Fields CRF compare to Maximum Entropy Models and Hidden Markov Models	587
10836	Two different learning models were introduced that can be used as part of the word2vec approach to learn the word embedding; they are: Continuous Bag-of-Words, or CBOW model. Continuous Skip-Gram Model.	Which is the best model used in Word2Vec algorithm for word embedding	10836
361	Artificial intelligence (AI) is the attempt to let computers perform services for which humans need intelligence. However, this is still not possible today. AI systems are capable of recognizing patterns, learning and making decisions.	Is artificial intelligence intelligent	361
7506	A random effect model is a model all of whose factors represent random effects. (See Random Effects.) Such models are also called variance component models. Random effect models are often hierarchical models. A model that contains both fixed and random effects is called a mixed model.	What is random effect in mixed model	7506
3120	Introduction Statistical discrete processes – for example, the number of accidents per driver, the number of insects per leaf in an orchard, the number of thunderstorms per year, the number of earthquakes per year, the number of patients visit emergency room in a certain hospital per day - often occur in real life.	What are uses of discrete distributions in real life	3120
8076	Artificial Intelligence ExamplesManufacturing robots.Smart assistants.Proactive healthcare management.Disease mapping.Automated financial investing.Virtual travel booking agent.Social media monitoring.Inter-team chat tool.More items	What products use artificial intelligence	8076
6796	"The Kruskal-Wallis H test (sometimes also called the ""one-way ANOVA on ranks"") is a rank-based nonparametric test that can be used to determine if there are statistically significant differences between two or more groups of an independent variable on a continuous or ordinal dependent variable."	When Kruskal Wallis test is used	6796
5247	R-squared is a goodness-of-fit measure for linear regression models. This statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively.  After fitting a linear regression model, you need to determine how well the model fits the data.	What is r squared change in regression	5247
3999	Perceptron Learning Rule states that the algorithm would automatically learn the optimal weight coefficients. The input features are then multiplied with these weights to determine if a neuron fires or not.	What do you mean by Perceptron and its learning rule	3999
9201	Unlike the independent-samples t-test, the Mann-Whitney U test allows you to draw different conclusions about your data depending on the assumptions you make about your data's distribution.  These different conclusions hinge on the shape of the distributions of your data, which we explain more about later.	What is the difference between t test and Mann Whitney test	9201
4423	Two disjoint events can never be independent, except in the case that one of the events is null.  Events are considered disjoint if they never occur at the same time. For example, being a freshman and being a sophomore would be considered disjoint events. Independent events are unrelated events.	Can two events be independent and disjoint	4423
3813	Interpolation refers to using the data in order to predict data within the dataset. Extrapolation is the use of the data set to predict beyond the data set.	What is the difference between interpolation and extrapolation	3813
7430	The most popular is definitely KMP, if you need fast string matching without any particular usecase in mind it's what you should use. Here are your options(with time complexity): Brute Force O(nm) Knuth–Morris–Pratt algorithm - O(n)	Which is the best algorithm for checking string similarity metric	7430
2386	To visualize a small data set containing multiple categorical (or qualitative) variables, you can create either a bar plot, a balloon plot or a mosaic plot.  These methods make it possible to analyze and visualize the association (i.e. correlation) between a large number of qualitative variables.	What is a recommended way to visualize categorical data	2386
2847	AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability.  By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.	What is ROC AUC score	2847
6785	Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.	What is gradient boosting used for	6785
99	Random forest (RF) is a machine-learning method that generally works well with high-dimensional problems and allows for nonlinear relationships between predictors; however, the presence of correlated predictors has been shown to impact its ability to identify strong predictors.	Can random forest handle correlated variables	99
2001	So regression performance is measured by how close it fits an expected line/curve, while machine learning is measured by how good it can solve a certain problem, with whatever means necessary. I'll argue that the distinction between machine learning and statistical inference is clear.	What is the difference between machine learning and regression	2001
7480	Abstract. Markov chain Monte Carlo (MCMC) is a simulation technique that can be used to find the posterior distribution and to sample from it. Thus, it is used to fit a model and to draw samples from the joint posterior distribution of the model parameters.  The software OpenBUGS and Stan are MCMC samplers.	What is Markov Chain Monte Carlo and why it matters	7480
19	When comparing two groups, you need to decide whether to use a paired test. When comparing three or more groups, the term paired is not apt and the term repeated measures is used instead. Use an unpaired test to compare groups when the individual values are not paired or matched with one another.	What statistical analysis should I use to compare two groups	19
3766	The Cox (proportional hazards or PH) model (Cox, 1972) is the most commonly used multivariate approach for analysing survival time data in medical research. It is a survival analysis regression model, which describes the relation between the event incidence, as expressed by the hazard function and a set of covariates.	What is multivariate Cox regression analysis	3766
9193	To reduce variability we perform multiple rounds of cross-validation with different subsets from the same data. We combine the validation results from these multiple rounds to come up with an estimate of the model's predictive performance. Cross-validation will give us a more accurate estimate of a model's performance.	What does cross validation reduce	9193
2271	It is a Markov random field. It was translated from statistical physics for use in cognitive science. The Boltzmann machine is based on stochastic spin-glass model with an external field, i.e., a Sherrington–Kirkpatrick model that is a stochastic Ising Model and applied to machine learning.	Is there a relation between Boltzmann machines and Markov random fields	2271
1122	The null hypothesis is a general statement that states that there is no relationship between two phenomenons under consideration or that there is no association between two groups. An alternative hypothesis is a statement that describes that there is a relationship between two selected variables in a study.	What is the difference between null and alternative hypothesis	1122
8556	In mathematics, a Fourier transform (FT) is a mathematical transform that decomposes a function (often a function of time, or a signal) into its constituent frequencies, such as the expression of a musical chord in terms of the volumes and frequencies of its constituent notes.	What does Fourier mean	8556
8502	A probability distribution is a statistical function that describes all the possible values and likelihoods that a random variable can take within a given range.  These factors include the distribution's mean (average), standard deviation, skewness, and kurtosis.	What is a probability distribution explain your answer	8502
9954	The t-distribution cannot be calculated without a known standard deviation, while the standard normal distribution can be.	Which of the following is a difference between the T distribution and the standard normal Z distribution group of answer choices	9954
6031	8:3417:13Suggested clip · 72 secondsStepwise regression procedures in SPSS (new, 2018) - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you interpret a stepwise regression analysis	6031
9820	Abstract. Hidden Markov Models (HMMs) provide a simple and effective frame- work for modelling time-varying spectral vector sequences. As a con- sequence, almost all present day large vocabulary continuous speech recognition (LVCSR) systems are based on HMMs.	What is hidden Markov in speech recognition	9820
8966	Gradient boosting is a type of machine learning boosting. It relies on the intuition that the best possible next model, when combined with previous models, minimizes the overall prediction error. The key idea is to set the target outcomes for this next model in order to minimize the error.	What is an intuitive explanation of Gradient Boosting	8966
3415	k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster.	What is the point of K means clustering	3415
390	Depending on the skill being taught, backward chaining has a distinct advantage: It directly links the independent completion of a task to the immediate reward or reinforcement. Once the child can complete the last step independently, he or she can work on also completing the next-to-last step independently.	What is an advantage of backward chaining	390
7130	For more tips, read 10 Best Practices for Effective Dashboards.Choose the right charts and graphs for the job.  Use predictable patterns for layouts.  Tell data stories quickly with clear color cues.  Incorporate contextual clues with shapes and designs.  Strategically use size to visualize values.More items	How do you visualize data effectively	7130
2361	By using these midpoints as the categorical response values, the researcher can easily calculate averages. Granted, this average will only be an estimate or a “ballpark” value but is still extremely useful for the purpose of data analysis.	Can you average categorical data	2361
4050	The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem.	What is back propagation in machine learning	4050
7179	In probability theory and statistics, the hypergeometric distribution is a discrete probability distribution that describes the probability of successes (random draws for which the object drawn has a specified feature) in draws, without replacement, from a finite population of size that contains exactly objects with	What is a hypergeometric probability distribution	7179
1280	Definition of outliers. An outlier is an observation that lies an abnormal distance from other values in a random sample from a population.	What defines an outlier	1280
5935	A statistic d is called an unbiased estimator for a function of the parameter g(θ) provided that for every choice of θ, Eθd(X) = g(θ). Any estimator that not unbiased is called biased. The bias is the difference bd(θ) = Eθd(X) − g(θ). We can assess the quality of an estimator by computing its mean square error.	How do you calculate an unbiased estimator	5935
2481	Standardized effect size statistics remove the units of the variables in the effect. The second type is simple. These statistics describe the size of the effect, but remain in the original units of the variables. So for example, say you're comparing the mean temperature of soil under two different conditions.	What is standardized effect	2481
3861	A square matrix that is not invertible is called singular or degenerate. A square matrix is singular if and only if its determinant is zero.  Non-square matrices (m-by-n matrices for which m ≠ n) do not have an inverse. However, in some cases such a matrix may have a left inverse or right inverse.	What is non invertible matrix	3861
5546	A data set can also be presented by means of a data frequency table, a table in which each distinct value is listed in the first row and its frequency, which is the number of times the value appears in the data set, is listed below it in the second row.	What is data frequency table	5546
9603	Factor Analysis (FA) is an exploratory technique applied to a set of outcome variables that seeks to find the underlying factors (or subsets of variables) from which the observed variables were generated.	What is factor analysis in multivariate analysis	9603
1069	There are different types of mean, viz. arithmetic mean, weighted mean, geometric mean (GM) and harmonic mean (HM). If mentioned without an adjective (as mean), it generally refers to the arithmetic mean.	How many types of mean in statistics	1069
6078	The squared error has some nice properties: It is symmetrical. That means, if the actual value is and you predict or , you get the same error measure.	Why we take SSE sum of square error and RMSE root mean square error	6078
2466	Low-shot learning deep learning is based on the concept that reliable algorithms can be created to make predictions from minimalist datasets.	What is low shot learning	2466
2076	Weights(Parameters) — A weight represent the strength of the connection between units. If the weight from node 1 to node 2 has greater magnitude, it means that neuron 1 has greater influence over neuron 2. A weight brings down the importance of the input value.	Why weight is used in neural network	2076
1923	Multi-class Classification using Decision Tree, Random Forest and Extra Trees Algorithm in Python: An End-To-End Data Science Recipe — 016. a) Different types of Machine Learning problems.  i) How to implement Decision Tree, Random Forest and Extra Tree Algorithms for Multiclass Classification in Python.	Can random forest be used for multiclass classification	1923
7950	Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal, but are also a popular tool in machine learning.	What are decision trees commonly used for	7950
1554	This is the basis of the Breusch–Pagan test. It is a chi-squared test: the test statistic is distributed nχ2 with k degrees of freedom. If the test statistic has a p-value below an appropriate threshold (e.g. p < 0.05) then the null hypothesis of homoskedasticity is rejected and heteroskedasticity assumed.	What is the null hypothesis for Heteroskedasticity	1554
8391	There are various ways to modify a study design to actively exclude or control confounding variables (3) including Randomization, Restriction and Matching. In randomization the random assignment of study subjects to exposure categories to breaking any links between exposure and confounders.	How do you deal with confounders within a statistical study	8391
5266	In an upper-tailed test the decision rule has investigators reject H0 if the test statistic is larger than the critical value. In a lower-tailed test the decision rule has investigators reject H0 if the test statistic is smaller than the critical value.	How do you know if its a lower or upper tailed test	5266
5901	The quality loss function as defined by Taguchi is the loss imparted to the society by the product from the time the product is designed to the time it is shipped to the customer. In fact, he defined quality as the conformity around a target value with a lower standard deviation in the outputs.	What is Taguchi quality loss function	5901
7365	A mode of a continuous probability distribution is often considered to be any value x at which its probability density function has a locally maximum value, so any peak is a mode. In symmetric unimodal distributions, such as the normal distribution, the mean (if defined), median and mode all coincide.	What is the mode of a continuous random variable	7365
5329	Achieving translation invariance in Convolutional NNs: Then the max pooling layer takes the output from the convolutional layer and reduces its resolution and complexity. It does so by outputting only the max value from a grid.So the information about the exact position of the max value in the grid is discarded.	How exactly does max pooling create translation invariance	5329
10801	7 Techniques to Handle Imbalanced DataUse the right evaluation metrics.  Resample the training set.  Use K-fold Cross-Validation in the right way.  Ensemble different resampled datasets.  Resample with different ratios.  Cluster the abundant class.  Design your own models.	How do you handle an unbalanced data set	10801
8933	The standard deviation (SD) measures the amount of variability, or dispersion, from the individual data values to the mean, while the standard error of the mean (SEM) measures how far the sample mean of the data is likely to be from the true population mean.  SD is the dispersion of individual data values.	What does standard deviation of the mean represent	8933
9253	How to Handle Imbalanced DatasetChange the evaluation matrix. If we apply the wrong evaluation matrix on the imbalanced dataset, it can give us misleading results.  Resample the dataset. Resample means to change the distribution of the imbalance classes in the dataset.  Change the algorithm and approach to the problem.	How do you handle an imbalanced data set	9253
9263	The cumulative distribution function (CDF) calculates the cumulative probability for a given x-value. Use the CDF to determine the probability that a random observation that is taken from the population will be less than or equal to a certain value.	What is the use of cumulative distribution function	9263
7866	So, for example, if our random variable were the number obtained by rolling a fair 3-sided die, the expected value would be (1 * 1/3) + (2 * 1/3) + (3 * 1/3) = 2.	How do you find the expected value example	7866
4069	Decision theory is the science of making optimal decisions in the face of uncertainty. Statistical decision theory is concerned with the making of decisions when in the presence of statistical knowledge (data) which sheds light on some of the uncertainties involved in the decision problem.	What is decision theory in statistics	4069
7590	The Akaike information criterion (AIC) is a mathematical method for evaluating how well a model fits the data it was generated from. In statistics, AIC is used to compare different possible models and determine which one is the best fit for the data.	What does Akaike information criterion mean	7590
10870	Though the name is a mouthful, the concept behind this is very simple. To tell briefly, LDA imagines a fixed set of topics. Each topic represents a set of words. And the goal of LDA is to map all the documents to the topics in a way, such that the words in each document are mostly captured by those imaginary topics.	How does LDA algorithm work	10870
3155	Definition. In machine learning, model validation is referred to as the process where a trained model is evaluated with a testing data set. The testing data set is a separate portion of the same data set from which the training set is derived.  Model validation is carried out after model training.	What is validation machine learning	3155
2736	Cost function(J) of Linear Regression is the Root Mean Squared Error (RMSE) between predicted y value (pred) and true y value (y). Gradient Descent: To update θ1 and θ2 values in order to reduce Cost function (minimizing RMSE value) and achieving the best fit line the model uses Gradient Descent.	What is a cost function in linear regression	2736
10299	Vector space model or term vector model is an algebraic model for representing text documents (and any objects, in general) as vectors of identifiers, such as, for example, index terms.  The model is used to represent documents in an n-dimensional space. But a “document” can mean any object you're trying to model.	What is vector space in machine learning	10299
7087	Decision Tree - Overfitting There are several approaches to avoiding overfitting in building decision trees. Pre-pruning that stop growing the tree earlier, before it perfectly classifies the training set. Post-pruning that allows the tree to perfectly classify the training set, and then post prune the tree.	What is pre pruning and post pruning in decision tree	7087
7296	The 7 Steps of Machine Learning1 - Data Collection.2 - Data Preparation.3 - Choose a Model.4 - Train the Model.5 - Evaluate the Model.6 - Parameter Tuning.7 - Make Predictions.More items	What are the correct steps of a machine learning process	7296
9349	gamma is a parameter for non linear hyperplanes. The higher the gamma value it tries to exactly fit the training data set gammas = [0.1, 1, 10, 100]for gamma in gammas: svc = svm.SVC(kernel='rbf', gamma=gamma).fit(X, y)	What is Gamma in SVC	9349
1860	The weighted kappa is calculated using a predefined table of weights which measure the degree of disagreement between the two raters, the higher the disagreement the higher the weight.	When should I use weighted kappa	1860
10993	Taking the square root of the variance gives us the units used in the original scale and this is the standard deviation. Standard deviation is the measure of spread most commonly used in statistical practice when the mean is used to calculate central tendency. Thus, it measures spread around the mean.	Where do we use standard deviation and variance	10993
9269	The generator is a convolutional neural network and the discriminator is a deconvolutional neural network. The goal of the generator is to artificially manufacture outputs that could easily be mistaken for real data. The goal of the discriminator is to identify which outputs it receives have been artificially created.	What is the goal of a generative adversarial network GAN )	9269
4281	If the outcomes are mutually independent, then yes the method is valid. If the outcomes are mutually exclusive, then no, the method is not valid. It's easy to see why this is the case. If you have three binary models, then the sum of the outcomes do not necessarily sum to one.	Can you split a multinomial logistic regression model into separate binary logistic regression models	4281
5770	Autocorrelation, also known as serial correlation, is the correlation of a signal with a delayed copy of itself as a function of delay. Informally, it is the similarity between observations as a function of the time lag between them.	What is correlation and autocorrelation	5770
5920	Choosing the right Activation FunctionSigmoid functions and their combinations generally work better in the case of classifiers.Sigmoids and tanh functions are sometimes avoided due to the vanishing gradient problem.ReLU function is a general activation function and is used in most cases these days.More items•	What is the activation function used for	5920
5851	Information provides a way to quantify the amount of surprise for an event measured in bits. Entropy provides a measure of the average amount of information needed to represent an event drawn from a probability distribution for a random variable.	Why is information entropy	5851
8125	While the returns for stocks usually have a normal distribution, the stock price itself is often log-normally distributed. This is because extreme moves become less likely as the stock's price approaches zero.	Why do prices and income follow a log normal distribution	8125
2036	Response bias can be defined as the difference between the true values of variables in a study's net sample group and the values of variables obtained in the results of the same study.  Nonresponse bias occurs when some respondents included in the sample do not respond.	What is the difference between nonresponse and response bias	2036
5722	Linear means something related to a line.  A non-linear equation is such which does not form a straight line. It looks like a curve in a graph and has a variable slope value. The major difference between linear and nonlinear equations is given here for the students to understand it in a more natural way.	What is the difference between linear and nonlinear association	5722
1089	The 5 main steps to create word clouds in RStep 1: Create a text file.  Step 2 : Install and load the required packages.  Step 3 : Text mining.  Step 4 : Build a term-document matrix.  Step 5 : Generate the Word cloud.	How do I use text mining in R	1089
10619	5 Most Important Methods For Statistical Data AnalysisMean. The arithmetic mean, more commonly known as “the average,” is the sum of a list of numbers divided by the number of items on the list.  Standard Deviation.  Regression.  Sample Size Determination.  Hypothesis Testing.	What is the best statistical analysis technique	10619
3198	Big data is a big deal. From reducing their costs and making better decisions, to creating products and services that are in demand by customers, businesses will increasingly benefit by using big-data analytics.	What's the big deal about Big Data	3198
10123	recursion	Which search method is used in Minimax algorithm	10123
7085	Linear filtering is the filtering method in which the value of output pixel is linear combinations of the neighbouring input pixels.  A non-linear filtering is one that cannot be done with convolution or Fourier multiplication. A sliding median filter is a simple example of a non-linear filter.	What is the difference between linear and nonlinear filters	7085
4711	Linear regression quantifies the relationship between one or more predictor variable(s) and one outcome variable.  For example, it can be used to quantify the relative impacts of age, gender, and diet (the predictor variables) on height (the outcome variable).	What is regression example	4711
1383	"For skewed distributions, it is quite common to have one tail of the distribution considerably longer or drawn out relative to the other tail. A ""skewed right"" distribution is one in which the tail is on the right side. A ""skewed left"" distribution is one in which the tail is on the left side."	What does a left skewed distribution mean	1383
10179	Pearson's product moment correlation coefficient (r) is given as a measure of linear association between the two variables: r² is the proportion of the total variance (s²) of Y that can be explained by the linear regression of Y on x. 1-r² is the proportion that is not explained by the regression.	What is the correlation coefficient in a linear regression	10179
5625	Investment risk is the idea that an investment will not perform as expected, that its actual return will deviate from the expected return. Risk is measured by the amount of volatility, that is, the difference between actual returns and average (expected) returns.	How do you measure risk and return	5625
2907	The probability distribution of a discrete random variable can always be represented by a table. For example, suppose you flip a coin two times.  The probability of getting 0 heads is 0.25; 1 head, 0.50; and 2 heads, 0.25. Thus, the table is an example of a probability distribution for a discrete random variable.	What is an example of probability distribution	2907
6763	Binary Search: Search a sorted array by repeatedly dividing the search interval in half. Begin with an interval covering the whole array. If the value of the search key is less than the item in the middle of the interval, narrow the interval to the lower half.	How do you perform a binary search	6763
3613	The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.  The rectified linear activation function overcomes the vanishing gradient problem, allowing models to learn faster and perform better.	What s so special about rectified linear units ReLU activation function	3613
7871	Typically, a regression analysis is done for one of two purposes: In order to predict the value of the dependent variable for individuals for whom some information concerning the explanatory variables is available, or in order to estimate the effect of some explanatory variable on the dependent variable.	What is the purpose of a regression model	7871
8008	T-test. A t-test is used to compare the mean of two given samples. Like a z-test, a t-test also assumes a normal distribution of the sample. A t-test is used when the population parameters (mean and standard deviation) are not known.	Is at test a statistical test	8008
7722	Replaces an image by the norm of its gradient, as estimated by discrete filters. The Raw filter of the detail panel designates two filters that correspond to the two components of the gradient in the principal directions.	What is a gradient norm	7722
3656	The amount that the weights are updated during training is referred to as the step size or the “learning rate.” Specifically, the learning rate is a configurable hyperparameter used in the training of neural networks that has a small positive value, often in the range between 0.0 and 1.0.	What is step size in machine learning	3656
123	Simply put, an activation function is a function that is added into an artificial neural network in order to help the network learn complex patterns in the data. When comparing with a neuron-based model that is in our brains, the activation function is at the end deciding what is to be fired to the next neuron.	What is the role of the activation function in a neural network How does this function in a human neural network system	123
4095	Dimensionality reduction is the process of reducing the number of random variables or attributes under consideration. High-dimensionality data reduction, as part of a data pre-processing-step, is extremely important in many real-world applications.	What is the need of dimensionality reduction in data mining	4095
927	Your classifier would have learned an equal an opposite rule, with the same performance and same AUC / ROC curve.	What will happen to AUC if I switch the positive and negative classes in the test data	927
4170	Posterior probability = prior probability + new evidence (called likelihood). For example, historical data suggests that around 60% of students who start college will graduate within 6 years. This is the prior probability. However, you think that figure is actually much lower, so set out to collect new data.	What is posterior probability example	4170
3052	It depends on the data you want and the project you're doing. You could use even your twitter data for sentiment analysis. Request your archive in twitter -> download -> analyse sentiment through supervised learning techniques.	Where can one find a training set for sentiment analysis	3052
8230	Random assignment helps reduce the chances of systematic differences between the groups at the start of an experiment and, thereby, mitigates the threats of confounding variables and alternative explanations. However, the process does not always equalize all of the confounding variables.	How does random assignment control for confounding variables	8230
5281	In Bayesian statistics, a maximum a posteriori probability (MAP) estimate is an estimate of an unknown quantity, that equals the mode of the posterior distribution. The MAP can be used to obtain a point estimate of an unobserved quantity on the basis of empirical data.	What is map in ML	5281
2893	The size of the sample space is the total number of possible outcomes. For example, when you roll 1 die, the sample space is 1, 2, 3, 4, 5, or 6. So the size of the sample space is 6.	How do you find the sample space	2893
4761	Some of my suggestions to you would be:Feature Scaling and/or Normalization - Check the scales of your gre and gpa features.  Class Imbalance - Look for class imbalance in your data.  Optimize other scores - You can optimize on other metrics also such as Log Loss and F1-Score.More items	How can you improve the accuracy of a logistic regression model in python	4761
9306	The k-means problem is finding the least-squares assignment to centroids. There are multiple algorithms for finding a solution. There is an obvious approach to find the global optimum: enumerating all k^n possible assignments - that will yield a global minimum, but in exponential runtime.	How do you get global minima in K means algorithm	9306
9969	If a p-value is lower than our significance level, we reject the null hypothesis. If not, we fail to reject the null hypothesis.	What happens when the p value is lower than the level of significance	9969
6804	1:314:30Suggested clip · 120 secondsCumulative Frequency Distribution (Less than and More than YouTubeStart of suggested clipEnd of suggested clip	How do you construct a less than cumulative frequency distribution	6804
2836	Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.	Is AI all about simulating human intelligence	2836
2111	For the vanishing gradient problem, the further you go through the network, the lower your gradient is and the harder it is to train the weights, which has a domino effect on all of the further weights throughout the network. That was the main roadblock to using Recurrent Neural Networks.	What is vanishing gradient problem in RNN	2111
338	Hypothesis Tests of the Mean and MedianParametric tests (means)Nonparametric tests (medians)1-sample t test1-sample Sign, 1-sample Wilcoxon2-sample t testMann-Whitney testOne-Way ANOVAKruskal-Wallis, Mood's median testFactorial DOE with one factor and one blocking variableFriedman test	What are the different types of parametric tests	338
1230	Simple linear regression relates X to Y through an equation of the form Y = a + bX. Both quantify the direction and strength of the relationship between two numeric variables.  The correlation squared (r2 or R2) has special meaning in simple linear regression.	Does linear regression show correlation	1230
9354	In statistics, the likelihood function (often simply called the likelihood) measures the goodness of fit of a statistical model to a sample of data for given values of the unknown parameters.	What does likelihood mean in statistics	9354
9814	If you're given the probability (percent) greater than x and you need to find x, you translate this as: Find b where p(X > b) = p (and p is given). Rewrite this as a percentile (less-than) problem: Find b where p(X < b) = 1 – p. This means find the (1 – p)th percentile for X.	How do you find the percentile under the normal curve	9814
6806	Two examples of common independent variables are age and time.  They're independent of everything else. The dependent variable (sometimes known as the responding variable) is what is being studied and measured in the experiment. It's what changes as a result of the changes to the independent variable.	What is an independent variable example	6806
8383	A decision tree is a flowchart-like diagram that shows the various outcomes from a series of decisions. It can be used as a decision-making tool, for research analysis, or for planning strategy. A primary advantage for using a decision tree is that it is easy to follow and understand.	What is decision tree diagram	8383
7022	Heteroscedasticity means unequal scatter. In regression analysis, we talk about heteroscedasticity in the context of the residuals or error term. Specifically, heteroscedasticity is a systematic change in the spread of the residuals over the range of measured values.	What is Homoscedasticity in regression analysis	7022
185	The universe is considered an isolated system because the energy of the universe is constant. This matches with the definition of an isolated system, which is that energy is not exchanged with the surroundings, thus staying constant.	Is the universe an isolated system	185
7488	Simple Linear Regression Math by HandCalculate average of your X variable.Calculate the difference between each X and the average X.Square the differences and add it all up.  Calculate average of your Y variable.Multiply the differences (of X and Y from their respective averages) and add them all together.More items	How do you calculate linear regression by hand	7488
193	Bayesian analysis is a statistical paradigm that answers research questions about unknown parameters using probability statements.	What is the purpose of Bayesian analysis	193
4853	Reliability refers to the extent that the instrument yields the same results over multiple trials. Validity refers to the extent that the instrument measures what it was designed to measure.  Construct validity uses statistical analyses, such as correlations, to verify the relevance of the questions.	What is validity and reliability in statistics	4853
2834	1:246:12Suggested clip · 104 secondsBuilding Statistical Models - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you make a statistical model	2834
4078	Naive Bayes classifier (Russell, & Norvig, 1995) is another feature-based supervised learning algorithm. It was originally intended to be used for classification tasks, but with some modifications it can be used for regression as well (Frank, Trigg, Holmes, & Witten, 2000) .	Can naive Bayes be used for regression	4078
10744	As the formula shows, the standard score is simply the score, minus the mean score, divided by the standard deviation.	How do you find the standardized score	10744
10303	12 Tips to boost your multitasking skillsAccept your limits. To better manage task organization, be aware of your limits, especially those you can't control.  Distinguish urgent from important.  Learn to concentrate.  Avoid distractions.  Work in blocks of time.  Work on related tasks together.  Learn to supervise.  Plan ahead.More items•	How can I learn multitasking	10303
668	How to conduct a multivariate testIdentify a problem.  Formulate a hypothesis.  Create variations.  Determine your sample size.  Test your tools.  Start driving traffic.  Analyze your results.  Learn from your results.	How do you do a multivariate test	668
8894	A subquery is a select statement that is embedded in a clause of another select statement.  A Correlated subquery is a subquery that is evaluated once for each row processed by the outer query or main query.	What is the difference between subquery and correlated query	8894
65	Look at normality plots of the data. “Normal Q-Q Plot” provides a graphical way to determine the level of normality. The black line indicates the values your sample should adhere to if the distribution was normal.  If the dots fall exactly on the black line, then your data are normal.	How do you know if your data is normally distributed	65
4410	A pooling layer is another building block of a CNN. Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network. Pooling layer operates on each feature map independently. The most common approach used in pooling is max pooling.	Why is the pooling layer used in CNN	4410
5698	How to Deal with MulticollinearityRemove some of the highly correlated independent variables.Linearly combine the independent variables, such as adding them together.Perform an analysis designed for highly correlated variables, such as principal components analysis or partial least squares regression.	How does logistic regression deal with Multicollinearity	5698
3335	Derivative RulesCommon FunctionsFunctionDerivativeSquarex22xSquare Root√x(½)x-½Exponentialexexaxln(a) ax24 more rows	What is the derivative of E X	3335
806	In exploratory studies, p-values enable the recognition of any statistically noteworthy findings. Confidence intervals provide information about a range in which the true value lies with a certain degree of probability, as well as about the direction and strength of the demonstrated effect.	What is the difference between P value and confidence interval	806
5856	In the design of experiments and analysis of variance, a main effect is the effect of an independent variable on a dependent variable averaged across the levels of any other independent variables.  Main effects are essentially the overall effect of a factor.	What do main effects mean in Anova	5856
8219	A function that represents a discrete probability distribution is called a probability mass function. A function that represents a continuous probability distribution is called a probability density function. Functions that represent probability distributions still have to obey the rules of probability.	What is the difference between probability density function and probability distribution function	8219
8865	Similar to the distinction in philosophy between a priori and a posteriori, in Bayesian inference a priori denotes general knowledge about the data distribution before making an inference, while a posteriori denotes knowledge that incorporates the results of making an inference.	What is the difference between a priori and a posteriori probability	8865
755	This learning process is independent.  During the training of ANN under unsupervised learning, the input vectors of similar type are combined to form clusters. When a new input pattern is applied, then the neural network gives an output response indicating the class to which input pattern belongs.	What is unsupervised learning in neural network	755
7394	Critic Loss: D(x) - D(G(z)) The discriminator tries to maximize this function. In other words, it tries to maximize the difference between its output on real instances and its output on fake instances.	What is discriminator loss	7394
2286	Tensors are simply mathematical objects that can be used to describe physical properties, just like scalars and vectors. In fact tensors are merely a generalisation of scalars and vectors; a scalar is a zero rank tensor, and a vector is a first rank tensor.	What do you mean by tensor	2286
2375	The task of object localization is to predict the object in an image as well as its boundaries.  Simply, object localization aims to locate the main (or most visible) object in an image while object detection tries to find out all the objects and their boundaries.	What is localization in image processing	2375
10659	Tokenization is the process of tokenizing or splitting a string, text into a list of tokens. One can think of token as parts like a word is a token in a sentence, and a sentence is a token in a paragraph. How sent_tokenize works ? The sent_tokenize function uses an instance of PunktSentenceTokenizer from the nltk.	How does NLTK sentence Tokenizer work	10659
7405	The best fit line is the one that minimises sum of squared differences between actual and estimated results. Taking average of minimum sum of squared difference is known as Mean Squared Error (MSE). Smaller the value, better the regression model.	How do you tell if a regression model is a good fit	7405
6076	The cross-entropy compares the model's prediction with the label which is the true probability distribution. The cross-entropy goes down as the prediction gets more and more accurate. It becomes zero if the prediction is perfect. As such, the cross-entropy can be a loss function to train a classification model.	How does cross entropy work	6076
6744	The Machine Learning algorithms that require the feature scaling are mostly KNN (K-Nearest Neighbours), Neural Networks, Linear Regression, and Logistic Regression.	Which machine learning algorithms require feature scaling	6744
4416	Definition. Inter-rater reliability is the extent to which two or more raters (or observers, coders, examiners) agree. It addresses the issue of consistency of the implementation of a rating system. Inter-rater reliability can be evaluated by using a number of different statistics.	What does Inter rater mean	4416
2090	Events A and B are independent if the equation P(A∩B) = P(A) · P(B) holds true. You can use the equation to check if events are independent; multiply the probabilities of the two events together to see if they equal the probability of them both happening together.	How do you know if something is independent in probability	2090
9339	An indicator random variable is a special kind of random variable associated with the occurence of an event. The indicator random variable IA associated with event A has value 1 if event A occurs and has value 0 otherwise. In other words, IA maps all outcomes in the set A to 1 and all outcomes outside A to 0.	What is an indicator random variable	9339
8821	The coefficient of variation is a better risk measure than the standard deviation alone because the CV adjusts for the size of the project. The CV measures the standard deviation divided by the mean and therefore puts the standard deviation into context.	Why is the coefficient of variation a better risk measure to	8821
4226	1 — Linear Regression.  2 — Logistic Regression.  3 — Linear Discriminant Analysis.  4 — Classification and Regression Trees.  5 — Naive Bayes.  6 — K-Nearest Neighbors.  7 — Learning Vector Quantization.  8 — Support Vector Machines.More items•	Which classification algorithms is easiest to start with for prediction	4226
4116	A feature selection method is proposed to select a subset of variables in principal component analysis (PCA) that preserves as much information present in the complete data as possible. The information is measured by means of the percentage of consensus in generalised Procrustes analysis.	How Principal component analysis is used for feature selection	4116
2122	The task boils down to computing the distance between two face vectors. As such, appropriate distance metrics are essential for face verification accuracy.  The use of cosine similarity in our method leads to an effective learning algorithm which can improve the generalization ability of any given metric.	Why does face verification identification usally use cosine similarity	2122
2105	When dealing with Machine Learning models, it is usually recommended that you store them somewhere. At the private sector, you oftentimes train them and store them before production, while in research and for future model tuning it is a good idea to store them locally.	Where are machine learning models stored	2105
6534	Logistic regression is a classification algorithm traditionally limited to only two-class classification problems. If you have more than two classes then Linear Discriminant Analysis is the preferred linear classification technique.	Is linear discriminant analysis machine learning	6534
4008	A significant result indicates that your data are significantly heteroscedastic, and thus the assumption of homoscedasticity in the regression residuals is violated. In your case the data violate the assumption of homoscedasticity, as your p value is 8.6⋅10−28. The e is standard scientific notation for powers of 10.	What is E in P value	4008
5684	A latent variable is a variable that cannot be observed. The presence of latent variables, however, can be detected by their effects on variables that are observable. Most constructs in research are latent variables.  Because measurement error is by definition unique variance, it is not captured in the latent variable.	What is the meaning of latent variable	5684
505	ANOVA is used to compare and contrast the means of two or more populations. ANCOVA is used to compare one variable in two or more populations while considering other variables.	Why we use Ancova instead of Anova	505
9654	"The ith order statistic of a set of n elements is the ith smallest element. For example, the minimum of a set of elements is the first order statistic (i = 1), and the maximum is the nth order statistic (i = n). A median, informally, is the ""halfway point"" of the set."	What is the ith order statistic	9654
2917	Convolution neural network is a type of neural network which has some or all convolution layers. Feed forward neural network is a network which is not recursive. neurons in this layer were only connected to neurons in the next layer.  neurons in this layer were only connected to neurons in the next layer.	What are the differences between a convolutional network and a feedforward neural network	2917
7391	Markov chains are an important concept in stochastic processes. They can be used to greatly simplify processes that satisfy the Markov property, namely that the future state of a stochastic variable is only dependent on its present state.	What is the use of Markov chain	7391
8567	Conditional Random Fields (CRF) CRF is a discriminant model for sequences data similar to MEMM. It models the dependency between each state and the entire input sequences. Unlike MEMM, CRF overcomes the label bias issue by using global normalizer.	What is CRF NLP	8567
9039	68% of the data is within 1 standard deviation (σ) of the mean (μ), 95% of the data is within 2 standard deviations (σ) of the mean (μ), and 99.7% of the data is within 3 standard deviations (σ) of the mean (μ).	What is 2 standard deviations from the mean	9039
5584	In scikit-learn we can use the CalibratedClassifierCV class to create well calibrated predicted probabilities using k-fold cross-validation.  In CalibratedClassifierCV the training sets are used to train the model and the test sets is used to calibrate the predicted probabilities.	What is CalibratedClassifierCV	5584
2310	Different classifiers are then added on top of this feature extractor to classify images.Support Vector Machines. It is a supervised machine learning algorithm used for both regression and classification problems.  Decision Trees.  K Nearest Neighbor.  Artificial Neural Networks.  Convolutional Neural Networks.	How do you classify images in machine learning	2310
10100	The AUC value lies between 0.5 to 1 where 0.5 denotes a bad classifer and 1 denotes an excellent classifier.	What is a good ROC score	10100
704	Data for two variables (usually two types of related data). Example: Ice cream sales versus the temperature on that day. The two variables are Ice Cream Sales and Temperature.	What are some examples of bivariate data	704
7989	Statement of the Multiplication Rule In order to use the rule, we need to have the probabilities of each of the independent events. Given these events, the multiplication rule states the probability that both events occur is found by multiplying the probabilities of each event.	Do you multiply independent events probability	7989
6410	Findings. A fundamental problem with stepwise regression is that some real explanatory variables that have causal effects on the dependent variable may happen to not be statistically significant, while nuisance variables may be coincidentally significant.	What is wrong with stepwise regression	6410
8004	Gradient Boosting or GBM is another ensemble machine learning algorithm that works for both regression and classification problems. GBM uses the boosting technique, combining a number of weak learners to form a strong learner.  We will use a simple example to understand the GBM algorithm.	What are different ensemble learning algorithms	8004
2306	The mean Average Precision or mAP score is calculated by taking the mean AP over all classes and/or overall IoU thresholds, depending on different detection challenges that exist. In PASCAL VOC2007 challenge, AP for one object class is calculated for an IoU threshold of 0.5.	How do you calculate average precision score	2306
4247	Interpolation is making an educated guess with the information within a certain data set. It is a “best guess” using the information you have at hand.	What is interpolation in machine learning	4247
4947	Unsupervised learning uses the entire dataset for the supervised training process. In contrast, in self-supervised learning, you withhold part of the data in some form, and you try to predict the rest.  In contrast, in self-supervised learning, you withhold part of the data in some form, and you try to predict the rest.	What is the difference between self supervised and unsupervised learning	4947
3749	A matrix A is symmetric if it is equal to its transpose, i.e., A=AT. A matrix A is symmetric if and only if swapping indices doesn't change its components, i.e., aij=aji.	What makes a matrix symmetric	3749
1026	A kind of average sometimes used in statistics and engineering, often abbreviated as RMS. To find the root mean square of a set of numbers, square all the numbers in the set and then find the arithmetic mean of the squares. Take the square root of the result. This is the root mean square.	How is root mean square calculated	1026
1257	Probit regression, also called a probit model, is used to model dichotomous or binary outcome variables. In the probit model, the inverse standard normal distribution of the probability is modeled as a linear combination of the predictors.	What is probit regression used for	1257
1044	4.1 Input Layer Input layer in CNN should contain image data. Image data is represented by three dimensional matrix as we saw earlier. You need to reshape it into a single column.  If you have “m” training examples then dimension of input will be (784, m).	What is input layer in CNN	1044
2683	Because neural networks work internally with numeric data, binary data (such as sex, which can be male or female) and categorical data (such as a community, which can be suburban, city or rural) must be encoded in numeric form.	Can neural network handle categorical data	2683
8652	Variance of estimator: Variance is one of the most popularly used measures of spread. It is taken into consideration for quantification of the amount of dispersion with respect to set of data values. Variance is defined as the average of the squared deviation of each observation from its mean.	What is the variance of the estimator	8652
8205	How It Works. Connected component labeling works by scanning an image, pixel-by-pixel (from top to bottom and left to right) in order to identify connected pixel regions, i.e. regions of adjacent pixels which share the same set of intensity values V.	How does connected component image labeling work on colored images	8205
7767	The variance is the average of the sum of squares (i.e., the sum of squares divided by the number of observations). The standard deviation is the square root of the variance.	How do you find the variance of a sum of squares	7767
9999	Predictive analytics are used to determine customer responses or purchases, as well as promote cross-sell opportunities. Predictive models help businesses attract, retain and grow their most profitable customers. Improving operations. Many companies use predictive models to forecast inventory and manage resources.	How are predictive analytics commonly used	9999
938	Machine learning is perhaps the principal technology behind two emerging domains: data science and artificial intelligence. The rise of machine learning is coming about through the availability of data and computation, but machine learning methdologies are fundamentally dependent on models.	What are the domains of machine learning	938
4740	The number of hidden neurons should be between the size of the input layer and the size of the output layer. The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer. The number of hidden neurons should be less than twice the size of the input layer.	How do you determine the size of a hidden layer	4740
3421	Blocking refers to classifying experimental units into blocks whereas stratification refers to classifying individuals of a population into strata. The samples from the strata in a stratified random sample can be the blocks in an experiment.	What is the difference between blocking and stratification	3421
9225	It is well known that maximum likelihood estimators are often biased, and it is of use to estimate the expected bias so that we can reduce the mean square errors of our parameter estimates.  In both problems, the first-order bias is found to be linear in the parameter and the sample size.	Is maximum likelihood estimator biased	9225
434	Rather than trying to define a number, instead define what a field of numbers is; instead of defining what a vector is, consider instead all the vectors that make up a vector space. So to understand tensors of a particular type, instead consider all those tensors of the same type together.	What is a good way to understand tensors	434
10022	Bayes Theorem for Modeling Hypotheses. Bayes Theorem is a useful tool in applied machine learning. It provides a way of thinking about the relationship between data and a model. A machine learning algorithm or model is a specific way of thinking about the structured relationships in the data.	How Bayes theorem is applied in machine learning	10022
4401	The WordNet is a part of Python's Natural Language Toolkit. It is a large word database of English Nouns, Adjectives, Adverbs and Verbs. These are grouped into some set of cognitive synonyms, which are called synsets.  In the wordnet, there are some groups of words, whose meaning are same.	What is NLTK WordNet	4401
3158	In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.	What are the differences between supervised and unsupervised classification	3158
9873	Hypergeometric Formula.. The hypergeometric distribution has the following properties: The mean of the distribution is equal to n * k / N . The variance is n * k * ( N - k ) * ( N - n ) / [ N2 * ( N - 1 ) ] .	What is the formula for hypergeometric distribution	9873
9296	Finally, the test dataset is a dataset used to provide an unbiased evaluation of a final model fit on the training dataset. If the data in the test dataset has never been used in training (for example in cross-validation), the test dataset is also called a holdout dataset.	Why is test data set used	9296
10672	The probability distribution of a discrete random variable can always be represented by a table. For example, suppose you flip a coin two times.  The probability of getting 0 heads is 0.25; 1 head, 0.50; and 2 heads, 0.25. Thus, the table is an example of a probability distribution for a discrete random variable.	What is a probability distribution example	10672
3714	A statistic is biased if the long-term average value of the statistic is not the parameter it is estimating. More formally, a statistic is biased if the mean of the sampling distribution of the statistic is not equal to the parameter.  Therefore the sample mean is an unbiased estimate of μ.	Is mean a biased estimator	3714
2013	Many everyday data sets typically follow a normal distribution: for example, the heights of adult humans, the scores on a test given to a large class, errors in measurements. The normal distribution is always symmetrical about the mean.	Does the data follow a normal distribution	2013
481	Simple linear regression is a regression model that estimates the relationship between one independent variable and one dependent variable using a straight line. Both variables should be quantitative.	What is a simple linear regression model	481
133	The second reason you may see validation loss lower than training loss is due to how the loss value are measured and reported: Training loss is measured during each epoch. While validation loss is measured after each epoch.	Why is my validation loss lower than training loss	133
10444	In other words, discriminative models are used to specify outputs based on inputs (by models such as Logistic regression, Neural networks and Random forests), while generative models generate both inputs and outputs (for example, by Hidden Markov model, Bayesian Networks and Gaussian mixture model).	Is Random Forest generative or discriminative	10444
2501	The ability to slide the signal is the what gives Engineers a more accurate representation of the signal and therefore a better resolution in time.  So when you use a Wavelet Transform the signal is deconstructed using the same wavelet at different scales, rather than the same sin() wave at different frequencies.	Why do we use wavelet transform	2501
8052	To create a stratified random sample, there are seven steps: (a) defining the population; (b) choosing the relevant stratification; (c) listing the population; (d) listing the population according to the chosen stratification; (e) choosing your sample size; (f) calculating a proportionate stratification; and (g) using	How do you do stratified sampling	8052
4375	A method of computing a kind of arithmetic mean of a set of numbers in which some elements of the set carry more importance (weight) than others. Example: Grades are often computed using a weighted average. Suppose that homework counts 10%, quizzes 20%, and tests 70%.	What is weighted average with example	4375
8293	In probability theory and statistics, the marginal distribution of a subset of a collection of random variables is the probability distribution of the variables contained in the subset. It gives the probabilities of various values of the variables in the subset without reference to the values of the other variables.	What does marginal distribution mean	8293
4182	Conditional probability is the probability of one event occurring with some relationship to one or more other events. For example: Event A is that it is raining outside, and it has a 0.3 (30%) chance of raining today. Event B is that you will need to go outside, and that has a probability of 0.5 (50%).	What is conditional probability explain with an example	4182
9660	Now we'll check out the proven way to improve the performance(Speed and Accuracy both) of neural network models:Increase hidden Layers.  Change Activation function.  Change Activation function in Output layer.  Increase number of neurons.  Weight initialization.  More data.  Normalizing/Scaling data.More items•	How can neural networks be improved	9660
36	In probability theory and related fields, a stochastic or random process is a mathematical object usually defined as a family of random variables.  Stochastic processes are widely used as mathematical models of systems and phenomena that appear to vary in a random manner.	What is probability and random process	36
2371	The mn Rule Consider an experiment that is performed in two stages. If the first stage can be accomplished in m different ways and for each of these ways, the second stage can be accomplished in n different ways, then there are to- tal mn different ways to accomplish the experiment.	What is the MN rule in statistics	2371
682	Recurrent Neural Networks (RNNs) are a form of machine learning algorithm that are ideal for sequential data such as text, time series, financial data, speech, audio, video among others.	Is recurrent neural networks are best suited for text processing	682
6278	3.1 . Each bootstrap distribution is centered at the statistic from the corresponding sample rather than at the population mean μ.	Where is a bootstrap distribution centered	6278
5771	DeepMind	Who has beaten AlphaGo	5771
7128	Pierre-Simon Laplace	Who proved the central limit theorem	7128
1915	The estimation of distribution algorithm (EDA) aims to explicitly model the probability distribution of the quality solutions to the underlying problem. By iterative filtering for quality solution from competing ones, the probability model eventually approximates the distribution of global optimum solutions.	Evolutionary Computation Estimation of Distribution Algorithm EDA	1915
9346	Artificial intelligence can dramatically improve the efficiencies of our workplaces and can augment the work humans can do. When AI takes over repetitive or dangerous tasks, it frees up the human workforce to do work they are better equipped for—tasks that involve creativity and empathy among others.	What is the role of artificial intelligence in the shaping modern society	9346
9894	Implementing Deep Learning Methods and Feature Engineering for Text Data: FastText. Overall, FastText is a framework for learning word representations and also performing robust, fast and accurate text classification. The framework is open-sourced by Facebook on GitHub.	Is fastText deep learning	9894
5377	The exponential distribution is often used to model the longevity of an electrical or mechanical device. In Example, the lifetime of a certain computer part has the exponential distribution with a mean of ten years (X∼Exp(0.1)).	When would you use an exponential distribution	5377
7286	"The definition is: ""Entropy is a measure of how evenly energy is distributed in a system. In a physical system, entropy provides a measure of the amount of energy that cannot be used to do work."""	What is entropy in layman's terms	7286
926	"For this, you aim to maximize the Youden's index, which is Maximum=Sensitivity + Specificity - 1. So you choose those value of the ROC-curve as a cut-off, where the term ""Sensitivity + Specificity - 1"" (parameters taken from the output in the same line as the observed value, see attachments) is maximal."	How cut off value is calculated from ROC curve	926
10750	The standard error tells you how accurate the mean of any given sample from that population is likely to be compared to the true population mean. When the standard error increases, i.e. the means are more spread out, it becomes more likely that any given mean is an inaccurate representation of the true population mean.	What standard error tells us	10750
3012	Validity is important because it can help determine what types of tests to use, and help to make sure researchers are using methods that are not only ethical, and cost-effective, but also a method that truly measures the idea or constructs in question.	What is the purpose of measuring the validity of a test	3012
1712	Standard deviation tells you how spread out the data is. It is a measure of how far each observed value is from the mean. In any distribution, about 95% of values will be within 2 standard deviations of the mean.	What does the standard deviation tell you	1712
9456	0:0012:40Suggested clip · 82 secondsCommon Source Amplifiers - Gain Equation - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you calculate gain of common source amplifier	9456
6498	Use Augmented Dickey-Fuller Test (adf test). A p-Value of less than 0.05 in adf. test() indicates that it is stationary.	How do I check if a time series is stationary in R	6498
8035	A CNN LSTM can be defined by adding CNN layers on the front end followed by LSTM layers with a Dense layer on the output. It is helpful to think of this architecture as defining two sub-models: the CNN Model for feature extraction and the LSTM Model for interpreting the features across time steps.	How do I combine CNN and Lstm	8035
6894	Subject 2. Time-series data is a set of observations collected at usually discrete and equally spaced time intervals.  Cross-sectional data are observations that come from different individuals or groups at a single point in time.	What is the difference between trend time series and cross section analysis	6894
10346	The pre-attention phase is an automatic process which happens unconsciously. The second stage is focused attention in which an individual takes all of the observed features and combines them to make a complete perception. This second stage process occurs if the object doesn't stand out immediately.	What are the two stages of processing in the feature integration theory	10346
5767	Data is the currency of applied machine learning.  Resampling is a methodology of economically using a data sample to improve the accuracy and quantify the uncertainty of a population parameter. Resampling methods, in fact, make use of a nested resampling method.	What is resampling in machine learning	5767
8868	"Statistical data binning is a way to group numbers of more or less continuous values into a smaller number of ""bins"". For example, if you have data about a group of people, you might want to arrange their ages into a smaller number of age intervals (for example, grouping every five years together)."	What is data binning in statistics	8868
7046	Temporal Difference is an approach to learning how to predict a quantity that depends on future values of a given signal. It can be used to learn both the V-function and the Q-function, whereas Q-learning is a specific TD algorithm used to learn the Q-function.	Is Q learning temporal difference	7046
3338	The main difference is the one of focus. Data Engineers are focused on building infrastructure and architecture for data generation. In contrast, data scientists are focused on advanced mathematics and statistical analysis on that generated data.  Simply put, data scientists depend on data engineers.	How data engineering is different from data science	3338
3637	The product moment correlation coefficient (pmcc) can be used to tell us how strong the correlation between two variables is. A positive value indicates a positive correlation and the higher the value, the stronger the correlation.  If there is a perfect negative correlation, then r = -1.	What does product moment correlation coefficient mean	3637
7979	Key Takeaways. Standard deviation looks at how spread out a group of numbers is from the mean, by looking at the square root of the variance. The variance measures the average degree to which each point differs from the mean—the average of all data points.	What is standard deviation and variance	7979
4526	In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers. A binary classifier is a function which can decide whether or not an input, represented by a vector of numbers, belongs to some specific class.	What is Perceptron learning algorithm	4526
6790	What is the F-distribution. A probability distribution, like the normal distribution, is means of determining the probability of a set of events occurring. This is true for the F-distribution as well. The F-distribution is a skewed distribution of probabilities similar to a chi-squared distribution.	Is F distribution a normal distribution	6790
1552	"6 Answers. Machine learning algorithms use optimization all the time.  Nonetheless, as mentioned in other answers, convex optimization is faster, simpler and less computationally intensive, so it is often easier to ""convexify"" a problem (make it convex optimization friendly), then use non-convex optimization."	Is convex optimization important for machine learning	1552
5680	A weak classifier is simply a classifier that performs poorly, but performs better than random guessing.  AdaBoost can be applied to any classification algorithm, so it's really a technique that builds on top of other classifiers as opposed to being a classifier itself.	What is weak classifier in AdaBoost	5680
850	K-means clustering algorithm computes the centroids and iterates until we it finds optimal centroid.  In this algorithm, the data points are assigned to a cluster in such a manner that the sum of the squared distance between the data points and centroid would be minimum.	What is K means clustering algorithm explain with an example	850
7851	TL;DR: Entropy is not quantized. Entropy is often stated to be the logarithm of the number of Quantum States accessible to the system.  Entropy is often stated to be the logarithm of the number of Quantum States accessible to the system.	Is entropy quantized	7851
6576	Confusion matrix not only gives you insight into the errors being made by your classifier but also types of errors that are being made. This breakdown helps you to overcomes the limitation of using classification accuracy alone. Every column of the confusion matrix represents the instances of that predicted class.	Why do we need confusion matrix in data mining	6576
5400	A simple linear regression plot for amount of rainfall. Regression analysis is used in stats to find trends in data. For example, you might guess that there's a connection between how much you eat and how much you weigh; regression analysis can help you quantify that.	What is regression analysis example	5400
5620	The coefficient of variation (COV) is a measure of relative event dispersion that's equal to the ratio between the standard deviation and the mean. While it is most commonly used to compare relative risk, the COV may be applied to any type of quantitative likelihood or probability distribution.	Where is coefficient variation used	5620
9428	Cluster analysis divides data into groups (clusters) that are meaningful, useful, or both. If meaningful groups are the goal, then the clusters should capture the natural structure of the data. In some cases, however, cluster analysis is only a useful starting point for other purposes, such as data summarization.	How do you read cluster analysis	9428
10733	Test method. Use the one-sample z-test to determine whether the hypothesized population proportion differs significantly from the observed sample proportion.	What test statistic is used to test a population proportion	10733
2933	In the context of AB testing experiments, statistical significance is how likely it is that the difference between your experiment's control version and test version isn't due to error or random chance.  It's commonly used in business to observe how your experiments affect your business's conversion rates.	What is statistical significance in AB testing	2933
3232	r text-mining natural-language. According the documentation of the removeSparseTerms function from the tm package, this is what sparsity entails: A term-document matrix where those terms from x are removed which have at least a sparse percentage of empty (i.e., terms occurring 0 times in a document) elements.	What is sparsity in document term matrix	3232
7262	The ground-truth bounding boxes (i.e., the hand labeled bounding boxes from the testing set that specify where in the image our object is).	What is ground truth box	7262
3735	Sentiment analysis (also known as opinion mining or emotion AI) refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information.	What is sentiment analysis in natural language processing	3735
6033	Simply put, a random sample is a subset of individuals randomly selected by researchers to represent an entire group as a whole. The goal is to get a sample of people that is representative of the larger population.	What is the main purpose of random sampling	6033
5744	Chi Square distributions are positively skewed, with the degree of skew decreasing with increasing degrees of freedom. As the degrees of freedom increases, the Chi Square distribution approaches a normal distribution.	What is the shape of the chi square distribution	5744
1144	Softmax regression (or multinomial logistic regression) is a generalization of logistic regression to the case where we want to handle multiple classes. In logistic regression we assumed that the labels were binary: y(i)∈{0,1} . We used such a classifier to distinguish between two kinds of hand-written digits.	Is Softmax the same as logistic regression	1144
9776	Definition: A vector space is a set V on which two operations + and · are defined, called vector addition and scalar multiplication. The operation + (vector addition) must satisfy the following conditions: Closure: If u and v are any vectors in V, then the sum u + v belongs to V.	How do you define a vector space	9776
5971	1 : a branch of mathematics dealing with the collection, analysis, interpretation, and presentation of masses of numerical data. 2 : a collection of quantitative data.	What is the simple definition of statistics	5971
435	Multicollinearity causes the following two basic types of problems: The coefficient estimates can swing wildly based on which other independent variables are in the model.  Multicollinearity reduces the precision of the estimate coefficients, which weakens the statistical power of your regression model.	How does Multicollinearity affect the regression model	435
5068	Key Takeaways. Standard deviation defines the line along which a particular data point lies. Z-score indicates how much a given value differs from the standard deviation. The Z-score, or standard score, is the number of standard deviations a given data point lies above or below mean.	What is the difference between AZ score and standard deviation	5068
315	The logit model uses something called the cumulative distribution function of the logistic distribution. The probit model uses something called the cumulative distribution function of the standard normal distribution to define f(∗). Both functions will take any number and rescale it to fall between 0 and 1.	What is logit probit model	315
942	A probability sampling method is any method of sampling that utilizes some form of random selection. In order to have a random selection method, you must set up some process or procedure that assures that the different units in your population have equal probabilities of being chosen.	What is probability sampling technique	942
9325	Mini-batch gradient descent is a variation of the gradient descent algorithm that splits the training dataset into small batches that are used to calculate model error and update model coefficients. Implementations may choose to sum the gradient over the mini-batch which further reduces the variance of the gradient.	What is mini batch stochastic gradient descent	9325
5300	Character N-grams (of at least 3 characters) that are common to words meaning “transport” in the same texts sample in French, Spanish and Greek and their respective frequency.	What is character N grams	5300
5833	The Linear Regression Equation The equation has the form Y= a + bX, where Y is the dependent variable (that's the variable that goes on the Y axis), X is the independent variable (i.e. it is plotted on the X axis), b is the slope of the line and a is the y-intercept.	How do you write a regression model	5833
853	A Kalman Filter is an algorithm that can predict future positions based on current position. It can also estimate current position better than what the sensor is telling us. It will be used to have better association.	How can a Kalman filter be used in computer vision	853
3627	Developers can make use of NLP to perform tasks like speech recognition, sentiment analysis, translation, auto-correct of grammar while typing, and automated answer generation. NLP is a challenging field since it deals with human language, which is extremely diverse and can be spoken in a lot of ways.	What is the scope of NLP	3627
1360	A continuous variable is one which can take on a value between any other two values, such as: indoor temperature, time spent waiting, water consumed, color wavelength, and direction of travel. A discrete variable corresponds to a digital quantity, while a continuous variable corresponds to an analog quantity.	Is time a discrete variable	1360
8313	ProcedureFrom the cluster management console, select Workload > Spark > Deep Learning.Select the Datasets tab.Click New.Create a dataset from Images for Object Classification.Provide a dataset name.Specify a Spark instance group.Specify image storage format, either LMDB for Caffe or TFRecords for TensorFlow.More items	How do you create a dataset of an image	8313
8784	The different types of regression in machine learning techniques are explained below in detail:Linear Regression. Linear regression is one of the most basic types of regression in machine learning.  Logistic Regression.  Ridge Regression.  Lasso Regression.  Polynomial Regression.  Bayesian Linear Regression.	What are the different types of regression	8784
10900	How to Use K-means Cluster Algorithms in Predictive AnalysisPick k random items from the dataset and label them as cluster representatives.Associate each remaining item in the dataset with the nearest cluster representative, using a Euclidean distance calculated by a similarity function.Recalculate the new clusters' representatives.More items	How is K means clustering used in prediction	10900
595	The p-value for each term tests the null hypothesis that the coefficient is equal to zero (no effect). A low p-value (< 0.05) indicates that you can reject the null hypothesis.	How do I interpret p value in logistic regression	595
98	The Monty Hall problem has confused people for decades. In the game show, Let's Make a Deal, Monty Hall asks you to guess which closed door a prize is behind. The answer is so puzzling that people often refuse to accept it! The problem occurs because our statistical assumptions are incorrect.	Why the Monty Hall problem is wrong	98
4517	A major difference is in its shape: the normal distribution is symmetrical, whereas the lognormal distribution is not. Because the values in a lognormal distribution are positive, they create a right-skewed curve.  A further distinction is that the values used to derive a lognormal distribution are normally distributed.	What is the difference between normal and lognormal distribution	4517
9316	If two random variables X and Y are independent, then they are uncorrelated. Proof. Uncorrelated means that their correlation is 0, or, equivalently, that the covariance between them is 0.	How do you prove two variables are uncorrelated	9316
10111	Advantages of Dimensionality Reduction It helps in data compression, and hence reduced storage space. It reduces computation time. It also helps remove redundant features, if any.	Why dimensionality reduction is important step in machine learning	10111
2725	Probability theory is the mathematical study of phenomena characterized by randomness or uncertainty. More precisely, probability is used for modelling situations when the result of an experiment, realized under the same circumstances, produces different results (typically throwing a dice or a coin).	What is probability theory used for	2725
5021	Discriminant analysis is a versatile statistical method often used by market researchers to classify observations into two or more groups or categories. In other words, discriminant analysis is used to assign objects to one group among a number of known groups.	What is discriminant analysis used for	5021
7482	The level of statistical significance is often expressed as a p-value between 0 and 1. The smaller the p-value, the stronger the evidence that you should reject the null hypothesis.  A p-value higher than 0.05 (> 0.05) is not statistically significant and indicates strong evidence for the null hypothesis.	Is the level of significance the same as the P value	7482
8199	Sparse coding is the representation of items by the strong activation of a relatively small set of neurons. For each stimulus, this is a different subset of all available neurons.	What is sparse coding in neural network	8199
2754	NHST is difficult to describe in one sentence, particularly here.	What does Null Hypothesis significance testing NHST mean	2754
4151	The performance of deep learning neural networks often improves with the amount of data available. Data augmentation is a technique to artificially create new training data from existing training data. This means, variations of the training set images that are likely to be seen by the model.	What is augmentation in deep learning	4151
5491	If your data contains both numeric and categorical variables, the best way to carry out clustering on the dataset is to create principal components of the dataset and use the principal component scores as input into the clustering.	Can you use categorical variables in clustering	5491
3994	If all of the values in the sample are identical, the sample standard deviation will be zero. When discussing the sample mean, we found that the sample mean for diastolic blood pressure was 71.3.	Can a sample mean be zero	3994
8665	There is a good reason why accuracy is not an appropriate measure for information retrieval problems. In almost all circumstances, the data is extremely skewed: normally over 99.9% of the documents are in the nonrelevant category.	Why accuracy is not used as a preferred method for real world IR system evaluation	8665
8501	Padding is a term relevant to convolutional neural networks as it refers to the amount of pixels added to an image when it is being processed by the kernel of a CNN. For example, if the padding in a CNN is set to zero, then every pixel value that is added will be of value zero.	What is padding in deep learning	8501
5909	resample Function One resampling application is the conversion of digitized audio signals from one sample rate to another, such as from 48 kHz (the digital audio tape standard) to 44.1 kHz (the compact disc standard).  resample applies a lowpass filter to the input sequence to prevent aliasing during resampling.	What is resampling in signal processing	5909
5350	In computer science and engineering, a test vector is a set of inputs provided to a system in order to test that system. In software development, test vectors are a methodology of software testing and software verification and validation.	What is input vector	5350
236	An easy guide to choose the right Machine Learning algorithmSize of the training data. It is usually recommended to gather a good amount of data to get reliable predictions.  Accuracy and/or Interpretability of the output.  Speed or Training time.  Linearity.  Number of features.	Which algorithm is right for machine learning	236
1002	Just multiply the probability of the first event by the second. For example, if the probability of event A is 2/9 and the probability of event B is 3/9 then the probability of both events happening at the same time is (2/9)*(3/9) = 6/81 = 2/27.	How do you find the probability of multiple events	1002
4449	To format the size of data points in a scatter plot graph, right click any of the data points and select 'format data series' then select marker options and customize for larger or smaller data points.	How do you make the dots on a scatter plot bigger	4449
6445	A common problem in machine learning is sparse data, which alters the performance of machine learning algorithms and their ability to calculate accurate predictions. Data is considered sparse when certain expected values in a dataset are missing, which is a common phenomenon in general large scaled data analysis.	What is sparse data in machine learning	6445
5550	Regression: This is a tool used to evaluate the relationship of a dependent variable in relation to multiple independent variables. A regression will analyze the mean of the dependent variable in relation to changes in the independent variables. Time Series: A time series measures data over a specific period of time.	What is the difference between time series and regression	5550
4621	Consider statistics as a problem-solving process and examine its four components: asking questions, collecting appropriate data, analyzing the data, and interpreting the results. This session investigates the nature of data and its potential sources of variation. Variables, bias, and random sampling are introduced.	What is the statistical problem solving process	4621
4859	Eigenanalysis is a mathematical operation on a square, symmetric matrix. A square matrix has the same number of rows as columns. A symmetric matrix is the same if you switch rows and columns. Distance and similarity matrices are nearly always square and symmetric.	What is Eigen analysis	4859
3241	Simply put, homoscedasticity means “having the same scatter.” For it to exist in a set of data, the points must be about the same distance from the line, as shown in the picture above. The opposite is heteroscedasticity (“different scatter”), where points are at widely varying distances from the regression line.	What does Homoscedasticity mean in regression	3241
4673	If you have both a response variable and an explanatory variable, the explanatory variable is always plotted on the x-axis (the horizontal axis). The response variable is always plotted on the y-axis (the vertical axis).	How do you know which is the explanatory variable	4673
10159	Approach –Load dataset from source.Split the dataset into “training” and “test” data.Train Decision tree, SVM, and KNN classifiers on the training data.Use the above classifiers to predict labels for the test data.Measure accuracy and visualise classification.	How do you do multi class classification	10159
3397	Here are some important considerations while choosing an algorithm.Size of the training data. It is usually recommended to gather a good amount of data to get reliable predictions.  Accuracy and/or Interpretability of the output.  Speed or Training time.  Linearity.  Number of features.	How can I choose among classification algorithms to work with	3397
2527	Genetic algorithms are stochastic search algorithms which act on a population of possible solutions.  Genetic algorithms are used in artificial intelligence like other search algorithms are used in artificial intelligence — to search a space of potential solutions to find one which solves the problem.	Are genetic algorithms artificial intelligence	2527
4730	Taguchi loss function formulaL is the loss function.y is the value of the characteristic you are measuring (e.g. length of product)m is the value you are aiming for (in our example, perfect length for the product)k is a proportionality constant (i.e. just a number)	How is Taguchi quality loss function calculated	4730
9386	Exploratory Data Analysis is one of the important steps in the data analysis process.  Exploratory Data Analysis is a crucial step before you jump to machine learning or modeling of your data. It provides the context needed to develop an appropriate model – and interpret the results correctly.	Why do we need to perform exploratory data analysis	9386
6448	Fortunately, hinge loss, logistic loss and square loss are all convex functions. Convexity ensures global minimum and it's computationally appleaing.	Is squared loss convex	6448
1433	The input nodes take in information, in the form which can be numerically expressed. The information is presented as activation values, where each node is given a number, the higher the number, the greater the activation.  The output nodes then reflect the input in a meaningful way to the outside world.	What is an activation value *	1433
92	Spreading activation is a method for searching associative networks, biological and artificial neural networks, or semantic networks.  Spreading activation can also be applied in information retrieval, by means of a network of nodes representing documents and terms contained in those documents.	How does activation spread through a semantic network	92
651	Examples of Artificial Intelligence: Work & School1 – Google's AI-Powered Predictions.  2 – Ridesharing Apps Like Uber and Lyft.  3 — Commercial Flights Use an AI Autopilot.1 – Spam Filters.2 – Smart Email Categorization.1 –Plagiarism Checkers.  2 –Robo-readers.  1 – Mobile Check Deposits.More items•	What are some applications of AI in real life	651
5488	There are two main ways to access subsets of the elements in a tensor, either of which should work for your example.Use the indexing operator (based on tf. slice() ) to extract a contiguous slice from the tensor. input = tf.  Use the tf. gather() op to select a non-contiguous slice from the tensor. input = tf.	How do I find the value of Tensor	5488
8331	"The sampling distribution of the sample mean can be thought of as ""For a sample of size n, the sample mean will behave according to this distribution."" Any random draw from that sampling distribution would be interpreted as the mean of a sample of n observations from the original population."	What does a sampling distribution of sample means represent	8331
3304	The determinant is related to the volume of the space occupied by the swarm of data points represented by standard scores on the measures involved.  When the measures are correlated, the space occupied becomes an ellipsoid whose volume is less than 1.	What does the determinant of the correlation matrix represent	3304
10691	0:041:23Suggested clip · 72 secondsQuick Example - Find the Area to the Right Of a Z-Score - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How is technology used to find the area to the right of Z	10691
7508	• A random process is a time-varying function that assigns the outcome of a random experiment to each time instant: X(t). • For a fixed (sample path): a random process is a time varying function, e.g., a signal.	What is random process in communication	7508
3409	Basically, it takes between 365 days (1 year) to 1,825 days (5 years) to learn artificial intelligence (assuming you put in 4 – 0.5 learning hours a day). And how fast you learn also affects how long it takes you to be an expert.	How long does it take to learn artificial intelligence	3409
4637	An autoregressive integrated moving average, or ARIMA, is a statistical analysis model that uses time series data to either better understand the data set or to predict future trends.	What are some applications of the Autoregressive integrated moving average ARIMA model	4637
2816	All descriptive statistics are either measures of central tendency or measures of variability, also known as measures of dispersion.  Range, quartiles, absolute deviation and variance are all examples of measures of variability. Consider the following data set: 5, 19, 24, 62, 91, 100.	What is an example of a descriptive statistic	2816
3929	The total number of contravariant and covariant indices of a tensor. The rank of a tensor is independent of the number of dimensions. of the underlying space.	What is tensor rank	3929
9960	Tensors are simply mathematical objects that can be used to describe physical properties, just like scalars and vectors. In fact tensors are merely a generalisation of scalars and vectors; a scalar is a zero rank tensor, and a vector is a first rank tensor.	What is meant by a tensor	9960
4328	Generative adversarial nets can be applied in many fields from generating images to predicting drugs, so don't be afraid of experimenting with them. We believe they help in building a better future for machine learning.	What are generative adversarial networks used for	4328
8271	the state of being likely or probable; probability. a probability or chance of something: There is a strong likelihood of his being elected.	What is meant by likelihood	8271
10351	Canonical discriminant analysis is a dimension-reduction technique related to principal component analysis and canonical correlation.  This maximal multiple correlation is called the first canonical correlation. The coefficients of the linear combination are the canonical coefficients or canonical weights.	What is canonical discriminant analysis	10351
2032	Entropy can be calculated for a random variable X with k in K discrete states as follows: H(X) = -sum(each k in K p(k) * log(p(k)))	How do you calculate entropy of information	2032
3839	Word2Vec can be used to get actionable metrics from thousands of customers reviews. Businesses don't have enough time and tools to analyze survey responses and act on them thereon. This leads to loss of ROI and brand value. Word embeddings prove invaluable in such cases.	Where is Word2Vec used	3839
7996	This is the “q-value.” A p-value of 5% means that 5% of all tests will result in false positives. A q-value of 5% means that 5% of significant results will result in false positives.	How do you interpret Q values	7996
9045	In statistics, a positively skewed (or right-skewed) distribution is a type of distribution in which most values are clustered around the left tail of the distribution while the right tail of the distribution is longer.	What does it mean when data is positively skewed	9045
2336	Normalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values. For machine learning, every dataset does not require normalization.	Does normalization improve performance machine learning	2336
10458	2:316:15Suggested clip · 118 secondsUnit Conversion the Easy Way (Dimensional Analysis) - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you convert dimensional analysis	10458
223	Multi-task learning (MTL) is a subfield of machine learning in which multiple learning tasks are solved at the same time, while exploiting commonalities and differences across tasks.  In the classification context, MTL aims to improve the performance of multiple classification tasks by learning them jointly.	What is multi task learning in machine learning	223
7707	The MSE is a measure of the quality of an estimator—it is always non-negative, and values closer to zero are better.  For an unbiased estimator, the MSE is the variance of the estimator. Like the variance, MSE has the same units of measurement as the square of the quantity being estimated.	Is MSE equal to variance	7707
7004	4:026:15Suggested clip · 93 secondsFinding the Test Statistic for a Wilcoxon Rank Sum Test in  - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you solve the Wilcoxon rank sum test	7004
6961	"if p is a statement variable, the negation of p is ""not p"", denoted by ~p. If p is true, then ~p is false. Conjunction: if p and q are statement variables, the conjunction of p and q is ""p and q"", denoted p q.(p q) ~(p q) p xor qExclusive Orp ~(~p)Double Negation"	What is logically equivalent to P or Q	6961
10438	The difference between combinations and permutations is ordering. With permutations we care about the order of the elements, whereas with combinations we don't. For example, say your locker “combo” is 5432. If you enter 4325 into your locker it won't open because it is a different ordering (aka permutation).	How do you know when to use a permutation instead of a combination	10438
2394	to safeguard against the researcher problem of experimenter bias, researchers employ blind observers, single and double blind study, and placebos. to control for ethnocentrism, they use cross cultural sampling.	What are two methods researchers use to avoid experimenter bias	2394
4089	In ordinary least squares, the relevant assumption of the classical linear regression model is that the error term is uncorrelated with the regressors. The presence of omitted-variable bias violates this particular assumption. The violation causes the OLS estimator to be biased and inconsistent.	Which assumption does omitted variable bias violate	4089
6231	0:012:32Suggested clip · 101 secondsMultiple Logistic Regression - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you do multiple logistic regression	6231
10025	Artificial General Intelligence	What does AGI stand for in artificial intelligence	10025
2168	Cross tabulationCross tabulations require that the two data columns be adjacent. You can drag columns by selecting them, and moving the cursor so it's immediately between two columns.  Once you have the columns adjacent, select both of them including the variable names all the way to the bottom.	How do you do cross tabulation	2168
1363	"Factor analysis is as much of a ""test"" as multiple regression (or statistical tests in general) in that it is used to reveal hidden or latent relationships/groupings in one's dataset.  Multiple regression takes data points in some n-dimensional space and finds the best fit line."	How is factor analysis different from multiple regression	1363
8611	When someone talks about AR, they are referring to technology that overlays information and virtual objects on real-world scenes in real-time. It uses the existing environment and adds information to it to make a new artificial environment.	What is augmented reality used for	8611
2218	They provide a natural way to handle missing data, they allow combination of data with domain knowledge, they facilitate learning about causal relationships between variables, they provide a method for avoiding overfitting of data (Heckerman, 1995), they can show good prediction accuracy even with rather small sample	What are the advantages of Bayesian networks	2218
3386	Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on. If your training/validation loss are about equal then your model is underfitting. Increase the size of your model (either number of layers or the raw number of neurons per layer)	How do neural networks reduce loss	3386
4446	"To put simply, likelihood is ""the likelihood of θ having generated D"" and posterior is essentially ""the likelihood of θ having generated D"" further multiplied by the prior distribution of θ."	What is the difference between likelihood function and posterior probability	4446
4565	Adding more training data.Reducing parameters. We have too many neurons in our hidden layers or too many layers. Let's remove some layers, or reduce the number of hidden neurons.Increase regularization. Either by increasing our. for L1/L2 weight regularization. We can also use dropout the technique.	Why and what to do when neural networks perform poorly on the training set	4565
3590	Learning involves far more than thinking: it involves the whole personality - senses, feelings, intuition, beliefs, values and will.  Learning occurs when we are able to: Gain a mental or physical grasp of the subject. Make sense of a subject, event or feeling by interpreting it into our own words or actions.	What is learning and how do we learn	3590
2048	EM is an iterative method which alternates between two steps, expectation (E) and maximization (M). For clustering, EM makes use of the finite Gaussian mixtures model and estimates a set of parameters iteratively until a desired convergence value is achieved.	What is Expectation Maximization clustering	2048
801	Simple logistic regression analysis refers to the regression application with one dichotomous outcome and one independent variable; multiple logistic regression analysis applies when there is a single dichotomous outcome and more than one independent variable.	What does multiple logistic regression mean	801
7240	Tokenization is one of the most common tasks when it comes to working with text data.  Tokenization is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called tokens.	What is tokenization NLP	7240
10936	"Click on the triangle-shaped icon located at the top right corner of the panel, and then choose ""Save Path"". Next, select ""Clipping Path"" from the same drop-down menu. A new dialog box will appear with a variety of clipping path settings. Make sure your path is selected, and then click OK."	How do you do a clipping path	10936
4657	It's a form of machine learning and therefore a branch of artificial intelligence. Depending on the complexity of the problem, reinforcement learning algorithms can keep adapting to the environment over time if necessary in order to maximize the reward in the long-term.	Is reinforcement learning AI	4657
10359	Independent EventsTwo events A and B are said to be independent if the fact that one event has occurred does not affect the probability that the other event will occur.If whether or not one event occurs does affect the probability that the other event will occur, then the two events are said to be dependent.	How do you know if an event is independent or dependent	10359
4185	While statistical significance relates to whether an effect exists, practical significance refers to the magnitude of the effect. However, no statistical test can tell you whether the effect is large enough to be important in your field of study.  An effect of 4 points or less is too small to care about.	How might a statistical test be statistically significant but not practical	4185
5598	When there is lack of domain understanding for feature introspection , Deep Learning techniques outshines others as you have to worry less about feature engineering . Deep Learning really shines when it comes to complex problems such as image classification, natural language processing, and speech recognition.	Why should I learn deep learning	5598
9903	Linear discriminant analysis (LDA) is one of commonly used supervised subspace learning methods.  The objective optimization is in both the ratio trace and the trace ratio forms, forming a complete framework of a new approach to jointly clustering and unsupervised subspace learning.	Is linear discriminant analysis supervised or unsupervised	9903
3410	Communalities – This is the proportion of each variable's variance that can be explained by the factors (e.g., the underlying latent continua). It is also noted as h2 and can be defined as the sum of squared factor loadings for the variables.  They are the reproduced variances from the factors that you have extracted.	What does Communalities mean in factor analysis	3410
4891	Non-linearity in neural networks simply mean that the output at any unit cannot be reproduced from a linear function of the input.	What is nonlinearity in neural networks	4891
10929	"Stochastic Gradient Descent: you would randomly select one of those training samples at each iteration to update your coefficients. Online Gradient Descent: you would use the ""most recent"" sample at each iteration. There is no stochasticity as you deterministically select your sample."	Difference between stochastic gradient descent and online learning	10929
4645	The first method involves the conditional distribution of a random variable X2 given X1. Therefore, a bivariate normal distribution can be simulated by drawing a random variable from the marginal normal distribution and then drawing a second random variable from the conditional normal distribution.	How do you create a bivariate normal distribution	4645
5402	In a crossover network, resistors are usually used in combination with other components to control either impedance magnitudes or the relative levels between different drivers in a system.	What does a resistor do in a crossover	5402
7065	A regression equation is used in stats to find out what relationship, if any, exists between sets of data. For example, if you measure a child's height every year you might find that they grow about 3 inches a year. That trend (growing three inches a year) can be modeled with a regression equation.	What does a regression equation tell you	7065
8989	Optimal control focuses on a subset of problems, but solves these problems very well, and has a rich history. RL can be thought of as a way of generalizing or extending ideas from optimal control to non-traditional control problems.	What is the difference between optimal control theory and reinforcement learning	8989
2559	Random forests perform well for multi-class object detection and bioinformatics, which tends to have a lot of statistical noise. Gradient Boosting performs well when you have unbalanced data such as in real time risk assessment.	Why is gradient boosting better than random forest	2559
6230	In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.	What is the difference between supervised and unsupervised learning	6230
7949	PD analysis is a method used by larger institutions to calculate their expected loss. A PD is assigned to each risk measure and represents as a percentage the likelihood of default.  LGD represents the amount unrecovered by the lender after selling the underlying asset if a borrower defaults on a loan.	What is PD and LGD	7949
10681	Instance-based methods are sometimes referred to as lazy learning methods because they delay processing until a new instance must be classified. The nearest neighbors of an instance are defined in terms of Euclidean distance.	Why instance based learning is called as lazy learning	10681
5395	Other ways of avoiding experimenter's bias include standardizing methods and procedures to minimize differences in experimenter-subject interactions; using blinded observers or confederates as assistants, further distancing the experimenter from the subjects; and separating the roles of investigator and experimenter.	How do you get rid of experimenter bias	6749
7455	The normal distribution is the most important probability distribution in statistics because it fits many natural phenomena. For example, heights, blood pressure, measurement error, and IQ scores follow the normal distribution. It is also known as the Gaussian distribution and the bell curve.	Why data should be normally distributed	7455
7550	An image histogram is a type of histogram that acts as a graphical representation of the tonal distribution in a digital image. It plots the number of pixels for each tonal value.  The vertical axis represents the size of the area (total number of pixels) that is captured in each one of these zones.	What is a histogram in image processing	7550
4074	conditions—Random, Normal, and Independent—is. important when constructing a confidence interval.	What are the three conditions for constructing a confidence interval for the population mean	4074
3990	Regression trees are used in Statistics, Data Mining and Machine learning. It is a very important and powerful technique when it comes to predictive analysis [5] . The goal is to predict the value of target variable on the basis of several input attributes that act as nodes of the regression tree.	Which type of data is often Modelled using regression trees	3990
10839	The C parameter trades off misclassification of training examples against simplicity of the decision surface. A low C makes the decision surface smooth, while a high C aims at classifying all training examples correctly by giving the model freedom to select more samples as support vectors.	Which parameter in SVM is responsible for tradeoff between misclassification and simplicity of model	10839
3654	Average-linkage is where the distance between each pair of observations in each cluster are added up and divided by the number of pairs to get an average inter-cluster distance. Average-linkage and complete-linkage are the two most popular distance metrics in hierarchical clustering.	How does Average Linkage work in Hierarchical Agglomerative clustering	3654
9670	Each is essentially a component of the prior term. That is, machine learning is a subfield of artificial intelligence. Deep learning is a subfield of machine learning, and neural networks make up the backbone of deep learning algorithms.	Is neural network a part of machine learning	9670
9411	Data visualization refers to the techniques used to communicate data or information by encoding it as visual objects (e.g., points, lines or bars) contained in graphics. The goal is to communicate information clearly and efficiently to users. It is one of the steps in data analysis or data science.	What is data visualization and its techniques	9411
6623	A data distribution is a function or a listing which shows all the possible values (or intervals) of the data. It also (and this is important) tells you how often each value occurs.	What does a distribution tell us about a set of data	6623
10089	The correlation coefficient is a measure of the degree of linear association between two continuous variables, i.e. when plotted together, how close to a straight line is the scatter of points.  Both x and y must be continuous random variables (and Normally distributed if the hypothesis test is to be valid).	For correlation coefficient between two random variables to be a meaningful measure of their linear association do the variables need to be normally distributed	10089
4684	A stochastic process is a family of random variables {Xθ}, where the parameter θ is drawn from an index set Θ. For example, let's say the index set is “time”.  One example of a stochastic process that evolves over time is the number of customers (X) in a checkout line.	What is a stochastic process provide an example	4684
7789	The covariance between X and Y is defined as Cov(X,Y)=E[(X−EX)(Y−EY)]=E[XY]−(EX)(EY).The covariance has the following properties:Cov(X,X)=Var(X);if X and Y are independent then Cov(X,Y)=0;Cov(X,Y)=Cov(Y,X);Cov(aX,Y)=aCov(X,Y);Cov(X+c,Y)=Cov(X,Y);Cov(X+Y,Z)=Cov(X,Z)+Cov(Y,Z);more generally,	How do you find the covariance of a random variable	7789
5966	The chi-square distribution curve is skewed to the right, and its shape depends on the degrees of freedom df. For df > 90, the curve approximates the normal distribution. Test statistics based on the chi-square distribution are always greater than or equal to zero.	What is the basic shape of the chi square distribution	5966
4971	The Gini coefficient for the entire world has been estimated by various parties to be between 0.61 and 0.68.	What is the average Gini coefficient	4971
836	R-squared should accurately reflect the percentage of the dependent variable variation that the linear model explains. Your R2 should not be any higher or lower than this value.  However, if you analyze a physical process and have very good measurements, you might expect R-squared values over 90%.	What is an acceptable R squared value	836
3701	"The decision rule is: Reject H0 if Z < 1.645. The decision rule is: Reject H0 if Z < -1.960 or if Z > 1.960. The complete table of critical values of Z for upper, lower and two-tailed tests can be found in the table of Z values to the right in ""Other Resources."""	What is the rule for rejecting Ho in terms of Z	3701
576	Suggest Edits. Support Vector Machines (SVMs) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.	What is a linear SVM	576
1412	Unsupervised learning is the Holy Grail of Deep Learning. The goal of unsupervised learning is to create general systems that can be trained with little data.  Today Deep Learning models are trained on large supervised datasets. Meaning that for each data, there is a corresponding label.	Can deep learning be unsupervised	1412
2030	1:1111:18Suggested clip · 91 secondsLimits of Functions of Two Variables - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you find the limit of a function with two variables	2030
3475	Text classification using word embeddings and deep learning in python — classifying tweets from twitterSplit the data into text (X) and labels (Y)Preprocess X.Create a word embedding matrix from X.Create a tensor input from X.Train a deep learning model using the tensor inputs and labels (Y)More items•	How do I use Word embeds for text classification	3475
2276	Gaussian Distribution Function The nature of the gaussian gives a probability of 0.683 of being within one standard deviation of the mean. The mean value is a=np where n is the number of events and p the probability of any integer value of x (this expression carries over from the binomial distribution ).	What is the mean of a Gaussian distribution	2276
6268	Dimensional Analysis (also called Factor-Label Method or the Unit Factor Method) is a problem-solving method that uses the fact that any number or expression can be multiplied by one without changing its value. It is a useful technique.	What is dimensional analysis and how do we use it	6268
5679	Just so, the Poisson distribution deals with the number of occurrences in a fixed period of time, and the exponential distribution deals with the time between occurrences of successive events as time flows by continuously.	What is the relationship between Poisson and exponential distribution	5679
3000	Regression analysis is used when you want to predict a continuous dependent variable from a number of independent variables. If the dependent variable is dichotomous, then logistic regression should be used.	Which method is used for predicting continuous dependent variable	3000
2510	The second derivative may be used to determine local extrema of a function under certain conditions. If a function has a critical point for which f′(x) = 0 and the second derivative is positive at this point, then f has a local minimum here.  This technique is called Second Derivative Test for Local Extrema.	Why do you use the second derivative test	2510
10650	With cluster sampling, in contrast, the sample includes elements only from sampled clusters. Multistage sampling. With multistage sampling, we select a sample by using combinations of different sampling methods. For example, in Stage 1, we might use cluster sampling to choose clusters from a population.	What is the difference between cluster and multistage sampling	10650
4692	In statistics a minimum-variance unbiased estimator (MVUE) or uniformly minimum-variance unbiased estimator (UMVUE) is an unbiased estimator that has lower variance than any other unbiased estimator for all possible values of the parameter.	What is minimum variance of an estimator	4692
5639	Do not confuse statistical significance with practical importance.  However, a weak correlation can be statistically significant, if the sample size is large enough.	Can a weak correlation be significant	5639
6225	In active learning teachers are facilitators rather than one way providers of information.  Other examples of active learning techniques include role-playing, case studies, group projects, think-pair-share, peer teaching, debates, Just-in-Time Teaching, and short demonstrations followed by class discussion.	What is an example of active learning	6225
3428	Overfitting is a modeling error that occurs when a function is too closely fit to a limited set of data points.  Thus, attempting to make the model conform too closely to slightly inaccurate data can infect the model with substantial errors and reduce its predictive power.	What is meant by Overfitting of data	3428
10878	ELIZA is an early natural language processing computer program created from 1964 to 1966 at the MIT Artificial Intelligence Laboratory by Joseph Weizenbaum.  As such, ELIZA was one of the first chatterbots and one of the first programs capable of attempting the Turing test.	What is Eliza in artificial intelligence	10878
5880	The Sobel filter is used for edge detection. It works by calculating the gradient of image intensity at each pixel within the image. It finds the direction of the largest increase from light to dark and the rate of change in that direction.	How do Sobel filters work	5880
6904	A term-document matrix represents the processed text from a text analysis as a table or matrix where the rows represent the text responses, or documents, and the columns represent the words or phrases (the terms).  matrix).	What is text Matrix	6904
10368	Non-probability sampling is often used because the procedures used to select units for inclusion in a sample are much easier, quicker and cheaper when compared with probability sampling. This is especially the case for convenience sampling.	Why do we use non probability sampling	10368
10989	R is now used by over 50% of data miners. R, Python, and SQL were the most popular programming languages. Python, Lisp/Clojure, and Unix tools showest the highest growth in 2012, while Java and MATLAB slightly declined in popularity.	What language is used for data mining	10989
3321	A tensor is a quantity, for example a stress or a strain, which has magnitude, direction, and a plane in which it acts. Stress and strain are both tensor quantities.  A tensor is a quantity, for example a stress or a strain, which has magnitude, direction, and a plane in which it acts.	What is tensor quantity	3321
5854	Stochastic Gradient Descent (SGD) is a simple yet very efficient approach to fitting linear classifiers and regressors under convex loss functions such as (linear) Support Vector Machines and Logistic Regression.	Is stochastic gradient descent linear	5854
6059	The CAC ratio is calculated by looking at the quarter over quarter increase in gross margin divided by the total sales and marketing expenses for that quarter. Gross margin is the total revenue minus cost of goods sold.	How is CAC ratio calculated	6059
3468	The experts predict that AI will outperform humans in the next 10 years in tasks such as translating languages (by 2024), writing high school essays (by 2026), and driving trucks (by 2027). But many other tasks will take much longer for machines to master.	Will artificial intelligence supersede human intelligence	3468
8769	Whereas AI is preprogrammed to carry out a task that a human can but more efficiently, artificial general intelligence (AGI) expects the machine to be just as smart as a human.  A machine that was able to do this would be considered a fine example of AGI.	What is the difference between general artificial intelligence and artificial intelligence	8769
1904	Any point directly on the y-axis has an X value of 0. Multiple Choice: In a simple Linear regression problem, r and b1. Explanation: r= correlation coefficient and b1= slope. If we have a downward sloping trend-line then that means we have a negative (or inverse) correlation coefficient.	What is the relationship between the linear correlation coefficient r and the slope b 1 of a regression line	1904
10500	The name tells you how to calculate it. You subtract the regression-predicted values from the actual values, square them (to get rid of directionality), take their average, then take the square root of the average.	How do you evaluate the accuracy of a regression result	10500
7171	Gradient Descent is the process of minimizing a function by following the gradients of the cost function. This involves knowing the form of the cost as well as the derivative so that from a given point you know the gradient and can move in that direction, e.g. downhill towards the minimum value.	What is gradient descent in logistic regression	7171
883	Poisson Formula. Suppose we conduct a Poisson experiment, in which the average number of successes within a given region is μ. Then, the Poisson probability is: P(x; μ) = (e-μ) (μx) / x! where x is the actual number of successes that result from the experiment, and e is approximately equal to 2.71828.	How do you find the probability of a Poisson distribution	883
4282	Advantages of distributed representations Mapping efficiency: a micro-feature-based distributed representation often allows a simple mapping (that uses few connections or weights) to solve a task. For example, suppose we wish to classify 100 different colored shapes as to whether or not they are yellow.	What are the advantages of distributed representations	4282
7863	As Justin Rising points out, the order statistics are clearly not independent of each other. . If the observations are independent and identically distributed from a continuous distribution, then any ordering of the samples is equally likely.	Are the order statistics independent	7863
7549	The value to be gained from taking a decision. Net gain is calculated by adding together the expected value of each outcome and deducting the costs associated with the decision.	How do you calculate decision trees	7549
7019	How to Deal with MulticollinearityRemove some of the highly correlated independent variables.Linearly combine the independent variables, such as adding them together.Perform an analysis designed for highly correlated variables, such as principal components analysis or partial least squares regression.	How can Multicollinearity be reduced	7019
6787	Each party in a dispute recognises that its own use of the concept is contested by those of other parties. To use an essentially contested concept means to use it against other users. To use such a concept means to use it aggresssively and defensively.	What is contested concept	6787
8419	Use. Cluster sampling is typically used in market research. It's used when a researcher can't get information about the population as a whole, but they can get information about the clusters.  Cluster sampling is often more economical or more practical than stratified sampling or simple random sampling.	Why do we use cluster sampling	8419
1003	0:082:33Suggested clip · 117 secondsHistogram Finding Frequency - Corbettmaths - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you read a relative frequency density histogram	1003
485	It is linear if there exists a function H(x) = β0 + βT x such that h(x) = I(H(x) > 0). H(x) is also called a linear discriminant function. The decision boundary is therefore defined as the set {x ∈ Rd : H(x)=0}, which corresponds to a (d − 1)-dimensional hyperplane within the d-dimensional input space X.	What are the decision boundaries for linear discriminant analysis	485
10610	A good knowledge representation system must have properties such as: Representational Accuracy: It should represent all kinds of required knowledge. Inferential Adequacy: It should be able to manipulate the representational structures to produce new knowledge corresponding to the existing structure.	What are the properties of good knowledge representation techniques	10610
9312	The example of reinforcement learning is your cat is an agent that is exposed to the environment. The biggest characteristic of this method is that there is no supervisor, only a real number or reward signal. Two types of reinforcement learning are 1) Positive 2) Negative.	What is reinforcement learning example	9312
8393	Unsupervised Learning is the second type of machine learning, in which unlabeled data are used to train the algorithm, which means it used against data that has no historical labels.	What category of machine learning algorithm finds patterns in the data when the data is not labeled	8393
2875	Convolutional Neural Networks (CNNs) is the most popular neural network model being used for image classification problem. The big idea behind CNNs is that a local understanding of an image is good enough.	What type of deep learning models are best suited for image recognition	2875
9500	Pre-Interview PreparationDevelop a deep knowledge of data structures. You should understand and be able to talk about different data structures and their strengths, weaknesses, and how they compare to each other.  Understand Big O notation.  Know the major sorting algorithms.	How do I start preparing for data structures and algorithms	9500
8763	The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output. Since probability of anything exists only between the range of 0 and 1, sigmoid is the right choice. The function is differentiable.	Why do we use sigmoid function	8763
3618	Streaming Data is data that is generated continuously by thousands of data sources, which typically send in the data records simultaneously, and in small sizes (order of Kilobytes).	What does streaming data mean	3618
3467	- Mode-The most repetitive number! - Median:The number in the MIDDLE when they are IN ORDER! - Mean- The AVERAGE OF ALL NUMBERS: You add up all the numbers then you divide it by the TOTAL NUMBER of NUMBERS! - Range - THE BIGGEST minus the Smallest!	What is the purpose of mean median mode and range	3467
9161	The standard deviation of the sample mean ˉX that we have just computed is the standard deviation of the population divided by the square root of the sample size: √10=√20/√2.	What is the formula for the standard deviation of the sampling distribution of the sample mean X	9161
10803	Causation explicitly applies to cases where action A {quote:right}Causation explicitly applies to cases where action A causes outcome B. {/quote} causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B—but one event doesn't necessarily cause the other event to happen.	How do you tell the difference between correlation and causation	10803
7467	Categories with a large difference between observed and expected values make a larger contribution to the overall chi-square statistic. In these results, the contribution values from each category sum to the overall chi-square statistic, which is 0.65.	What is the contribution to the chi square statistic	7467
3179	A statistical hypothesis is a formal claim about a state of nature structured within the framework of a statistical model. For example, one could claim that the median time to failure from (acce]erated) electromigration of the chip population described in Section 6.1.	What is a statistical hypothesis example	3179
2710	In this blog we will learn what is calibration and why and when we should use it. We calibrate our model when the probability estimate of a data point belonging to a class is very important. Calibration is comparison of the actual output and the expected output given by a system.	Why do we need calibration in machine learning	2710
8623	Standard deviation (represented by the symbol sigma, σ ) shows how much variation or dispersion exists from the average (mean), or expected value. More precisely, it is a measure of the average distance between the values of the data in the set and the mean.	How do you explain standard deviation in statistics	8623
2414	So the difference is in the way the future reward is found. In Q-learning it's simply the highest possible action that can be taken from state 2, and in SARSA it's the value of the actual action that was taken.	What is the difference between Q learning and Sarsa	2414
6338	Fixed effects are variables that are constant across individuals; these variables, like age, sex, or ethnicity, don't change or change at a constant rate over time. They have fixed effects; in other words, any change they cause to an individual is the same.	What does fixed effect mean in statistics	6338
5561	The number of outcomes in non-overlapping intervals are independent.   The probability of two or more outcomes in a sufficiently short interval is virtually zero.   The probability of exactly one outcome in a sufficiently short interval or small region is proportional to the length of the interval or region.	How do I know if my data is Poisson distributed	5561
1993	A Bayesian network (also known as a Bayes network, belief network, or decision network) is a probabilistic graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG).  Efficient algorithms can perform inference and learning in Bayesian networks.	What does Bayesian networks mean in Machine Learning	1993
494	Definition. In machine learning, model validation is referred to as the process where a trained model is evaluated with a testing data set. The testing data set is a separate portion of the same data set from which the training set is derived.  Model validation is carried out after model training.	What is validation in machine learning	494
10372	Edge detection is an image processing technique for finding the boundaries of objects within images. It works by detecting discontinuities in brightness. Edge detection is used for image segmentation and data extraction in areas such as image processing, computer vision, and machine vision.	Why do we need edge detection	10372
2642	Using P values and Significance Levels Together If your P value is less than or equal to your alpha level, reject the null hypothesis. The P value results are consistent with our graphical representation. The P value of 0.03112 is significant at the alpha level of 0.05 but not 0.01.	Is the P value the same as Alpha	2642
7025	A GLM is absolutely a statistical model, but statistical models and machine learning techniques are not mutually exclusive. In general, statistics is more concerned with inferring parameters, whereas in machine learning, prediction is the ultimate goal.	Are generalized linear models statistical methods or machine learning methods	7025
2643	We input the data in the learning algorithm as a set of inputs, which is called as Features, denoted by X along with the corresponding outputs, which is indicated by Y, and the algorithm learns by comparing its actual production with correct outputs to find errors. It then modifies the model accordingly.	What data would be used as input to the machine learning algorithms	2643
484	Kappa is widely used on Twitch in chats to signal you are being sarcastic or ironic, are trolling, or otherwise playing around with someone. It is usually typed at the end of a string of text, but, as can often the case on Twitch, it is also often used on its own or repeatedly (to spam someone).	What is Kappa used for	484
10296	When q-learning is performed we create what's called a q-table or matrix that follows the shape of [state, action] and we initialize our values to zero. We then update and store our q-values after an episode. This q-table becomes a reference table for our agent to select the best action based on the q-value.	What does the Q table in Q learning algorithm represent	10296
70	A commonly used rule says that a data point is an outlier if it is more than 1.5 ⋅ IQR 1.5\cdot \text{IQR} 1. 5⋅IQR1, point, 5, dot, start text, I, Q, R, end text above the third quartile or below the first quartile.	How do you determine if there are outliers in a data set	70
9735	Randomization as a method of experimental control has been extensively used in human clinical trials and other biological experiments. It prevents the selection bias and insures against the accidental bias. It produces the comparable groups and eliminates the source of bias in treatment assignments.	Why is it important to randomise participants in a study	9735
5556	Two-sample t-test is used when the data of two samples are statistically independent, while the paired t-test is used when data is in the form of matched pairs.  To use the two-sample t-test, we need to assume that the data from both samples are normally distributed and they have the same variances.	What is the difference between at test and a paired t test	5556
3519	The formula to calculate the test statistic comparing two population means is, Z= ( x - y )/√(σx2/n1 + σy2/n2). In order to calculate the statistic, we must calculate the sample means ( x and y ) and sample standard deviations (σx and σy) for each sample separately. n1 and n2 represent the two sample sizes.	How do you find the test statistic	3519
4307	One reason you should consider when using ReLUs is, that they can produce dead neurons. That means that under certain circumstances your network can produce regions in which the network won't update, and the output is always 0.	Why is ReLu used in hidden layers	4307
5878	The mean squared error tells you how close a regression line is to a set of points. It does this by taking the distances from the points to the regression line (these distances are the “errors”) and squaring them. The squaring is necessary to remove any negative signs. It also gives more weight to larger differences.	How do you interpret mean square error	5878
6967	'Learning to learn' is the ability to pursue and persist in learning, to organise one's own learning, including through effective management of time and information, both individually and in groups.	What is the meaning of learning to learn	6967
1965	Back-propagation is the process of calculating the derivatives and gradient descent is the process of descending through the gradient, i.e. adjusting the parameters of the model to go down through the loss function.	What is the difference between Backpropagation and gradient descent	1965
160	To measure the relationship between numeric variable and categorical variable with > 2 levels you should use eta correlation (square root of the R2 of the multifactorial regression). If the categorical variable has 2 levels, point-biserial correlation is used (equivalent to the Pearson correlation).	How do you find the correlation between categorical variables	160
6567	A Z-score is a score which indicates how many standard deviations an observation is from the mean of the distribution. Z-scores tend to be used mainly in the context of the normal curve, and their interpretation based on the standard normal table.  Non-normal distributions can also be transformed into sets of Z-scores.	Can z score be used for non normal distribution	6567
670	A normal distribution is determined by two parameters the mean and the variance.  Now the standard normal distribution is a specific distribution with mean 0 and variance 1. This is the distribution that is used to construct tables of the normal distribution.	What is the difference between a normal distribution and a standard normal distribution	670
2802	The standard error of estimate, Se indicates approximately how much error you make when you use the predicted value for Y (on the least-squares line) instead of the actual value of Y.	What does the standard error of the estimate represent	2802
1476	The component form of simple exponential smoothing is given by: Forecast equation^yt+h|t=ℓtSmoothing equationℓt=αyt+(1−α)ℓt−1, Forecast equation y ^ t + h | t = ℓ t Smoothing equation ℓ t = α y t + ( 1 − α ) ℓ t − 1 , where ℓt is the level (or the smoothed value) of the series at time t .	What is the exponential smoothing formula	1476
9809	The Agglomerative Hierarchical Clustering is the most common type of hierarchical clustering used to group objects in clusters based on their similarity.	Which type of hierarchical clustering algorithm is more commonly used	9809
3975	The reasoning is the mental process of deriving logical conclusion and making predictions from available knowledge, facts, and beliefs.  In artificial intelligence, the reasoning is essential so that the machine can also think rationally as a human brain, and can perform like a human.	What is reasoning in artificial intelligence	3975
6859	The eigenvalues and eigenvectors of a matrix are often used in the analysis of financial data and are integral in extracting useful information from the raw data. They can be used for predicting stock prices and analyzing correlations between various stocks, corresponding to different companies.	What are the uses of eigenvalues	6859
5168	The learning rate is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated.  The learning rate may be the most important hyperparameter when configuring your neural network.	What is learning rate in CNN	5168
8641	The most intuitive way to increase the frequency resolution of an FFT is to increase the size while keeping the sampling frequency constant. Doing this will increase the number of frequency bins that are created, decreasing the frequency difference between each.	How can frequency resolution be improved	8641
9150	"The ""Linear-by-Linear"" test is for ordinal (ordered) categories and assumes equal and ordered intervals. The Linear-by-Linear Association test is a test for trends in a larger-than-2x2 table. Its value is shown to be significant and indicates that income tends to rise with values of ""male"" (i.e., from 0 to 1)."	What is linear by linear association chi square test	9150
6672	In logistic regression, as with any flavour of regression, it is fine, indeed usually better, to have continuous predictors. Given a choice between a continuous variable as a predictor and categorising a continuous variable for predictors, the first is usually to be preferred.	Can you use continuous variables in logistic regression	6672
1856	From the menus of SPSS choose: Analyze Scale Multidimensional Scaling… In Distances, select either Data are distances or Create distances from data. If your data are distances, you must select at least four numeric variables for analysis, and you can click Shape to indicate the shape of the distance matrix.	How do you do multidimensional scaling in SPSS	1856
6809	A local minimum of a function (typically a cost function in machine learning, which is something we want to minimize based on empirical data) is a point in the domain of a function that has the following property: the function evaluates to a greater value at every other point in a neighborhood around the local minimum	What is local minima in machine learning	6809
4778	There are four types of classification. They are Geographical classification, Chronological classification, Qualitative classification, Quantitative classification.	What are the types of classification in statistics	4778
5088	TensorFlow Datasets is a collection of datasets ready to use, with TensorFlow or other Python ML frameworks, such as Jax. All datasets are exposed as tf. data. Datasets , enabling easy-to-use and high-performance input pipelines. To get started see the guide and our list of datasets.	What is dataset in TensorFlow	5088
5251	Eigenvectors are a special set of vectors associated with a linear system of equations (i.e., a matrix equation) that are sometimes also known as characteristic vectors, proper vectors, or latent vectors (Marcus and Minc 1988, p.  Each eigenvector is paired with a corresponding so-called eigenvalue.	What are eigenvectors of a matrix	5251
7478	The standard deviation is a statistic that measures the dispersion of a dataset relative to its mean and is calculated as the square root of the variance.  If the data points are further from the mean, there is a higher deviation within the data set; thus, the more spread out the data, the higher the standard deviation.	What mean standard deviation	7478
9413	The (statistical) design of experiments (DOE) is an efficient procedure for planning experiments so that the data obtained can be analyzed to yield valid and objective conclusions. DOE begins with determining the objectives of an experiment and selecting the process factors for the study.	What is statistical design of experiments	9413
6927	With the LassoCV, RidgeCV, and Linear Regression machine learning algorithms.Define the problem.Gather the data.Clean & Explore the data.Model the data.Evaluate the model.Answer the problem.	How do you predict using machine learning	6927
10578	Bootstrapping is a type of resampling where large numbers of smaller samples of the same size are repeatedly drawn, with replacement, from a single original sample. For example, let's say your sample was made up of ten numbers: 49, 34, 21, 18, 10, 8, 6, 5, 2, 1. You randomly draw three numbers 5, 1, and 49.	What is an example of bootstrapping	10578
213	The standard deviation (SD) measures the amount of variability, or dispersion, from the individual data values to the mean, while the standard error of the mean (SEM) measures how far the sample mean of the data is likely to be from the true population mean. The SEM is always smaller than the SD.	What is the difference between mean and standard deviation	213
3269	A simple definition of a sampling frame is the set of source materials from which the sample is selected. The definition also encompasses the purpose of sampling frames, which is to provide a means for choosing the particular members of the target population that are to be interviewed in the survey.	What is the purpose of sampling frame	3269
8708	A statistic is a characteristic of a sample. Generally, a statistic is used to estimate the value of a population parameter. For instance, suppose we selected a random sample of 100 students from a school with 1000 students. The average height of the sampled students would be an example of a statistic.	What is an example of a statistic in the study	8708
7289	A random variable is a numerical description of the outcome of a statistical experiment.  For a discrete random variable, x, the probability distribution is defined by a probability mass function, denoted by f(x). This function provides the probability for each value of the random variable.	What is a random variable in probability theory	7289
3109	(When does a random variable have a Poisson YouTubeStart of suggested clipEnd of suggested clip	How do you find the Poisson distribution	3109
2741	Bayesian networks are a type of Probabilistic Graphical Model that can be used to build models from data and/or expert opinion. They can be used for a wide range of tasks including prediction, anomaly detection, diagnostics, automated insight, reasoning, time series prediction and decision making under uncertainty.	How the Bayesian network can be used	2741
1113	"A common pattern is the bell-shaped curve known as the ""normal distribution."" In a normal or ""typical"" distribution, points are as likely to occur on one side of the average as on the other. Note that other distributions look similar to the normal distribution."	What is a normal distribution in a histogram	1113
339	3.1 Comparison MatrixClassification AlgorithmsAccuracyF1-ScoreNaïve Bayes80.11%0.6005Stochastic Gradient Descent82.20%0.5780K-Nearest Neighbours83.56%0.5924Decision Tree84.23%0.63083 more rows•	Which algorithm is best for classification	339
6884	In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.	Which is better supervised or unsupervised learning	6884
9461	Listen to pronunciation. (NOR-mul raynj) In medicine, a set of values that a doctor uses to interpret a patient's test results. The normal range for a given test is based on the results that are seen in 95% of the healthy population.	What does normal range mean	9461
8862	Now, three variable case it is less clear for me. An intuitive definition for covariance function would be Cov(X,Y,Z)=E[(x−E[X])(y−E[Y])(z−E[Z])], but instead the literature suggests using covariance matrix that is defined as two variable covariance for each pair of variables.	How do you find the covariance of three variables	8862
194	The simplest example of a non-linear operator (non-linear functional) is a real-valued function of a real argument other than a linear function.  Under other restrictions on K(t,s,u) an Urysohn operator acts on other spaces, for instance, L2[a,b] or maps one Orlicz space LM1[a,b] into another LM2[a,b].	Which is not a linear operator	194
1268	A random variable is a numerical description of the outcome of a statistical experiment.  For a discrete random variable, x, the probability distribution is defined by a probability mass function, denoted by f(x). This function provides the probability for each value of the random variable.	What is random variables in probability	1268
4660	Multiple regression estimates how the changes in each predictor variable relate to changes in the response variable.  What does it mean to control for the variables in the model? It means that when you look at the effect of one variable in the model, you are holding constant all of the other predictors in the model.	What does it mean to control for a variable in multiple regression	4660
2769	In a Data Mining sense, the similarity measure is a distance with dimensions describing object features. That means if the distance among two data points is small then there is a high degree of similarity among the objects and vice versa. The similarity is subjective and depends heavily on the context and application.	What are the measures of similarity in data mining	2769
7533	Here is step by step on how to compute K-nearest neighbors KNN algorithm:Determine parameter K = number of nearest neighbors.Calculate the distance between the query-instance and all the training samples.Sort the distance and determine nearest neighbors based on the K-th minimum distance.More items	How is KNN algorithm calculated	7533
4977	2:194:05Suggested clip · 97 secondsChoosing Intervals for a Histogram - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you determine the intervals for a histogram	4977
5741	Automatic thresholding Select initial threshold value, typically the mean 8-bit value of the original image. Divide the original image into two portions; Pixel values that are less than or equal to the threshold; background. Pixel values greater than the threshold; foreground.	How is the threshold value calculated in image processing	5741
5614	Since both drifts involve a statistical change in the data, the best approach to detect them is by monitoring its statistical properties, the model's predictions, and their correlation with other factors.	How do you detect data Drifting	5614
5693	The process of adjusting the weights and threshold of the ADALINE network is based on a learning algorithm named the Delta rule (Widrow and Hoff 1960) or Widrow-Hoff learning rule, also known as LMS (Least Mean Square ) algorithm or Gradient Descent method.	What is the delta rule of Adaline network	5693
1015	It's a cost function that is used as loss for machine learning models, telling us how bad it's performing, the lower the better. Also it's much easier to reason about the loss this way, to be consistent with the rule of loss functions approaching 0 as the model gets better.	Why do we use negative log likelihood	1015
228	The learning algorithm of the Hopfield network is unsupervised, meaning that there is no “teacher” telling the network what is the correct output for a certain input.	Is Hopfield network supervised or unsupervised	228
9103	Recall is the number of relevant documents retrieved by a search divided by the total number of existing relevant documents, while precision is the number of relevant documents retrieved by a search divided by the total number of documents retrieved by that search.	What is the difference between precision and recall	9103
4918	So that we only have to have one area table, rather than an infinite number of area tables. Of course, technology can find area under any normal curve and so tables of values are a bit archaic.	Why do we Standardise normal distribution	4918
3665	When working with a measurement variable, the Kruskal–Wallis test starts by substituting the rank in the overall data set for each measurement value. The smallest value gets a rank of 1, the second-smallest gets a rank of 2, etc.	How do you rank data for the Kruskal Wallis test	3665
2182	The Poisson distribution is used to describe the distribution of rare events in a large population. For example, at any particular time, there is a certain probability that a particular cell within a large population of cells will acquire a mutation.	When should I use Poisson distribution	2182
1926	In class limit, the upper extreme value of the first class interval and the lower extreme value of the next class interval will not be equal. In class boundary, the upper extreme value of the first class interval and the lower extreme value of the next class interval will be equal.	What is the difference between class interval and class boundary	1926
7597	A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other.	What is convolutional neural network algorithm	7597
6323	Multivariate ANOVA (MANOVA) extends the capabilities of analysis of variance (ANOVA) by assessing multiple dependent variables simultaneously. ANOVA statistically tests the differences between three or more group means.  This statistical procedure tests multiple dependent variables at the same time.	Is Anova Multivariate analysis	6323
3501	A frequent problem in estimating logistic regression models is a failure of the likelihood maximization algorithm to converge. In most cases, this failure is a consequence of data patterns known as complete or quasi-complete separation.  Log-likelihood as a function of the slope, quasi-complete separation.	Is logistic regression guaranteed to converge	3501
4742	Group projects, discussions, and writing are examples of active learning, because they involve doing something.	Which of the following are examples of active learning	4742
9946	As a hypothetical example of systematic sampling, assume that in a population of 10,000 people, a statistician selects every 100th person for sampling. The sampling intervals can also be systematic, such as choosing a new sample to draw from every 12 hours.	What is systematic sampling example	9946
6127	Mathematically speaking, the regret is expressed as the difference between the payoff (reward or return) of a possible action and the payoff of the action that has been actually taken. If we denote the payoff function as u the formula becomes: regret = u(possible action) - u(action taken)	What is regret in reinforcement learning	6127
1999	Classification/Recognition: Given an image with an object , find out what that object is.  In other words, classify it in a class from a set of predefined categories. Localization : Find where the object is and draw a bounding box around it.	What is localization in deep learning	1999
389	Definition. Data Partitioning is the technique of distributing data across multiple tables, disks, or sites in order to improve query processing performance or increase database manageability.	What is partitioning of data	389
589	Definition: Gamma distribution is a distribution that arises naturally in processes for which the waiting times between events are relevant. It can be thought of as a waiting time between Poisson distributed events.	What does gamma distribution mean	589
2687	Partial least squares regression (PLS regression) is a statistical method that bears some relation to principal components regression; instead of finding hyperplanes of maximum variance between the response and independent variables, it finds a linear regression model by projecting the predicted variables and the	What is PLS in statistics	2687
6688	"Writing up resultsFirst, present descriptive statistics in a table.  Organize your results in a table (see Table 3) stating your dependent variable (dependent variable = YES) and state that these are ""logistic regression results.""  When describing the statistics in the tables, point out the highlights for the reader.More items"	How do you write logistic regression results	6688
10638	A probability distribution is a statistical function that describes all the possible values and likelihoods that a random variable can take within a given range.  These factors include the distribution's mean (average), standard deviation, skewness, and kurtosis.	What is a probability distribution in statistics	10638
974	The sample variance is an estimator for the population variance. When applied to sample data, the population variance formula is a biased estimator of the population variance: it tends to underestimate the amount of variability.  We are using one fitted value (sample mean) in our estimate of the variance.	Why is the formula of sample variance different from population variance	974
4647	Correlation measures linearity between X and Y. If ρ(X,Y) = 0 we say that X and Y are “uncorrelated.” If two variables are independent, then their correlation will be 0. However, like with covariance.	What is the correlation between two independent random variables	4647
438	Detection theory or signal detection theory is a means to measure the ability to differentiate between information-bearing patterns (called stimulus in living organisms, signal in machines) and random patterns that distract from the information (called noise, consisting of background stimuli and random activity of the	What is noise in signal detection theory	789
8637	A histogram shows bars representing numerical values by range of value. A bar chart shows categories, not numbers, with bars indicating the amount of each category. Histogram example: student's ages, with a bar showing the number of students in each year.	What can you tell from a histogram	8637
373	Discrete random variables can only take on values from a countable set of numbers such as the integers or some subset of integers. (Usually, they can't be fractions.)	Can a discrete variable take any fractional value	373
4626	Softmax Thus sigmoid is widely used for binary classification problems. While building a network for a multiclass problem, the output layer would have as many neurons as the number of classes in the target. For instance if you have three classes, there would be three neurons in the output layer.	Which activation function is used for binary classification	4626
10093	Best Image Processing Projects CollectionLicense plate recognition.Face Emotion recognition.Face recognition.Cancer detection.Object detection.Pedestrian detection.Lane detection for ADAS.Blind assistance systems.More items	Whatt are best image processing ideas	10093
7198	A single object of the world from which a model will be learned, or on which a model will be used (e.g., for prediction). In most machine learning work, instances are described by feature vectors; some work uses more complex representations (e.g., containing relations between instances or between parts of instances).	What is an instance in machine learning	7198
5622	First multiply the critical value by the standard deviation. Then divide this result by the error from Step 1. Now square this result. This result is the sample size.	How do you find the sample size when given the mean and standard deviation	5622
7856	"The coefficient of determination is a measurement used to explain how much variability of one factor can be caused by its relationship to another related factor. This correlation, known as the ""goodness of fit,"" is represented as a value between 0.0 and 1.0."	What does the coefficient of determination tell you	7856
1630	Box plots divide the data into sections that each contain approximately 25% of the data in that set. Box plots are useful as they provide a visual summary of the data enabling researchers to quickly identify mean values, the dispersion of the data set, and signs of skewness.	What is the point of a box plot	1630
10701	The general idea is that machine learning, while not always the perfect choice, can be powerful in modeling time series data due to its ability to handle non-linear data. The feature engineering applied to the time series data in a machine learning approach is the key to how successful the model will be.	Data Science Can machine learning be used for time series analysis	10701
1339	Bivariate analysis is one of the simplest forms of quantitative (statistical) analysis. It involves the analysis of two variables (often denoted as X, Y), for the purpose of determining the empirical relationship between them. Bivariate analysis can be helpful in testing simple hypotheses of association.	What is the use of bivariate analysis	1339
1329	Model specification refers to the determination of which independent variables should be included in or excluded from a regression equation.  A multiple regression model is, in fact, a theoretical statement about the causal relationship between one or more independent variables and a dependent variable.	What is a model in regression analysis	1329
3348	The steps in grouping may be summarized as follows:Decide on the number of classes.Determine the range, i.e., the difference between the highest and lowest observations in the data.Divide range by the number of classes to estimate approximate size of the interval (h).More items	How do you find the class interval in a frequency table	3348
3789	A joint probability distribution shows a probability distribution for two (or more) random variables. Instead of events being labeled A and B, the norm is to use X and Y. The formal definition is: f(x,y) = P(X = x, Y = y) The whole point of the joint distribution is to look for a relationship between two variables.	What is joint distribution in statistics	3789
3390	"The word ""deep"" in ""deep learning"" refers to the number of layers through which the data is transformed.  Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively."	Why is the word deep used in deep learning	3390
7884	How Change Detection WorksDeveloper updates the data model, e.g. by updating a component binding.Angular detects the change.Change detection checks every component in the component tree from top to bottom to see if the corresponding model has changed.If there is a new value, it will update the component's view (DOM)	How does change detection work in angular	7884
2022	MLP usually means many layers and can be supervised with labels. RBM (Restricted Boltzmann Machine) consists of only 2 layers: input layer & hidden layer, and it is un-supervised (no labels).  RBM (Restricted Boltzmann Machine) consists of only 2 layers: input layer & hidden layer, and it is un-supervised (no labels).	Whats the difference between Multilayer Perceptron and Restricted Boltzmann Machine	2022
1390	Poisson Formula. P(x; μ) = (e-μ) (μx) / x! where x is the actual number of successes that result from the experiment, and e is approximately equal to 2.71828. The Poisson distribution has the following properties: The mean of the distribution is equal to μ . The variance is also equal to μ .	What is mean in Poisson distribution	1390
2216	Vectors have many real-life applications, including situations involving force or velocity. For example, consider the forces acting on a boat crossing a river. The boat's motor generates a force in one direction, and the current of the river generates a force in another direction. Both forces are vectors.	What are some applications of vectors in real life	2216
9806	Data quality is important when applying Artificial Intelligence techniques, because the results of these solutions will be as good or bad as the quality of the data used.  The algorithms that feed systems based on Artificial Intelligence can only assume that the data to be analyzed are reliable.	Why is data important in AI	9806
3583	The number of input variables or features for a dataset is referred to as its dimensionality.  Large numbers of input features can cause poor performance for machine learning algorithms. Dimensionality reduction is a general field of study concerned with reducing the number of input features.	What is Dimension machine learning	3583
1461	The Real World is a term by the redpills to refer to reality, the true physical world and life outside the Matrix.	What is the real world in the Matrix	1461
6186	Weights and biases (commonly referred to as w and b) are the learnable parameters of a machine learning model.  When the inputs are transmitted between neurons, the weights are applied to the inputs along with the bias. A neuron. Weights control the signal (or the strength of the connection) between two neurons.	What is a weight in machine learning	6186
1350	First, let's review how to calculate the population standard deviation:Calculate the mean (simple average of the numbers).For each number: Subtract the mean. Square the result.Calculate the mean of those squared differences.  Take the square root of that to obtain the population standard deviation.	How do you find the population standard deviation	1350
1618	A Convolutional Neural Networks Introduction so to speak.Step 1: Convolution Operation.  Step 1(b): ReLU Layer.  Step 2: Pooling.  Step 3: Flattening.  Step 4: Full Connection.  Step 1 - Convolution Operation.  Step 1(b): The Rectified Linear Unit (ReLU)  Step 2 - Max Pooling.More items•	What are the steps in convolution neural network	1618
1271	In computational learning theory, probably approximately correct (PAC) learning is a framework for mathematical analysis of machine learning.	What is PAC in machine learning	1271
5142	The disadvantage of the ANOVA F-test is that if we reject the null hypothesis, we do not know which treatments can be said to be significantly different from the others, nor, if the F-test is performed at level α, can we state that the treatment pair with the greatest mean difference is significantly different at level	What is the limitation of the F ratio in Anova	5142
2171	The difference between forward and backward chaining is: Backward chaining starts with a goal and then searches back through inference rules to find the facts that support the goal. Forward chaining starts with facts and searches forward through the rules to find a desired goal.	What is the difference between forward and backward chaining in artificial intelligence	2171
6001	Hypothesis Testing — 2-tailed testSpecify the Null(H0) and Alternate(H1) hypothesis.Choose the level of Significance(α)Find Critical Values.Find the test statistic.Draw your conclusion.	How do you do a two sided hypothesis test	6001
3073	The basic idea behind a neural network is to simulate (copy in a simplified but reasonably faithful way) lots of densely interconnected brain cells inside a computer so you can get it to learn things, recognize patterns, and make decisions in a humanlike way.	How does a neural network function	3073
7683	We use binary cross-entropy loss for classification models which output a probability p. The range of the sigmoid function is [0, 1] which makes it suitable for calculating probability.	Which loss function is used for binary classification	7683
387	The uniform distribution defines equal probability over a given range for a continuous distribution. For this reason, it is important as a reference distribution. One of the most important applications of the uniform distribution is in the generation of random numbers.	What is the use of uniform distribution	387
4941	Normal distribution describes continuous data which have a symmetric distribution, with a characteristic 'bell' shape. Binomial distribution describes the distribution of binary data from a finite sample. Thus it gives the probability of getting r events out of n trials.	What is the difference between binomial and normal distribution	4941
7141	Given that the range can easily be computed with information on the maximum and minimum value of the data set, users requiring only a rough indication of the data may prefer to use this indicator over more sophisticated measures of spread, like the standard deviation.	What are the uses of range in statistics	7141
6838	Nonparametric tests are also called distribution-free tests because they don't assume that your data follow a specific distribution. You may have heard that you should use nonparametric tests when your data don't meet the assumptions of the parametric test, especially the assumption about normally distributed data.	When should nonparametric statistics be used	6838
8771	"Ground truth is a term used in statistics and machine learning that means checking the results of machine learning for accuracy against the real world. The term is borrowed from meteorology, where ""ground truth"" refers to information obtained on site."	What is ground truth in AI	8771
9169	The law of large numbers, in probability and statistics, states that as a sample size grows, its mean gets closer to the average of the whole population. In the 16th century, mathematician Gerolama Cardano recognized the Law of Large Numbers but never proved it.	What does the law of large numbers mean	9169
6875	Stochastic vs. For example, a stochastic variable is a random variable. A stochastic process is a random process. Typically, random is used to refer to a lack of dependence between observations in a sequence. For example, the rolls of a fair die are random, so are the flips of a fair coin.	What is the difference between random and stochastic	6875
925	Descriptive analytics is a statistical method that is used to search and summarize historical data in order to identify patterns or meaning.	What are descriptive analytics	925
5652	8 Examples of Artificial IntelligenceGoogle Maps and Ride-Hailing Applications. One doesn't have to put much thought into traveling to a new destination anymore.  Face Detection and Recognition.  Text Editors or Autocorrect.  Search and Recommendation Algorithms.  Chatbots.  Digital Assistants.  Social Media.  E-Payments.	What are some examples of artificial intelligence	5652
1504	Shift-invariance: this means that if we shift the input in time (or shift the entries in a vector) then the output is shifted by the same amount.	What is shift invariance in a convolutional neural network CNN	1504
4476	bucketized_column. Represents discretized dense input bucketed by boundaries .	What do you use the TF Feature_column Bucketized_column function for	4476
1897	Negative binomial regression – Negative binomial regression can be used for over-dispersed count data, that is when the conditional variance exceeds the conditional mean.	When would you use a negative binomial distribution	1897
5001	Covariance measures the directional relationship between the returns on two assets. A positive covariance means that asset returns move together while a negative covariance means they move inversely.	How do you explain covariance	5001
214	A sampling error is a statistical error that occurs when an analyst does not select a sample that represents the entire population of data and the results found in the sample do not represent the results that would be obtained from the entire population.	What is a sampling error in research	214
6378	The marketplace for predictive analytics software has ballooned: G2Crowd records 92 results in the category. Pricing varies substantially based on the number of users and, in some cases, amount of data, but generally starts around $1,000 per year, though it can easily scale into six figures.	How much does Predictive Analytics cost	6378
8480	Denying the antecedent, sometimes also called inverse error or fallacy of the inverse, is a formal fallacy of inferring the inverse from the original statement. It is committed by reasoning in the form: If P, then Q. Therefore, if not P, then not Q.	What is denying the antecedent in relation to a propositional fallacy	8480
4773	An estimate of a population parameter may be expressed in two ways: Point estimate. A point estimate of a population parameter is a single value of a statistic. For example, the sample mean x is a point estimate of the population mean μ.	What are the methods of estimation in statistics	4773
5154	4:306:35Suggested clip · 77 secondsMarginal PDF from Joint PDF - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you find the marginal density function	5154
2920	It might take about 2-4 hours of coding and 1-2 hours of training if done in Python and Numpy (assuming sensible parameter initialization and a good set of hyperparameters). No GPU required, your old but gold CPU on a laptop will do the job. Longer training time is expected if the net is deeper than 2 hidden layers.	How long do neural networks take to train	2920
8409	The purpose of factor analysis is to reduce many individual items into a fewer number of dimensions. Factor analysis can be used to simplify data, such as reducing the number of variables in regression models.	What is the purpose of factor analysis	8409
2016	Neural network regularization is a technique used to reduce the likelihood of model overfitting. There are several forms of regularization. The most common form is called L2 regularization.  L2 regularization tries to reduce the possibility of overfitting by keeping the values of the weights and biases small.	What is l2 regularization in neural networks	2016
964	"An Iterator is an object that can be used to loop through collections, like ArrayList and HashSet. It is called an ""iterator"" because ""iterating"" is the technical term for looping. To use an Iterator, you must import it from the java."	What is the use of iterator	964
7386	Some additional simple scoring methods include:Counts. Count the number of times each word appears in a document.Frequencies. Calculate the frequency that each word appears in a document out of all the words in the document.	How do you calculate bag words	7386
10356	LSTMs solve the problem using a unique additive gradient structure that includes direct access to the forget gate's activations, enabling the network to encourage desired behaviour from the error gradient using frequent gates update on every time step of the learning process.	How does Lstm overcomes vanishing gradient problem	10356
2041	In its simplest form, the sigmoid is a representation of time (on the horizontal axis) and activity (on the vertical axis). The wonder of this curve is that it really describes most phenomena, regardless of type.  The phenomenon experiences sharp growth. It hits a maturity phase where growth slows, and then stops.	What does a sigmoid curve mean	2041
8661	There are two main reasons to use logarithmic scales in charts and graphs. The first is to respond to skewness towards large values; i.e., cases in which one or a few points are much larger than the bulk of the data. The second is to show percent change or multiplicative factors.	Why would you use a logarithmic scale	8661
3840	Symmetrical distribution occurs when the values of variables occur at regular frequencies and the mean, median and mode occur at the same point. In graph form, symmetrical distribution often appears as a bell curve. If a line were drawn dissecting the middle of the graph, it would show two sides that mirror each other.	What is symmetric data distribution	3840
6349	(i) The value of dimensionless constants cannot be determined by this method. (ii) This method cannot be applied to equations involving exponential and trigonometric functions. (iii) It cannot be applied to an equation involving more than three physical quantities.	What are the advantages and disadvantages of Dimensional Analysis	6349
3640	Conclusion. Human intelligence revolves around adapting to the environment using a combination of several cognitive processes. The field of Artificial intelligence focuses on designing machines that can mimic human behavior. However, AI researchers are able to go as far as implementing Weak AI, but not the Strong AI.	What is the difference between intelligence and artificial intelligence	3640
1774	To write a null hypothesis, first start by asking a question. Rephrase that question in a form that assumes no relationship between the variables. In other words, assume a treatment has no effect. Write your hypothesis in a way that reflects this.	How do you write a hypothesis and null hypothesis	1774
2732	In simple words, stemming technique only looks at the form of the word whereas lemmatization technique looks at the meaning of the word. It means after applying lemmatization, we will always get a valid word.	What is the difference between stemming and Lemmatization	2732
10651	Coefficients of linear discriminants: Shows the linear combination of predictor variables that are used to form the LDA decision rule. for example, LD1 = 0.91*Sepal.	What is coefficients of linear Discriminants	10651
9790	The higher the number of features, the harder it gets to visualize the training set and then work on it.  Dimensionality reduction is the process of reducing the number of random variables under consideration, by obtaining a set of principal variables. It can be divided into feature selection and feature extraction.	How does dimensionality reduction work	9790
4304	Both indices take values from zero to one. In a similarity index, a value of 1 means that the two communities you are comparing share all their species, while a value of 0 means they share none. In a dissimilarity index the interpretation is the opposite: 1 means that the communities are totally different.	How do you interpret Sorensen index of similarity	4304
2569	In short, the problem with neural networks is that a number of parameter have to be set before any training can begin. However, there are no clear rules how to set these parameters.  By combining genetic algorithms with neural networks (GANN), the genetic algorithm is used to find these parameters.	Can we incorporate genetic algorithm concept to artificial neural network	2569
8531	Probability distributions are a fundamental concept in statistics. They are used both on a theoretical level and a practical level. Some practical uses of probability distributions are: To calculate confidence intervals for parameters and to calculate critical regions for hypothesis tests.	What is the use of probability distribution	8531
4342	The short answer is: Logistic regression is considered a generalized linear model because the outcome always depends on the sum of the inputs and parameters. Or in other words, the output cannot depend on the product (or quotient, etc.)	Is logistic regression a generalized linear model	4342
8034	Statistical power, or the power of a hypothesis test is the probability that the test correctly rejects the null hypothesis. That is, the probability of a true positive result.  statistical power is the probability that a test will correctly reject a false null hypothesis.	What is statistical power in research	8034
4381	Statistical inference involves hypothesis testing (evaluating some idea about a population using a sample) and estimation (estimating the value or potential range of values of some characteristic of the population based on that of a sample).	What does statistical inference take into account	4381
2775	In machine learning and statistics, the learning rate is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function.  In the adaptive control literature, the learning rate is commonly referred to as gain.	What is meant by learning rate	2775
3194	5 Ways to Avoid Being Fooled By Statistics.  Do A Little Bit of Math and apply Common Sense.  Always Look for the Source and check the authority of the source.  Question if the statistics are biased or statistically insignificant.  Question if the statistics are skewed purposely or Misinterpreted.More items•	How can we avoid misleading statistics	3194
5863	Multinomial logistic regression (often just called 'multinomial regression') is used to predict a nominal dependent variable given one or more independent variables. It is sometimes considered an extension of binomial logistic regression to allow for a dependent variable with more than two categories.	When would you use multinomial regression	10949
1342	Getting Familiar with ML Pipelines A machine learning pipeline is used to help automate machine learning workflows. They operate by enabling a sequence of data to be transformed and correlated together in a model that can be tested and evaluated to achieve an outcome, whether positive or negative.	What do you think is important in a machine learning Pipeline	1342
1109	In an analogy to standard deviation, taking the square root of MSE yields the root-mean-square error or root-mean-square deviation (RMSE or RMSD), which has the same units as the quantity being estimated; for an unbiased estimator, the RMSE is the square root of the variance, known as the standard error.	Is RMSE and standard error same	1109
6876	Preference learning is a subfield in machine learning, which is a classification method based on observed preference information. In the view of supervised learning, preference learning trains on a set of items which have preferences toward labels or other items and predicts the preferences for all items.	What is preference Learning And how is it different from machine learning	6876
5110	Normalization basically means bringing all the values to once scale and there is nothing wrong using percentage but there must be a base value for normalizing the data and if you are asking about 100 as a base value and then converting everything as % it will not be equal to normalization as in normalization the base	What is normalized percentage	5110
977	Consider a binomial distribution with parameters (n, p). When n is large and p is small , approximate the probability using Poisson distribution. When n is large and p is close to 0.5, use normal approximation.	When do I approximate Binomial Distribution with Normal vs Poisson	977
7559	Which intuitively says that the probability of has to be “really high”. In other words, if your value is smaller than E[X], then the upper bound of it taking that value is 1 (basically sort of an uninteresting statement, since you already knew the upper bound was 1 or greater).	What is an intuitive explanation of Markovs inequality	7559
6343	Some Disadvantages of KNNAccuracy depends on the quality of the data.With large data, the prediction stage might be slow.Sensitive to the scale of the data and irrelevant features.Require high memory – need to store all of the training data.Given that it stores all of the training, it can be computationally expensive.	Which of the following are the disadvantages of using Knn	6343
3810	Let's GO!Step 0 : Pre-requisites. It is recommended that before jumping on to Deep Learning, you should know the basics of Machine Learning.  Step 1 : Setup your Machine.  Step 2 : A Shallow Dive.  Step 3 : Choose your own Adventure!  Step 4 : Deep Dive into Deep Learning.	How do you implement deep learning	3810
10893	The disadvantages: Convenience samples do not produce representative results. If you need to extrapolate to the target population, convenience samples aren't going to get you there.	What is the problem with convenience sampling	10893
1277	Techniques to reduce underfitting :Increase model complexity.Increase number of features, performing feature engineering.Remove noise from the data.Increase the number of epochs or increase the duration of training to get better results.	How do you prevent Underfitting in machine learning	1277
8902	Control Charts: A discrete distribution is one in which the data can only take on certain values, for example integers. A continuous distribution is one in which data can take on any value within a specified range (which may be infinite).	What is discrete and continuous distribution	8902
5166	In regression analysis, the dependent variable is denoted Y and the independent variable is denoted X. So, in this case, Y=total cholesterol and X=BMI. When there is a single continuous dependent variable and a single independent variable, the analysis is called a simple linear regression analysis .	How do you find x and y variables in regression	5166
9026	So standard deviation gives you more deviation than mean deviation whem there are certain data points that are too far from its mean.	Which is larger average deviation or standard deviation	9026
4096	Gradient descent is an optimization algorithm that's used when training a machine learning model. It's based on a convex function and tweaks its parameters iteratively to minimize a given function to its local minimum.	What is a gradient machine learning	4096
290	Order of training data during training a neural network matters a great deal. If you are training with a mini batch you may see large fluctuations in accuracy (and cost function) and may end up over fitting correlated portions of your mini batch.	Does the order of training examples within a minibatch matter when training a neural network	290
1751	Classification accuracy is our starting point. It is the number of correct predictions made divided by the total number of predictions made, multiplied by 100 to turn it into a percentage.	How do you calculate classification accuracy	1751
8032	SVM tries to finds the “best” margin (distance between the line and the support vectors) that separates the classes and this reduces the risk of error on the data, while logistic regression does not, instead it can have different decision boundaries with different weights that are near the optimal point.	Is SVM better than logistic regression	8032
1182	An autoregressive integrated moving average, or ARIMA, is a statistical analysis model that uses time series data to either better understand the data set or to predict future trends.	What is Arima model used for	1182
4462	In statistics, the kth order statistic of a statistical sample is equal to its kth-smallest value. Together with rank statistics, order statistics are among the most fundamental tools in non-parametric statistics and inference.	What is KTH in statistics	4462
3091	In simple terms, deep learning is when ANNs learn from large amounts of data. Similar to how humans learn from experience, a deep learning algorithm performs a task repeatedly, each time tweaking it slightly to improve the outcome.	How does a deep neural network learn	3091
3295	Sampling errors can be reduced by the following methods: (1) by increasing the size of the sample (2) by stratification. Increasing the size of the sample: The sampling error can be reduced by increasing the sample size. If the sample size n is equal to the population size N, then the sampling error is zero.	What is sampling error and how can it be reduced	3295
10117	"The Kruskal-Wallis H test (sometimes also called the ""one-way ANOVA on ranks"") is a rank-based nonparametric test that can be used to determine if there are statistically significant differences between two or more groups of an independent variable on a continuous or ordinal dependent variable."	What is Kruskal Wallis test used for	10117
1470	3 Answers. Attempts to find an average value of AC would directly provide you the answer zero Hence, RMS values are used. They help to find the effective value of AC (voltage or current). This RMS is a mathematical quantity (used in many math fields) used to compare both alternating and direct currents (or voltage).	Why use root mean square instead of average	1470
4928	A p-value less than 0.05 (typically ≤ 0.05) is statistically significant. It indicates strong evidence against the null hypothesis, as there is less than a 5% probability the null is correct (and the results are random). Therefore, we reject the null hypothesis, and accept the alternative hypothesis.	Why is the standard p value 0 05	4928
10761	The most used algorithm to train neural networks is gradient descent. We'll define it later, but for now hold on to the following idea: the gradient is a numeric calculation allowing us to know how to adjust the parameters of a network in such a way that its output deviation is minimized.	What is a gradient in neural network	10761
9123	Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples.	What is meant by supervised machine learning	9123
4392	Definition: Quota sampling is a sampling methodology wherein data is collected from a homogeneous group. It involves a two-step process where two variables can be used to filter information from the population. It can easily be administered and helps in quick comparison.	What is meant by quota sampling	4392
137	"International communication (also referred to as the study of global communication or transnational communication) is the communication practice that occurs across international borders.  International communication ""encompasses political, economic, social, cultural and military concerns""."	What is the meaning of international communication	137
10899	K-means clustering is one of the simplest and popular unsupervised machine learning algorithms.  In other words, the K-means algorithm identifies k number of centroids, and then allocates every data point to the nearest cluster, while keeping the centroids as small as possible.	What is K means algorithm in machine learning	10899
7714	"The purpose of a neural network is to learn to recognize patterns in your data. Once the neural network has been trained on samples of your data, it can make predictions by detecting similar patterns in future data. Software that learns is truly ""Artificial Intelligence""."	What is the purpose of a neural network	7714
3123	Object is a copy of the class. Instance is a variable that holds the memory address of the object. You can also have multiple objects of the same class and then multiple instances of each of those objects. In these cases, each object's set of instances are equivalent in value, but the instances between objects are not.	What is the difference between object and instance	3123
887	GAN Training Step 1 — Select a number of real images from the training set. Step 2 — Generate a number of fake images. This is done by sampling random noise vectors and creating images from them using the generator. Step 3 — Train the discriminator for one or more epochs using both fake and real images.	How do you create a generative adversarial network	887
9065	In implementing most of the machine learning algorithms, we represent each data point with a feature vector as the input. A vector is basically an array of numerics, or in physics, an object with magnitude and direction.	What is data representation in machine learning	9065
6493	In other words, accuracy describes the difference between the measurement and the part's actual value, while precision describes the variation you see when you measure the same part repeatedly with the same device.	What is the relationship between precision and accuracy	6493
6533	To find the average, add them together and divide by the number of values (10 in this case). When repeated measurements give different results, we want to know how widely spread the readings are. The spread of values tells us something about the uncertainty of a measurement.	How do you find the uncertainty of a measurement	6533
8155	The maximum entropy principle is defined as modeling a given set of data by finding the highest entropy to satisfy the constraints of our prior knowledge.  The maximum entropy model is a conditional probability model p(y|x) that allows us to predict class labels given a set of features for a given data point.	What is maximum entropy model in NLP	8155
3253	Now living under the identity of Scarecrow, Hide helped Koutarou Amon flee from Akihiro Kanou after he was turned into a one-eyed ghoul.	Did hide become a ghoul	3253
5780	In Semantic networks, we can represent our knowledge in the form of graphical networks. This network consists of nodes representing objects and arcs which describe the relationship between those objects. Semantic networks can categorize the object in different forms and can also link those objects.	How knowledge is represented using semantic network	5780
8639	For example RSA Encryption padding is randomized, ensuring that the same message encrypted multiple times looks different each time. It also avoids other weaknesses, such as encrypting the same message using different RSA keys leaking the message, or an attacker creating messages derived from some other ciphertexts.	What is padding in RSA encryption	8639
3281	Predicting Google's Stock Price using Linear RegressionTake a value of x (say x=0)Find the corresponding value of y by putting x=0 in the equation.Store the (x,y) value pair in a table.Repeat the process once or twice or as many times as we want.Plot the points on the graph to obtain the straight line.	How do you use linear regression to predict stock prices	3281
5592	Truncated Backpropagation Through Time (truncated BPTT) is a widespread method for learning recurrent computational graphs. Truncated BPTT keeps the computational benefits of Backpropagation Through Time (BPTT) while relieving the need for a complete backtrack through the whole data sequence at every step.	What is truncated Bptt	5592
9223	In geometry, a hyperplane is a subspace whose dimension is one less than that of its ambient space. If a space is 3-dimensional then its hyperplanes are the 2-dimensional planes, while if the space is 2-dimensional, its hyperplanes are the 1-dimensional lines.	What is meant by Hyperplane	9223
21	HMMs is the Hidden Markov Models library for Python. It is easy to use, general purpose library, implementing all the important submethods, needed for the training, examining and experimenting with the data models.	What is the best Python library for Hidden Markov Models	21
2069	For example, a p-value of 0.01 would mean there is a 1% chance of committing a Type I error. However, using a lower value for alpha means that you will be less likely to detect a true difference if one really exists (thus risking a type II error).	What is the relationship between the p value of a t test and the Type I and Type II errors	2069
6405	It's O(V+E) because each visit to v of V must visit each e of E where |e| <= V-1. Since there are V visits to v of V then that is O(V).  So total time complexity is O(V + E).	Why is the complexity of DFS o v e	6405
3552	In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.	What is supervised and unsupervised learning explain with the examples	3552
4357	Best Practices of Data CleaningSetting up a Quality Plan. RELATED BLOG.  Fill-out missing values. One of the first steps of fixing errors in your dataset is to find incomplete values and fill them out.  Removing rows with missing values.  Fixing errors in the structure.  Reducing data for proper data handling.	How does machine learning clean data	4357
2137	In statistics, linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression.  Such models are called linear models.	How do you explain linear regression	2137
2396	Some business analysts at claim that AI is a game changer for the personal device market. By 2020, about 60 percent of personal-device technology vendors will depend on AI-enabled Cloud platforms to deliver enhanced functionality and personalized services. AI technology will deliver an “emotional user experience.”	What is the future of AI and machine learning	2396
3747	Linear models, generalized linear models, and nonlinear models are examples of parametric regression models because we know the function that describes the relationship between the response and explanatory variables.  If the relationship is unknown and nonlinear, nonparametric regression models should be used.	Is linear regression non parametric	3747
8540	Definition: Given data the maximum likelihood estimate (MLE) for the parameter p is the value of p that maximizes the likelihood P(data |p). That is, the MLE is the value of p for which the data is most likely. 100 P(55 heads|p) = ( 55 ) p55(1 − p)45.	How do you find the maximum likelihood estimator	8540
1542	How to Find the Mean. The mean is the average of the numbers. It is easy to calculate: add up all the numbers, then divide by how many numbers there are. In other words it is the sum divided by the count.	How do you find the mean in statistics	1542
9351	Exponential smoothing is a way to smooth out data for presentations or to make forecasts. It's usually used for finance and economics. If you have a time series with a clear pattern, you could use moving averages — but if you don't have a clear pattern you can use exponential smoothing to forecast.	When would you use exponential smoothing	9351
10670	Improving the PF can maximize current-carrying capacity, improve voltage to equipment, reduce power losses, and lower electric bills. The simplest way to improve power factor is to add PF correction capacitors to the electrical system. PF correction capacitors act as reactive current generators.	How can we control the power factor	10670
6971	Interpolation refers to using the data in order to predict data within the dataset. Extrapolation is the use of the data set to predict beyond the data set.	What is the difference between extrapolation and interpolation	6971
9761	Machine Learning: Reinforcement Learning — Markov Decision Processes.  A mathematical representation of a complex decision making process is “Markov Decision Processes” (MDP). MDP is defined by: A state S, which represents every state that one could be in, within a defined world.	What is MDP in machine learning	9761
8847	Sample moments are those that are utilized to approximate the unknown population moments. Sample moments are calculated from the sample data. Such moments include mean, variance, skewness, and kurtosis.	What are sample moments	8847
9661	For example, Q-learning is an off-policy learner. On-policy methods attempt to evaluate or improve the policy that is used to make decisions. In contrast, off-policy methods evaluate or improve a policy different from that used to generate the data.11‏/04‏/2020	What is the difference between on policy and off policy	9661
8590	In the extended Kalman filter, the state transition and observation models don't need to be linear functions of the state but may instead be differentiable functions.  These matrices can be used in the Kalman filter equations. This process essentially linearizes the non-linear function around the current estimate.	How does extended Kalman filter work	8590
7568	The purpose of Causal Analysis and Resolution (CAR) is to identify causes of defects and other problems and take action to prevent them from occurring in the future. Introductory Notes The Causal Analysis and Resolution process area involves the following: Identifying and analyzing causes of defects and other problems.	What is causal analysis and resolution	7568
7475	A control problem involves a system that is described by state variables.  The problem is to find a time control stratergy to make the system reach the terget state that is find conditions for application of force as a function of the control variables of the system (V,W,Th).	What is control problem	7475
3424	You now know that: Bias is the simplifying assumptions made by the model to make the target function easier to approximate. Variance is the amount that the estimate of the target function will change given different training data. Trade-off is tension between the error introduced by the bias and the variance.	What is tradeoff between bias and variance	3424
1057	You can reduce High variance, by reducing the number of features in the model. There are several methods available to check which features don't add much value to the model and which are of importance. Increasing the size of the training set can also help the model generalise.	How do you handle high variance data	1057
1078	If the data is symmetrical - normally distributed - then the mean tell you where the line of symmetry falls. The standard deviation tells you more. It tells you if the data is closely distributed to the mean (small standard deviation) or is the data widely distributed (big standard deviation).	Why do we use standard deviation instead of mean deviation	1078
10728	No, you don't have to transform your observed variables just because they don't follow a normal distribution. Linear regression analysis, which includes t-test and ANOVA, does not assume normality for either predictors (IV) or an outcome (DV). No way!  Yes, you should check normality of errors AFTER modeling.	Does the dependent variable need to be normally distributed in linear regression	10728
622	The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement. It can be used to estimate summary statistics such as the mean or standard deviation.	What is bootstrap sampling in machine learning and why is it important 1	622
9184	Each of the steps should take about 4–6 weeks' time. And in about 26 weeks since the time you started, and if you followed all of the above religiously, you will have a solid foundation in deep learning.	How long will it take to learn deep learning	9184
9264	there are three general categories of learning that artificial intelligence (AI)/machine learning utilizes to actually learn. They are Supervised Learning, Unsupervised Learning and Reinforcement learning.  The machine then maps the inputs and the outputs.	What is learning and types of learning in artificial intelligence	9264
7723	Machine learning algorithms are almost always optimized for raw, detailed source data. Thus, the data environment must provision large quantities of raw data for discovery-oriented analytics practices such as data exploration, data mining, statistics, and machine learning.	What type of data does machine learning need	7723
6562	Here is a brief review of our original seven techniques for dimensionality reduction:Missing Values Ratio.  Low Variance Filter.  High Correlation Filter.  Random Forests/Ensemble Trees.  Principal Component Analysis (PCA).  Backward Feature Elimination.  Forward Feature Construction.	Which technique can be implemented if you want to reduce the dimensionality of a certain statistical problem	6562
4453	Decision Trees in Machine Learning. Decision Tree models are created using 2 steps: Induction and Pruning. Induction is where we actually build the tree i.e set all of the hierarchical decision boundaries based on our data. Because of the nature of training decision trees they can be prone to major overfitting.	How is a decision tree trained	4453
10018	Normalization usually means to scale a variable to have a values between 0 and 1, while standardization transforms data to have a mean of zero and a standard deviation of 1. This standardization is called a z-score, and data points can be standardized with the following formula: A z-score standardizes variables.	What does it mean to normalize a variable	10018
6176	The optimal number of clusters can be defined as follow:Compute clustering algorithm (e.g., k-means clustering) for different values of k.  For each k, calculate the total within-cluster sum of square (wss).Plot the curve of wss according to the number of clusters k.More items	How do you find the optimal number of clusters	6176
9467	Credit card tokenization substitutes sensitive customer data with a one-time alphanumeric ID that has no value or connection to the account's owner. This randomly generated token is used to access, pass, transmit and retrieve customer's credit card information safely.	What is tokenization and how does it work	9467
6221	In our implementation of gradient descent, we have used a function compute_gradient(loss) that computes the gradient of a loss operation in our computational graph with respect to the output of every other node n (i.e. the direction of change for n along which the loss increases the most).	Is backpropagation gradient descent	6221
5902	Distance Learning Off-line is a mode of delivery that does not require online participation. You do not have to come to campus. Course materials may be available through the internet, but they can also be mailed to you if you prefer.	What is meant by offline classes	5902
3472	one training example	How many training examples are required by one shot learning for each class	3472
6407	Normal distribution, also known as the Gaussian distribution, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. In graph form, normal distribution will appear as a bell curve.	What does normal distribution mean in statistics	6407
5953	In a true experiment, participants are randomly assigned to either the treatment or the control group, whereas they are not assigned randomly in a quasi-experiment.  Thus, the researcher must try to statistically control for as many of these differences as possible.	What is the difference between field experiment and quasi experiment	5953
6810	The effect of the logit transformation is primarily to pull out the ends of the distribution. Over a broad range of intermediate values of the proportion (p), the relationship of logit(p) and p is nearly linear.	Why do we use logit transformation	6810
4757	KNN represents a supervised classification algorithm that will give new data points accordingly to the k number or the closest data points, while k-means clustering is an unsupervised clustering algorithm that gathers and groups data into k number of clusters.	How is Knn different from K means clustering	4757
2792	Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the	Is Random Forest a classification technique	2792
2213	A Z-score is a numerical measurement that describes a value's relationship to the mean of a group of values. Z-score is measured in terms of standard deviations from the mean. If a Z-score is 0, it indicates that the data point's score is identical to the mean score.	What does the Z in z score stand for	2213
3244	Hyperparameters are the variables which determines the network structure(Eg: Number of Hidden Units) and the variables which determine how the network is trained(Eg: Learning Rate). Hyperparameters are set before training(before optimizing the weights and bias).	What are the Hyperparameters of a neural network	3244
8913	Natural numbers are a part of the number system which includes all the positive integers from 1 till infinity and are also used for counting purpose. It does not include zero (0). In fact, 1,2,3,4,5,6,7,8,9…., are also called counting numbers.	Is 0 part of the natural numbers	8913
9205	SummaryUse the function cor. test(x,y) to analyze the correlation coefficient between two variables and to get significance level of the correlation.Three possible correlation methods using the function cor.test(x,y): pearson, kendall, spearman.	How do you show the relationship between two variables in R	9205
1008	Quantiles are points in a distribution that relate to the rank order of values in that distribution.  Centiles/percentiles are descriptions of quantiles relative to 100; so the 75th percentile (upper quartile) is 75% or three quarters of the way up an ascending list of sorted values of a sample.	What is difference between quantile and percentile	1008
4810	Bias machine learning can even be applied when interpreting valid or invalid results from an approved data model. Nearly all of the common machine learning biased data types come from our own cognitive biases. Some examples include Anchoring bias, Availability bias, Confirmation bias, and Stability bias.	What is bias in machine learning example	4810
1925	How to find the mean of the probability distribution: StepsStep 1: Convert all the percentages to decimal probabilities. For example:  Step 2: Construct a probability distribution table.  Step 3: Multiply the values in each column.  Step 4: Add the results from step 3 together.	How do you find the distribution in statistics	1925
10407	A t-value is the relative error difference in contrast to the null hypothesis. A p-value, is the statistical significance of a measurement in how correct a statistical evidence part, is.	What is the difference between a t value and p value	10407
2145	Explanation: Correlation is the process of studying the cause and effect relationship that exists between two variables. Correlation coefficient is the measure of the correlation that exists between two variables.	What is the difference between correlation coefficient and correlation	2145
6615	"The method of analyzing an image that has undergone binarization processing is called ""blob analysis"". A blob refers to a lump. Blob analysis is image processing's most basic method for analyzing the shape features of an object, such as the presence, number, area, position, length, and direction of lumps."	What is a blob in image processing	6615
2373	The “moments” of a random variable (or of its distribution) are expected values of powers or related functions of the random variable. The rth moment of X is E(Xr). In particular, the first moment is the mean, µX = E(X). The mean is a measure of the “center” or “location” of a distribution.	What is the moment of a random variable	2373
4038	Linear Regression is a machine learning algorithm based on supervised learning. It performs a regression task. Regression models a target prediction value based on independent variables.  Linear regression performs the task to predict a dependent variable value (y) based on a given independent variable (x).	Is regression an algorithm	4038
7115	The expected value (EV) is an anticipated value for an investment at some point in the future. In statistics and probability analysis, the expected value is calculated by multiplying each of the possible outcomes by the likelihood each outcome will occur and then summing all of those values.	What is expected value of probability distribution	7115
6502	"Loss is often used in the training process to find the ""best"" parameter values for your model (e.g. weights in neural network).  Once you find the optimized parameters above, you use this metrics to evaluate how accurate your model's prediction is compared to the true data."	Why is it useful to track loss while the model is being trained	6502
7836	How to find the mean of the probability distribution: StepsStep 1: Convert all the percentages to decimal probabilities. For example:  Step 2: Construct a probability distribution table.  Step 3: Multiply the values in each column.  Step 4: Add the results from step 3 together.	How do you find the mean of a probability distribution	7836
10162	Chi Square distributions are positively skewed, with the degree of skew decreasing with increasing degrees of freedom. As the degrees of freedom increases, the Chi Square distribution approaches a normal distribution. Figure 1 shows density functions for three Chi Square distributions.	What is the skewness of a chi square distribution	10162
1697	LDA is a probabilistic generative model that extracts the thematic structure in a big document collection. The model assumes that every topic is a distribution of words in the vocabulary, and every document (described over the same vocabulary) is a distribution of a small subset of these topics.	What is LDA clustering	1697
9567	Connected components labeling scans an image and groups its pixels into components based on pixel connectivity, i.e. all pixels in a connected component share similar pixel intensity values and are in some way connected with each other.	What is labeling in image processing	9567
1851	When we know an input value and want to determine the corresponding output value for a function, we evaluate the function.  When we know an output value and want to determine the input values that would produce that output value, we set the output equal to the function's formula and solve for the input.	What is output value	1851
4137	"Q-learning is a model-free reinforcement learning algorithm to learn quality of actions telling an agent what action to take under what circumstances.  ""Q"" names the function that the algorithm computes with the maximum expected rewards for an action taken in a given state."	What is Q function in machine learning	4137
1095	When most dependent variables are numeric, logistic regression and SVM should be the first try for classification. These models are easy to implement, their parameters easy to tune, and the performances are also pretty good. So these models are appropriate for beginners.	Which algorithm is used for classification	1095
8080	"The binomial distribution model allows us to compute the probability of observing a specified number of ""successes"" when the process is repeated a specific number of times (e.g., in a set of patients) and the outcome for a given patient is either a success or a failure."	What are the application of binomial distribution	8080
7700	Systematic sampling is frequently used to select a specified number of records from a computer file. Stratified sampling is commonly used probability method that is superior to random sampling because it reduces sampling error. A stratum is a subset of the population that share at least one common characteristic.	What is stratified and systematic sampling	7700
6781	Univariate and multivariate represent two approaches to statistical analysis. Univariate involves the analysis of a single variable while multivariate analysis examines two or more variables. Most multivariate analysis involves a dependent variable and multiple independent variables.	What is the difference between univariate and multivariate regression	6781
6517	It appears that the median is always closest to the high point (the mode), while the mean tends to be farther out on the tail. In a symmetrical distribution, the mean and the median are both centrally located close to the high point of the distribution.	Where is the mean located in relationship to the median	6517
4814	Assumptions. The assumptions of discriminant analysis are the same as those for MANOVA. The analysis is quite sensitive to outliers and the size of the smallest group must be larger than the number of predictor variables. Multivariate normality: Independent variables are normal for each level of the grouping variable.	What are the assumptions of discriminant analysis	4814
6220	The Mann Whitney U test, sometimes called the Mann Whitney Wilcoxon Test or the Wilcoxon Rank Sum Test, is used to test whether two samples are likely to derive from the same population (i.e., that the two populations have the same shape).	When would you use a Wilcoxon rank sum test	6220
4601	Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data.  A linear regression line has an equation of the form Y = a + bX, where X is the explanatory variable and Y is the dependent variable.	What is meant by linear regression	4601
10128	Descriptive statistics are used to describe the basic features of the data in a study. They provide simple summaries about the sample and the measures.  Descriptive statistics are typically distinguished from inferential statistics. With descriptive statistics you are simply describing what is or what the data shows.	What do you mean by descriptive statistics	10128
10445	Odds Ratio is a measure of the strength of association with an exposure and an outcome.OR > 1 means greater odds of association with the exposure and outcome.OR = 1 means there is no association between exposure and outcome.OR < 1 means there is a lower odds of association between the exposure and outcome.	How do you interpret odds ratio	10445
9424	Named Entity Recognition can automatically scan entire articles and reveal which are the major people, organizations, and places discussed in them. Knowing the relevant tags for each article help in automatically categorizing the articles in defined hierarchies and enable smooth content discovery.	How do you use a named entity recognition	9424
2992	In artificial intelligence, an intelligent agent (IA) refers to an autonomous entity which acts, directing its activity towards achieving goals (i.e. it is an agent), upon an environment using observation through sensors and consequent actuators (i.e. it is intelligent).	What is an agent artificial intelligence	2992
2534	Clean, augment, and preprocess the data into a convenient form, if needed. Conduct an exploratory analysis of the data to get a better sense of it. Using what you find as a guide, construct a model of some aspect of the data. Use the model to answer the question you started with, and validate your results.	How do you make a predictive model in R	2534
10660	On a technical note, estimation of a latent variable is done by analyzing the variance and covariance of the indicators. The measurement model of a latent variable with effect indicators is the set of relationships (modeled as equations) in which the latent variable is set as the predictor of the indicators.	How do you calculate latent variables	10660
5958	T - test is used to if the means of two populations are equal (assuming similar variance) whereas F-test is used to test if the variances of two populations are equal. F - test can also be extended to check whether the means of three or more groups are different or not (ANOVA F-test).	Whats the difference between an F Test and T Test	5958
10640	The first step in backward elimination is pretty simple, you just select a significance level, or select the P-value. Usually, in most cases, a 5% significance level is selected. This means the P-value will be 0.05. You can change this value depending on the project.	What is significance level in backward elimination	10640
6606	An SVM possesses a number of parameters that increase linearly with the linear increase in the size of the input. A NN, on the other hand, doesn't. Even though here we focused especially on single-layer networks, a neural network can have as many layers as we want.	What is the difference between SVM and neural networks	6606
1869	Variance (σ2) in statistics is a measurement of the spread between numbers in a data set. That is, it measures how far each number in the set is from the mean and therefore from every other number in the set.	What does variance mean in at test	1869
6229	The sample mean is a consistent estimator for the population mean. A consistent estimate has insignificant errors (variations) as sample sizes grow larger. More specifically, the probability that those errors will vary by more than a given amount approaches zero as the sample size increases.	Is the sample mean a consistent estimator	6229
2475	The standard deviation (SD) measures the amount of variability, or dispersion, from the individual data values to the mean, while the standard error of the mean (SEM) measures how far the sample mean of the data is likely to be from the true population mean. The SEM is always smaller than the SD.	What is difference between standard deviation and standard error	2475
8138	Linear Growth Model Organisms generally grow in spurts that are dependent on both environment and genetics. Under controlled laboratory conditions, however, one can often observe a constant rate of growth. These periods of constant growth are often referred to as the linear portions of the growth curve.	What is a linear growth curve	8138
4106	The input gate controls the extent to which a new value flows into the cell, the forget gate controls the extent to which a value remains in the cell and the output gate controls the extent to which the value in the cell is used to compute the output activation of the LSTM unit.	What is forget gate in Lstm	4106
3751	The Z score is a test of statistical significance that helps you decide whether or not to reject the null hypothesis. The p-value is the probability that you have falsely rejected the null hypothesis. Z scores are measures of standard deviation.  Both statistics are associated with the standard normal distribution.	Is Z score the test statistic	3751
2405	Sensitivity refers to a test's ability to designate an individual with disease as positive. A highly sensitive test means that there are few false negative results, and thus fewer cases of disease are missed. The specificity of a test is its ability to designate an individual who does not have a disease as negative.	What does it mean if a test is sensitive but not specific	2405
3641	A matrix is a linear operator acting on the vector space of column vectors. Per linear algebra and its isomorphism theorems, any vector space is isomorphic to any other vector space of the same dimension. As such, matrices can be seen as representations of linear operators subject to some basis of column vectors.	Is a matrix an operator	3641
2946	The population mean of the distribution of sample means is the same as the population mean of the distribution being sampled from.  Thus as the sample size increases, the standard deviation of the means decreases; and as the sample size decreases, the standard deviation of the sample means increases.	How does standard deviation change with sample size	2946
2443	If you are broadcasting or reinforcing sound outside, and even your best windscreen can't keep out the persistent low-frequency rumble from wind noise, then stopping it right at the source may be your best option. Highpass filters are excellent for this application.	When should I use high pass filter	2443
10108	Machine Learning This phenomenon states that with a fixed number of training samples, the average (expected) predictive power of a classifier or regressor first increases as number of dimensions or features used is increased but beyond a certain dimensionality it starts deteriorating instead of improving steadily.	What is the curse of dimensionality in machine learning	10108
3026	Fractional scaling helps you to fully utilize your HiDPI monitors, high-resolution laptops by making your desktop not too small or not too big and keep things in balance. Although the resolution settings are there to help they sometimes are not feasible due to the operating system limitations.	What is fractional scaling ubuntu	3026
4578	When small samples are used to estimate a population mean, in cases where the population standard deviation is unknown: the t-distribution must be used to obtain the critical value. the resulting margin of error for a confidence interval estimate will tend to be fairly small.	When small samples are used to estimate a population mean in cases where the population standard deviation is unknown	4578
9240	In probability theory and statistics, Bayes's theorem (alternatively Bayes's law or Bayes's rule), named after Reverend Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event.  Bayesian inference is fundamental to Bayesian statistics.	What is Bayes theorem statistics	9240
5861	Here are some tips for connecting the shape of a histogram with the mean and median:If the histogram is skewed right, the mean is greater than the median.  If the histogram is close to symmetric, then the mean and median are close to each other.  If the histogram is skewed left, the mean is less than the median.	How do you find the mean and median of a histogram	5861
7963	2 Answers. If M is your matrix, then it represents a linear f:Rn→Rn, thus when you do M(T) by row times column multiplication you obtain a vectorial expression for your f(T). Thus ∂M∂T is just the derivative of the vector MT, which you do component-wise.	Can you take the derivative of a matrix	7963
3146	The Formula for the Slope For paired data (x,y) we denote the standard deviation of the x data by sx and the standard deviation of the y data by sy. The formula for the slope a of the regression line is: a = r(sy/sx)	How do you find the slope of the regression line in R	3146
9489	Marginal probability effects are the partial effects of each explanatory variable on. the probability that the observed dependent variable Yi = 1, where in probit. models.	What is marginal effects in probit model	9489
8532	A fast Fourier transform (FFT) is an algorithm that computes the discrete Fourier transform (DFT) of a sequence, or its inverse (IDFT). Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa.	What is FFT and its applications in DAA	8532
6945	The variance (symbolized by S2) and standard deviation (the square root of the variance, symbolized by S) are the most commonly used measures of spread. We know that variance is a measure of how spread out a data set is. It is calculated as the average squared deviation of each number from the mean of a data set.	What is variance and deviation	6945
3857	In the terminology of machine learning, classification is considered an instance of supervised learning, i.e., learning where a training set of correctly identified observations is available.  An algorithm that implements classification, especially in a concrete implementation, is known as a classifier.	What is classification learning	3857
5204	training set—a subset to train a model. test set—a subset to test the trained model.	What is meant by training set and test set	5204
7591	Random Forest Algorithm The Random Forest ML Algorithm is a versatile supervised learning algorithm that's used for both classification and regression analysis tasks.	Which algorithms can be used for both classification and regression tasks	7591
5096	- if R-squared value 0.3 < r < 0.5 this value is generally considered a weak or low effect size, - if R-squared value 0.5 < r < 0.7 this value is generally considered a Moderate effect size, - if R-squared value r > 0.7 this value is generally considered strong effect size, Ref: Source: Moore, D. S., Notz, W.	What does a weak R squared value mean	5096
2338	the t-test is robust against non-normality; this test is in doubt only when there can be serious outliers (long-tailed distributions – note the finite variance assumption); or when sample sizes are small and distributions are far from normal. 10 / 20 Page 20 . . .	Is t test robust to violations of normality	2338
6402	Therefore, a number of alternative ways of handling the missing data has been developed.Listwise or case deletion.  Pairwise deletion.  Mean substitution.  Regression imputation.  Last observation carried forward.  Maximum likelihood.  Expectation-Maximization.  Multiple imputation.More items•	How do you handle missing data in regression analysis	6402
8850	A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agent's gain is another agent's loss).	What is an adversarial neural network	8850
1616	The normalisation ensures that the inputs have a mean of 0 and a standard deviation of 1, meaning that the input distribution to every neuron will be the same, thereby fixing the problem of internal covariate shift and providing regularisation.	How does Batch normalization address the problem of Internal Covariate Shift	1616
6489	2.1 The Early Days. Constraint satisfaction, in its basic form, involves finding a value for each one of a set of problem variables where constraints specify that some subsets of values cannot be used together.	What is constraints satisfaction problem in AI	6489
5203	Cohen came up with a mechanism to calculate a value which represents the level of agreement between judges negating the agreement by chance.  You can see that balls which are agreed on by chance are removed both from agreed and total number of balls. And that is the whole intuition of Kappa value aka Kappa coefficient.	What is an intuitive explanation of Cohens kappa statistic	5203
2633	The false discovery rate (FDR) is a method of conceptualizing the rate of type I errors in null hypothesis testing when conducting multiple comparisons.  Thus, FDR-controlling procedures have greater power, at the cost of increased numbers of Type I errors.	What is FDR correction	2633
5339	Mean and Variance of a Binomial Distribution The variance of a Binomial Variable is always less than its mean. ∴ npq<np. For Maximum Variance: p=q=0.5 and σmax = n/4.	What is the maximum value of the variance of binomial distribution	5339
7988	Classification accuracy is our starting point. It is the number of correct predictions made divided by the total number of predictions made, multiplied by 100 to turn it into a percentage.	What is classification accuracy	7988
9740	5 Successful ExamplesSentiment Analysis Examples.Reputation Management - Social Media Monitoring - Brand Monitoring.Market Research, Competitor Analysis.Product Analytics.Customer Analysis.Customer Support.	What are the most popular application areas for sentiment analysis	9740
1984	This is a form of regression, that constrains/ regularizes or shrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or flexible model, so as to avoid the risk of overfitting. A simple relation for linear regression looks like this.	What is the use of regularization in machine learning	1984
78	Advantages and Disadvantages of Artificial Intelligence Reduction in Human Error: The phrase “human error” was born because humans make mistakes from time to time.   Takes risks instead of Humans:   Available 24x7:   Helping in Repetitive Jobs:   Digital Assistance:   Faster Decisions:   Daily Applications:   New Inventions:	What are some of the benefits of AI development	78
8254	Lab Color is a more accurate color space.  It specifies a color using a 3-axis system. The a-axis (green to red), b-axis (blue to yellow) and Lightness axis. The best thing about Lab Color is that it's device-independent. That means that it's easier to achieve exactly the same color across different media.	What does lab color mean	8254
2406	In-group favoritism, sometimes known as in-group–out-group bias, in-group bias, intergroup bias, or in-group preference, is a pattern of favoring members of one's in-group over out-group members. This can be expressed in evaluation of others, in allocation of resources, and in many other ways.	What does having biased groups mean	2406
8029	Basically, you're just pre-setting some of the weights of the new network. Be sure to initialize the new connections to have similar distributions. Make the last layer a concatenation of their results and then add another few layers. Make the last layer a concatenation of their results and the original input.	How do I connect two neural networks	8029
366	The matrix norm is similar to the magnitude of a vector. It is useful whenever a system/problem can be formulated into a matrix that has some physical meaning.	What is Matrix norm used for	366
3309	Factor-Label Method	What does dimensional analysis mean	3309
7229	In the context of gradient boosting, the training loss is the function that is optimized using gradient descent, e.g., the “gradient” part of gradient boosting models. Specifically, the gradient of the training loss is used to change the target variables for each successive tree.	What is loss function in gradient boosting	7229
8547	In probability theory and statistics, the exponential distribution is the probability distribution of the time between events in a Poisson point process, i.e., a process in which events occur continuously and independently at a constant average rate.	What does it mean to be exponentially distributed	8547
9336	Exponential moving averages, or EMA, give more weighting to recent prices. They reduce the effect of the lag that comes from using previous price data and can help you identify a trend earlier, so it's a useful indicator for trading short-term contracts.	In trading why would we use the exponential moving average over the simple moving average	9336
1139	1 Introduction. The partial least squares (PLS) algorithm was first introduced for regression tasks and then evolved into a classification method that is well known as PLS-discriminant analysis (PLS-DA).	Whats the abbreviation for orthogonal partial least squares discriminant analysis	1139
4083	Decision tree builds classification or regression models in the form of a tree structure.  The topmost decision node in a tree which corresponds to the best predictor called root node. Decision trees can handle both categorical and numerical data.	Can decision trees be used for classification	4083
9417	In simple terms, a quantile is where a sample is divided into equal-sized, adjacent, subgroups (that's why it's sometimes called a “fractile“).  The median cuts a distribution into two equal areas and so it is sometimes called 2-quantile. Quartiles are also quantiles; they divide the distribution into four equal parts.	What is quantile example	9417
1222	Probabilistic data structures are a group of data structures that are extremely useful for big data and streaming applications. Generally speaking, these data structures use hash functions to randomize and compactly represent a set of items.	What is a probabilistic data structure	1222
4442	There are several methods through which you can evaluate a Logistic regression model:Goodness of Fit.Likelihood ratio test.Wald's Test.Hosmer-Lemeshov Test.ROC (AUC) curve.Confidence Intervals.Correlation factors and coefficients.Variance Inflation Factor(VIF)More items	How do you evaluate a logit model	4442
3554	Synset is a special kind of a simple interface that is present in NLTK to look up words in WordNet. Synset instances are the groupings of synonymous words that express the same concept. Some of the words have only one Synset and some have several.	What is a Synset in WordNet	3554
2815	Stratified random sampling refers to a sampling method that has the following properties.The population consists of N elements.The population is divided into H groups, called strata.Each element of the population can be assigned to one, and only one, stratum.More items	What are the properties of stratified random sampling	2815
5769	The solution involves four steps.Make sure the samples from each population are big enough to model differences with a normal distribution.  Find the mean of the difference in sample proportions: E(p1 - p2) = P1 - P2 = 0.52 - 0.47 = 0.05.Find the standard deviation of the difference.  Find the probability.	How do you find the difference between sample proportions	5769
7434	The normal distribution is a probability distribution. As with any probability distribution, the proportion of the area that falls under the curve between two points on a probability distribution plot indicates the probability that a value will fall within that interval.	How is the concept of probability related to the normal distribution	7434
6541	The median is another form of an average. It usually represents the middle number in a given sequence of numbers when it's ordered by rank.	Is the median the average	6541
6184	Similar to the t-test/correlation equivalence, the relationship between two dichotomous variables is the same as the difference between two groups when the dependent variable is dichotmous. The appropriate test to compare group differences with a dichotmous outcome is the chi-square statistic.	Which statistical technique is appropriate for find out the correlation between two dichotomous variables	6184
9248	Gaussian RBF(Radial Basis Function) is another popular Kernel method used in SVM models for more. RBF kernel is a function whose value depends on the distance from the origin or from some point. Gaussian Kernel is of the following format; ||X1 — X2 || = Euclidean distance between X1 & X2.	What is gaussian kernel in SVM	9248
729	In short, it ensures each subgroup within the population receives proper representation within the sample. As a result, stratified random sampling provides better coverage of the population since the researchers have control over the subgroups to ensure all of them are represented in the sampling.	What's stratified sampling Why is it preferred	729
1723	Dense layer is the regular deeply connected neural network layer. It is most common and frequently used layer. Dense layer does the below operation on the input and return the output.  dot represent numpy dot product of all input and its corresponding weights.	What is dense layer in sequential model	1723
4431	Adjusted R-squared value can be calculated based on value of r-squared, number of independent variables (predictors), total sample size. Every time you add a independent variable to a model, the R-squared increases, even if the independent variable is insignificant. It never declines.	How is adjusted r2 calculated	4431
8620	The primary goal of EDA is to maximize the analyst's insight into a data set and into the underlying structure of a data set, while providing all of the specific items that an analyst would want to extract from a data set, such as: a good-fitting, parsimonious model. a list of outliers.	What are the two goals of exploratory data analysis	8620
3187	In your case, with three groups, you'd run ANOVA. If you need to compare the 5-point scales one at a time, then non-parametric statistics are more appropriate. To compare two groups use the Mann-Whitney U test. To compare three or more groups use the Kruskal–Wallis H test.	Which statistical test should I use to compare 3 ordinal variables	3187
1584	In the context of conventional artificial neural networks convergence describes a progression towards a network state where the network has learned to properly respond to a set of training patterns within some margin of error.	What is convergence in neural network	1584
6	"In terms of machine learning, ""concept learning"" can be defined as: “The problem of searching through a predefined space of potential hypotheses for the hypothesis that best fits the training examples.” — Tom Michell. Much of human learning involves acquiring general concepts from past experiences."	What is concept in machine learning	6
243	The agent function is a mathematical function that maps a sequence of perceptions into action. The function is implemented as the agent program. The part of the agent taking an action is called an actuator. environment -> sensors -> agent function -> actuators -> environment.	What is Agent function in artificial intelligence	243
26	There are two reasons why Mean Squared Error(MSE) is a bad choice for binary classification problems:  If we use maximum likelihood estimation(MLE), assuming that the data is from a normal distribution(a wrong assumption, by the way), we get the MSE as a Cost function for optimizing our model.	Why is squared loss bad for classification	26
2903	Sentiment analysis also means you'll be able to detect changes in the overall opinion towards your brand. Because it provides insight into the way your customers are feeling when they approach you, you can monitor trends and see if overall opinion towards your company drops or rises.	What are the benefits of sentiment analysis	2903
5858	The main difference between probability and likelihood is that the former is normalized.  Probability refers to the occurrence of future events, while a likelihood refers to past events with known outcomes. Probability is used when describing a function of the outcome given a fixed parameter value.	What is the difference between probability and likelihood	5858
4770	A decision tree is simply a set of cascading questions. When you get a data point (i.e. set of features and values), you use each attribute (i.e. a value of a given feature of the data point) to answer a question. The answer to each question decides the next question.	How do you explain a decision tree	4770
7717	Logistic regression is quite different than linear regression in that it does not make several of the key assumptions that linear and general linear models (as well as other ordinary least squares algorithm based models) hold so close: (1) logistic regression does not require a linear relationship between the dependent	Does logistic regression data need to be normally distributed	7717
9664	It is often pointed out that when ANOVA is applied to just two groups, and when therefore one can calculate both a t-statistic and an F-statistic from the same data, it happens that the two are related by the simple formula: t2 = F.	What is the relationship between F statistic and T statistic	9664
10954	A classification is an ordered set of related categories used to group data according to its similarities. It consists of codes and descriptors and allows survey responses to be put into meaningful categories in order to produce useful data. A classification is a useful tool for anyone developing statistical surveys.	What is meant by classification in statistics	10954
9789	A set is countable if: (1) it is finite, or (2) it has the same cardinality (size) as the set of natural numbers (i.e., denumerable). Equivalently, a set is countable if it has the same cardinality as some subset of the set of natural numbers. Otherwise, it is uncountable.	What is countable set in analysis	9789
6901	Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.	What is NLP problem	6901
7748	Z-tests are statistical calculations that can be used to compare population means to a sample's. T-tests are calculations used to test a hypothesis, but they are most useful when we need to determine if there is a statistically significant difference between two independent sample groups.	What is the difference between z test and t test	7748
5672	If a variable can take on any value between two specified values, it is called a continuous variable; otherwise, it is called a discrete variable. Some examples will clarify the difference between discrete and continuous variables.  The number of heads could be any integer value between 0 and plus infinity.	What is difference between discrete and continuous variable	5672
4007	Artificial intelligence (AI) is a branch of computer science.  Most AI programs are not used to control robots. Even when AI is used to control robots, the AI algorithms are only part of the larger robotic system, which also includes sensors, actuators, and non-AI programming.	How artificial intelligence is related to robotics	4007
923	The model works by first splitting the input image into a grid of cells, where each cell is responsible for predicting a bounding box if the center of a bounding box falls within it. Each grid cell predicts a bounding box involving the x, y coordinate and the width and height and the confidence.	How does a bounding box work	923
1891	Autoregression is a time series model that uses observations from previous time steps as input to a regression equation to predict the value at the next time step. It is a very simple idea that can result in accurate forecasts on a range of time series problems.	What are autoregressive models in machine learning	1891
725	Gradient descent is best used when the parameters cannot be calculated analytically (e.g. using linear algebra) and must be searched for by an optimization algorithm.	What are the conditions in which Gradient descent is applied	725
2014	Softmax is an activation function that outputs the probability for each class and these probabilities will sum up to one. Cross Entropy loss is just the sum of the negative logarithm of the probabilities.  Therefore, Softmax loss is just these two appended together.	Is Softmax a loss function	2014
6252	Parametric statistics are based on assumptions about the distribution of population from which the sample was taken. Nonparametric statistics are not based on assumptions, that is, the data can be collected from a sample that does not follow a specific distribution.	What is parametric statistics and nonparametric statistics	6252
1422	Dimensional Analysis (also called Factor-Label Method or the Unit Factor Method) is a problem-solving method that uses the fact that any number or expression can be multiplied by one without changing its value. It is a useful technique.	What is dimensional analysis method	1422
8438	Having good test re-test reliability signifies the internal validity of a test and ensures that the measurements obtained in one sitting are both representative and stable over time.	Why is test retest reliability important	8438
3511	Multidimensional scaling is a visual representation of distances or dissimilarities between sets of objects.  Objects that are more similar (or have shorter distances) are closer together on the graph than objects that are less similar (or have longer distances).	What is multidimensional scaling in statistics	3511
283	Feature Selection vs Dimensionality Reduction While both methods are used for reducing the number of features in a dataset, there is an important difference. Feature selection is simply selecting and excluding given features without changing them. Dimensionality reduction transforms features into a lower dimension.	Whats the difference between dimensionality reduction and feature selection	283
9207	Top 10 Machine Learning ApplicationsTraffic Alerts.Social Media.Transportation and Commuting.Products Recommendations.Virtual Personal Assistants.Self Driving Cars.Dynamic Pricing.Google Translate.More items•	What are the applications of machine learning	9207
9010	Explanation: Simple reflex agent is based on the present condition and so it is condition action rule. 5. What are the composition for agents in artificial intelligence? Explanation: An agent program will implement function mapping percepts to actions.	What are the composition for agents in artificial intelligence	9010
7917	Linear regression is a linear method to model the relationship between your independent variables and your dependent variables. Advantages include how simple it is and ease with implementation and disadvantages include how is' lack of practicality and how most problems in our real world aren't “linear”.	What are the advantages and disadvantages of linear regression	7917
2856	A greedy algorithm is used to construct a Huffman tree during Huffman coding where it finds an optimal solution. In decision tree learning, greedy algorithms are commonly used, however they are not guaranteed to find the optimal solution. One popular such algorithm is the ID3 algorithm for decision tree construction.	Where greedy algorithm is used	2856
344	This approach involves either forward selection, adding features one at a time, or backward selection, removing features one at a time until some criterion is reached. Additionally, a bidirectional selection method is available that involves adding or removing a feature at each step.	What is backward selection	344
5117	Spectroscopy in chemistry and physics, a method of analyzing the properties of matter from their electromagnetic interactions. Spectral estimation, in statistics and signal processing, an algorithm that estimates the strength of different frequency components (the power spectrum) of a time-domain signal.	How is spectral analysis used	5117
1495	Batch size controls the accuracy of the estimate of the error gradient when training neural networks. Batch, Stochastic, and Minibatch gradient descent are the three main flavors of the learning algorithm. There is a tension between batch size and the speed and stability of the learning process.	Does batch size affect accuracy	1495
6367	4:1410:53Suggested clip · 113 secondsStochastic Gradient Descent, Clearly Explained!!! - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you use stochastic gradient descent	6367
3403	The simplest solution is to use other activation functions, such as ReLU, which doesn't cause a small derivative. Residual networks are another solution, as they provide residual connections straight to earlier layers.	How do you solve the vanishing gradient problem	3403
9968	"In this view, associative networks are fundamentally unorganized lists of features. By specifying what attributes to include, a frame structure promises to provide the ""framework"" upon which to organize and hang what a consumer knows about a product."	What do you know about associative network and frames	9968
10645	You might also see this written as something like “An unbiased estimator is when the mean of the statistic's sampling distribution is equal to the population's parameter.” This essentially means the same thing: if the statistic equals the parameter, then it's unbiased.	How do you prove an estimator is unbiased	10645
6099	You can use a bivariate Pearson Correlation to test whether there is a statistically significant linear relationship between height and weight, and to determine the strength and direction of the association.	When would you use a bivariate correlation	6099
7192	Fuelled by successes in Computer Go, Monte Carlo tree search (MCTS) has achieved widespread adoption within the games community. Its links to traditional reinforcement learning (RL) methods have been outlined in the past; however, the use of RL techniques within tree search has not been thoroughly studied yet.	Is Monte Carlo Tree Search reinforcement learning	7192
6071	A latent variable is a random variable which you can't observe neither in training nor in test phase . It is derived from the latin word latēre which means hidden. Intuitionally, some phenomenons like incidences,altruism one can't measure while others like speed or height one can.	What are latent variables in machine learning	6071
6085	The three main metrics used to evaluate a classification model are accuracy, precision, and recall. Accuracy is defined as the percentage of correct predictions for the test data. It can be calculated easily by dividing the number of correct predictions by the number of total predictions.	How do you evaluate machine learning algorithms	6085
2359	"Conditional random fields (CRFs) are a class of statistical modeling method often applied in pattern recognition and machine learning and used for structured prediction. Whereas a classifier predicts a label for a single sample without considering ""neighboring"" samples, a CRF can take context into account."	What is CRF in machine learning	2359
8830	Formally, a statistic T(X1,···,Xn) is said to be sufficient for θ if the conditional distribution of X1,···,Xn, given T = t, does not depend on θ for any value of t. In other words, given the value of T, we can gain no more knowledge about θ from knowing more about the probability distribution of X1,···,Xn.	How do you prove a statistic is sufficient	8830
879	Anomaly detection (or outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.	What is outlier detection in machine learning	879
263	Machine learning usually has to achieve multiple targets, which are often conflicting with each other. Multi-objective model selection to improve the performance of learning models, such as neural networks, support vector machines, decision trees, and fuzzy systems.	What are some Machine Learning techniques for objective optimization	263
1603	Two random variables X and Y are said to be bivariate normal, or jointly normal, if aX+bY has a normal distribution for all a,b∈R. In the above definition, if we let a=b=0, then aX+bY=0. We agree that the constant zero is a normal random variable with mean and variance 0.	How do you know if a bivariate is normal distribution	1603
6653	The eigenvalues and eigenvectors of a matrix are often used in the analysis of financial data and are integral in extracting useful information from the raw data. They can be used for predicting stock prices and analyzing correlations between various stocks, corresponding to different companies.	Where do we use eigenvalues	6653
7152	Nonparametric tests are sometimes called distribution-free tests because they are based on fewer assumptions (e.g., they do not assume that the outcome is approximately normally distributed).  There are several statistical tests that can be used to assess whether data are likely from a normal distribution.	Why would you use a nonparametric test	7152
9388	Rather than using the past values of the forecast variable in a regression, a moving average model uses past forecast errors in a regression-like model.  While, the autoregressive model(AR) uses the past forecasts to predict future values.	What are the differences between autoregressive and moving average models	9388
8877	Coef. A regression coefficient describes the size and direction of the relationship between a predictor and the response variable. Coefficients are the numbers by which the values of the term are multiplied in a regression equation.	What do the coefficients in logistic regression mean	8877
10306	RELU activation solves this by having a gradient slope of 1, so during backpropagation, there isn't gradients passed back that are progressively getting smaller and smaller. but instead they are staying the same, which is how RELU solves the vanishing gradient problem.	How does ReLU solve vanishing gradient problem	10306
8749	As you have seen, in order to perform a likelihood ratio test, one must estimate both of the models one wishes to compare. The advantage of the Wald and Lagrange multiplier (or score) tests is that they approximate the LR test, but require that only one model be estimated.	How do you calculate the likelihood ratio	8749
5179	"Answer. When the ROC curve dips prominently into the lower right half of the graph, this is likely a sign that either the wrong State Value has been specified or the wrong Test-State association direction has been specified in the ""Test Direction"" area of the ""ROC Curve:Options"" dialog."	Why is my ROC curve inverted	5179
2571	The Least Squares AssumptionsUseful Books for This Topic:  ASSUMPTION #1: The conditional distribution of a given error term given a level of an independent variable x has a mean of zero.  ASSUMPTION #2: (X,Y) for all n are independently and identically distributed.  ASSUMPTION #3: Large outliers are unlikely.More items•	What are the least squares assumptions	2571
3826	Keras is a neural network library while TensorFlow is the open-source library for a number of various tasks in machine learning. TensorFlow provides both high-level and low-level APIs while Keras provides only high-level APIs.	What is the relationship between tensorflow with keras	3826
9505	It's more of an approach than a process. Predictive analytics and machine learning go hand-in-hand, as predictive models typically include a machine learning algorithm. These models can be trained over time to respond to new data or values, delivering the results the business needs.	Is predictive modeling machine learning	9505
4093	8 Powerful Tricks That Make You Grasp New Concepts Faster1) Use mental associations. Colours, acronyms and word associations can be especially useful tools to help you hold on to thoughts, patterns and concepts.  2) Apply the 80/20 principle.  3) Break it down.  4) Write it down.  5) Connect existing knowledge.  6) Try Brain exercises.  7) Learn your way.  8) Teach other people.	How do you understand a concept deeply	4093
10524	Linear regression is used to find the best fitting line between all the points of your dataset (by computing the minimum of a given distance), it does not, in itself, reduce the dimensionality of your data.	Why cant we use linear regression for dimension reduction	10524
1016	Convergence in distribution is in some sense the weakest type of convergence. All it says is that the CDF of Xn's converges to the CDF of X as n goes to infinity. It does not require any dependence between the Xn's and X. We saw this type of convergence before when we discussed the central limit theorem.	What does convergence in distribution mean	1016
4868	Hidden Markov models have been around for a pretty long time (1970s at least). It's a misnomer to call them machine learning algorithms.  It is most useful, IMO, for state sequence estimation, which is not a machine learning problem since it is for a dynamical process, not a static classification task.	Is Markov model machine learning	4868
3565	The Unsharp Mask filter adjusts the contrast of the edge detail and creates the illusion of a more focused image.	What does the unsharp mask filter do	3565
6941	The joint behavior of two random variables X and Y is determined by the. joint cumulative distribution function (cdf):(1.1) FXY (x, y) = P(X ≤ x, Y ≤ y),where X and Y are continuous or discrete. For example, the probability.  P(x1 ≤ X ≤ x2,y1 ≤ Y ≤ y2) = F(x2,y2) − F(x2,y1) − F(x1,y2) + F(x1,y1).	How do you find the joint distribution of two random variables	6941
4326	Spearman Rank Correlation: Worked Example (No Tied Ranks)The formula for the Spearman rank correlation coefficient when there are no tied ranks is:  Step 1: Find the ranks for each individual subject.  Step 2: Add a third column, d, to your data.  Step 5: Insert the values into the formula.More items•	How do you use Spearman's rank correlation coefficient	4326
4566	Knowledge-representation is a field of artificial intelligence that focuses on designing computer representations that capture information about the world that can be used to solve complex problems.  Virtually all knowledge representation languages have a reasoning or inference engine as part of the system.	What do you mean by knowledge representation	4566
664	Feature extraction describes the relevant shape information contained in a pattern so that the task of classifying the pattern is made easy by a formal procedure. In pattern recognition and in image processing, feature extraction is a special form of dimensionality reduction.	What is feature extraction in image processing	664
6236	The goodness of fit test is a statistical hypothesis test to see how well sample data fit a distribution from a population with a normal distribution. Put differently, this test shows if your sample data represents the data you would expect to find in the actual population or if it is somehow skewed.	What is the purpose of a goodness of fit test	6236
7036	If your p-value is less than or equal to the set significance level, the data is considered statistically significant. As a general rule, the significance level (or alpha) is commonly set to 0.05, meaning that the probability of observing the differences seen in your data by chance is just 5%.	How do you test if a difference is statistically significant	7036
7794	Machine learning is changing the world by transforming all segments including healthcare services, education, transport, food, entertainment, and different assembly line and many more. It will impact lives in almost every aspect, including housing, cars, shopping, food ordering, etc.	How is Machine Learning changing the world	7794
2353	In simple linear regression a single independent variable is used to predict the value of a dependent variable. In multiple linear regression two or more independent variables are used to predict the value of a dependent variable. The difference between the two is the number of independent variables.	What should I choose simple linear regression or multiple linear regression	2353
9494	Prior probability represents what is originally believed before new evidence is introduced, and posterior probability takes this new information into account.  A posterior probability can subsequently become a prior for a new updated posterior probability as new information arises and is incorporated into the analysis.	What is prior and posterior	9494
7911	The Moment Generating Function of the Binomial Distribution (3) dMx(t) dt = n(q + pet)n−1pet = npet(q + pet)n−1. Evaluating this at t = 0 gives (4) E(x) = np(q + p)n−1 = np.	What is the moment generating function of binomial distribution	7911
6727	It is usually defined as the ratio of the variance to the mean. As a formula, that's: D = σ2 / μ.	How do you find the variance of a ratio	6727
6321	Expectation maximization is applicable whenever the data are missing completely at random or missing at random-but unsuitable when the data are not missing at random.	What is Expectation Maximization for missing data	6321
4889	Biased but consistent , it approaches the correct value, and so it is consistent. ), these are both negatively biased but consistent estimators.	Can a biased estimator be consistent	4889
7297	Importance sampling is a variance reduction technique that can be used in the Monte Carlo method. The idea behind importance sampling is that certain values of the input random variables in a simulation have more impact on the parameter being estimated than others.	What is the importance of a sampling approach to the estimation of expected values in Monte Carlo algorithms	7297
9369	To perform principal component analysis using the correlation matrix using the prcomp() function, set the scale argument to TRUE . Plot the first two PCs of the correlation matrix using the autoplot() function.	How do you do principal component analysis in R	9369
9439	Logistic regression is a supervised learning classification algorithm used to predict the probability of a target variable. The nature of target or dependent variable is dichotomous, which means there would be only two possible classes.  Mathematically, a logistic regression model predicts P(Y=1) as a function of X.	How does logistic regression algorithm work	9439
2453	In the study of probability theory, the central limit theorem (CLT) states that the distribution of sample approximates a normal distribution (also known as a “bell curve”) as the sample size becomes larger, assuming that all samples are identical in size, and regardless of the population distribution shape.	What is central limit theorem in probability	2453
5039	Machine learning algorithms are the engines of machine learning, meaning it is the algorithms that turn a data set into a model. Which kind of algorithm works best (supervised, unsupervised, classification, regression, etc.)	What is learning algorithm in machine learning	5039
10038	Risk tolerance	What is the opposite of risk aversion	10038
8184	There are basically two methods to reduce autocorrelation, of which the first one is most important:Improve model fit. Try to capture structure in the data in the model.  If no more predictors can be added, include an AR1 model.	How do you fix autocorrelation	8184
4233	In statistics, Bayesian linear regression is an approach to linear regression in which the statistical analysis is undertaken within the context of Bayesian inference.	Is linear regression Bayesian	4233
10212	0:3910:15Suggested clip · 118 secondsConducting a Multiple Regression using Microsoft Excel Data YouTubeStart of suggested clipEnd of suggested clip	How do you do a regression analysis with multiple variables	10212
3662	Creative Ways to Benefit From Social Media AnalyticsEngage Better With Your Audience. Many businesses have a hard time keeping up with the vast amount of social media activity that impacts their brand.  Improve Customer Relations.  Monitor Your Competition.  Identify and Engage With Your Top Customers.  Find Out Where Your Industry is Heading.	What are the benefits of social media analytics	3662
205	Area in TailsConfidence LevelArea between 0 and z-scorez-score50%0.25000.67480%0.40001.28290%0.45001.64595%0.47501.9602 more rows	What is the z score for 50 confidence interval	205
5647	Advantages of Naive Bayes ClassifierIt is simple and easy to implement.It doesn't require as much training data.It handles both continuous and discrete data.It is highly scalable with the number of predictors and data points.It is fast and can be used to make real-time predictions.More items•	What are the advantages of using a naive Bayes classifier as opposed to other methods	5647
552	Since a Naive Bayes text classifier is based on the Bayes's Theorem, which helps us compute the conditional probabilities of occurrence of two events based on the probabilities of occurrence of each individual event, encoding those probabilities is extremely useful.	How does naive Bayes work in text classification	552
8776	The Taguchi loss function is graphical depiction of loss developed by the Japanese business statistician Genichi Taguchi to describe a phenomenon affecting the value of products produced by a company.  This means that if the product dimension goes out of the tolerance limit the quality of the product drops suddenly.	What does the Taguchi loss function indicate	8776
4640	Adam can be looked at as a combination of RMSprop and Stochastic Gradient Descent with momentum. It uses the squared gradients to scale the learning rate like RMSprop and it takes advantage of momentum by using moving average of the gradient instead of gradient itself like SGD with momentum.	How does the Adam Optimizer work	4640
5911	In (and after) TensorFlow version 0.11. 0RC1, you can save and restore your model directly by calling tf. train. export_meta_graph and tf.	How do I save and restore model in Tensorflow	5911
5087	In computer science, a universal Turing machine (UTM) is a Turing machine that simulates an arbitrary Turing machine on arbitrary input.  In terms of computational complexity, a multi-tape universal Turing machine need only be slower by logarithmic factor compared to the machines it simulates.	What is universal Turing machine in TOC	5087
5595	A feature vector is just a vector that contains information describing an object's important characteristics. In image processing, features can take many forms. A simple feature representation of an image is the raw intensity value of each pixel. However, more complicated feature representations are also possible.	What is CNN feature vector	5595
5120	The weighted kappa is calculated using a predefined table of weights which measure the degree of disagreement between the two raters, the higher the disagreement the higher the weight.	What is weighted kappa	5120
2328	Decision Tree node splitting is an important step, the core issue is how to choose the splitting attribute.  5, the splitting criteria is calculating information gain of each attribute, then the attribute with the maximum information gain or information gain ratio is selected as splitting attribute.	What is splitting criterion in data mining	2328
2670	Multinomial logistic regression does have assumptions, such as the assumption of independence among the dependent variable choices. This assumption states that the choice of or membership in one category is not related to the choice or membership of another category (i.e., the dependent variable).	What are the assumptions of multinomial logistic regression	2670
5719	he confidence interval tells you more than just the possible range around the estimate. It also tells you about how stable the estimate is. A stable estimate is one that would be close to the same value if the survey were repeated.	What does the confidence interval tell you	5719
1969	Assuming the sample size is constant across sampling methods, cluster sampling generally provides less precision than either simple random sampling or stratified sampling. This is the main disadvantage of cluster sampling.	What is the disadvantage of cluster sampling	1969
5589	The target variable of a dataset is the feature of a dataset about which you want to gain a deeper understanding. A supervised machine learning algorithm uses historical data to learn patterns and uncover relationships between other features of your dataset and the target.	What is a target in machine learning	5589
5873	Bias is stated as a penchant that prevents objective consideration of an issue or situation; basically the formation of opinion beforehand without any examination. Selection is stated as the act of choosing or selecting a preference; resulting in a carefully chosen and representative choice.	What is the difference between bias and selection	5873
499	Using proper validation techniques helps you understand your model, but most importantly, estimate an unbiased generalization performance.Splitting your data.  k-Fold Cross-Validation (k-Fold CV)  Leave-one-out Cross-Validation (LOOCV)  Nested Cross-Validation.  Time Series CV.  Comparing Models.	How do you validate a model performance	499
6149	One drawback of boxplots is that they tend to emphasize the tails of a distribution, which are the least certain points in the data set. They also hide many of the details of the distribution.	What are the disadvantages of a box plot	6149
1558	Preparing Your Dataset for Machine Learning: 8 Basic Techniques That Make Your Data BetterArticulate the problem early.Establish data collection mechanisms.Format data to make it consistent.Reduce data.Complete data cleaning.Decompose data.Rescale data.Discretize data.	How would you prepare a dataset for deep learning	1558
4474	– Rejection sampling: reject samples disagreeing with evidence. – Markov chain Monte Carlo (MCMC): sample from a stochastic process. whose stationary distribution is the true posterior.	What does rejection sampling mean in Bayesian nets	4474
2410	Every probability pi is a number between 0 and 1, and the sum of all the probabilities is equal to 1. Examples of discrete random variables include: The number of eggs that a hen lays in a given day (it can't be 2.3) The number of people going to a given soccer match.	What is an example of a discrete random variable	2410
10762	A sequence of random variables is covariance stationary if all the terms of the sequence have the same mean, and if the covariance between any two terms of the sequence depends only on the relative positions of the two terms, that is, on how far apart they are located from each other, and not on their absolute position	How do you prove covariance stationary	10762
6561	Auxiliary Classifiers are type of architectural component that seek to improve the convergence of very deep networks. They are classifier heads we attach to layers before the end of the network.	What is auxiliary classifier	6561
6897	Try to avoid implementing cheap tricks to make your code run faster.Optimize your Code using Appropriate Algorithm.  Optimize Your Code for Memory.  printf and scanf Vs cout and cin.  Using Operators.  if Condition Optimization.  Problems with Functions.  Optimizing Loops.  Data Structure Optimization.More items•	How do you optimize code	6897
694	Word2Vec slightly customizes the process and calls it negative sampling. In Word2Vec, the words for the negative samples (used for the corrupted pairs) are drawn from a specially designed distribution, which favours less frequent words to be drawn more often.	What is negative sampling in Word2Vec	694
1737	Feature extraction is a general term for methods of constructing combinations of the variables to get around these problems while still describing the data with sufficient accuracy. Many machine learning practitioners believe that properly optimized feature extraction is the key to effective model construction.	What are feature extraction algorithms	1737
4540	A discrete distribution is a statistical distribution that shows the probabilities of discrete (countable) outcomes, such as 1, 2, 3  Overall, the concepts of discrete and continuous probability distributions and the random variables they describe are the underpinnings of probability theory and statistical analysis.	What are discrete distributions	4540
2108	Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. Specific applications of AI include expert systems, natural language processing (NLP), speech recognition and machine vision.	Is AI Artificial Intelligence	2108
10725	2 Answers. If you have two classes (i.e. binary classification), you should use a binary crossentropy loss. If you have more than two you should use a categorical crossentropy loss.	How do I tell which loss function is suitable for image classification	10725
5225	Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training.  Unlabeled data, when used in conjunction with a small amount of labeled data, can produce considerable improvement in learning accuracy.	Does unlabeled data really help in semi supervised learning	5225
6092	Classification is a type of supervised learning. It specifies the class to which data elements belong to and is best used when the output has finite and discrete values. It predicts a class for an input variable as well.	What is ML classification	6092
4592	As already discussed, SVM aims at maximizing the geometric margin and returns the corresponding hyperplane.  Such points are called as support vectors (fig. - 1). Therefore, the optimization problem as defined above is equivalent to the problem of maximizing the margin value (not geometric/functional margin values).	What does SVM optimize	4592
1967	At Google, we call it Wide & Deep Learning. It's useful for generic large-scale regression and classification problems with sparse inputs (categorical features with a large number of possible feature values), such as recommender systems, search, and ranking problems.	What is wide and deep learning	1967
9235	A studentized residual is calculated by dividing the residual by an estimate of its standard deviation. The standard deviation for each residual is computed with the observation excluded. For this reason, studentized residuals are sometimes referred to as externally studentized residuals.	How do you find the Studentized residual	9235
333	Poisson Formula. P(x; μ) = (e-μ) (μx) / x! where x is the actual number of successes that result from the experiment, and e is approximately equal to 2.71828. The Poisson distribution has the following properties: The mean of the distribution is equal to μ . The variance is also equal to μ .	What is Poisson distribution formula	333
6706	F-test is used either for testing the hypothesis about the equality of two population variances or the equality of two or more population means. The equality of two population means was dealt with t-test. Besides a t-test, we can also apply F-test for testing equality of two population means.	What are the applications of F test	6706
2294	The value of the odds ratio tells you how much more likely someone under 25 might be to make a claim, for example, and the associated confidence interval indicates the degree of uncertainty associated with that ratio.	How do you interpret confidence intervals and odds ratio	2294
4131	Cross Entropy is definitely a good loss function for Classification Problems, because it minimizes the distance between two probability distributions - predicted and actual.  So cross entropy make sure we are minimizing the difference between the two probability. This is the reason.	Why is cross entropy used for classification	4131
1544	Class limits specify the span of data values that fall within a class. Class boundaries are values halfway between the upper class limit of one class and the lower class limit of the next.  Class limits are not possible data values. Class boundaries specify the span of data values that fall within a class.	What is the difference between a class boundary in a class limit	1544
1693	Unsupervised feature learning is learning features from unlabeled data. The goal of unsupervised feature learning is often to discover low-dimensional features that captures some structure underlying the high-dimensional input data.	What is unsupervised feature learning	1693
4543	Statistically significant means a result is unlikely due to chance. The p-value is the probability of obtaining the difference we saw from a sample (or a larger one) if there really isn't a difference for all users.  Statistical significance doesn't mean practical significance.	What does it mean if a test is not statistically significant	4543
2482	Motivation. Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization.  Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance.	Why do we normalize a feature	2482
5231	Naive Bayes uses a similar method to predict the probability of different class based on various attributes. This algorithm is mostly used in text classification and with problems having multiple classes.	In what real world applications is Naive Bayes classifier used	5231
2611	Implementing Deep Q-Learning using TensorflowPrerequisites: Deep Q-Learning.Step 1: Importing the required libraries.Step 2: Building the Environment.Step 3: Building the learning agent.Step 4: Finding the Optimal Strategy.The agent tries different methods to reach the top and thus gaining knowledge from each episode.Step 5: Testing the Learning Agent.More items•	How is deep Q learning implemented	2611
10783	Q-learning is called off-policy because the updated policy is different from the behavior policy, so Q-Learning is off-policy. In other words, it estimates the reward for future actions and appends a value to the new state without actually following any greedy policy.	Why Q learning is off policy	10783
4635	The formula for calculating a z-score is is z = (x-μ)/σ, where x is the raw score, μ is the population mean, and σ is the population standard deviation. As the formula shows, the z-score is simply the raw score minus the population mean, divided by the population standard deviation.	How do you calculate z score normalization	4635
7562	How to find accuracy of ARIMA model?Problem description: Prediction on CPU utilization.  Step 1: From Elasticsearch I collected 1000 observations and exported on Python.Step 2: Plotted the data and checked whether data is stationary or not.Step 3: Used log to convert the data into stationary form.Step 4: Done DF test, ACF and PACF.More items•	How do you know if Arima model is accurate	7562
6269	Generally a cosine similarity between two documents is used as a similarity measure of documents. In Java, you can use Lucene (if your collection is pretty large) or LingPipe to do this. The basic concept would be to count the terms in every document and calculate the dot product of the term vectors.	How do you find the similarity between two documents	6269
2147	The significance level for a given hypothesis test is a value for which a P-value less than or equal to is considered statistically significant. Typical values for are 0.1, 0.05, and 0.01. These values correspond to the probability of observing such an extreme value by chance.	What does a significance level of 0.01 mean	2147
7379	We will learn Classification algorithms, types of classification algorithms, support vector machines(SVM), Naive Bayes, Decision Tree and Random Forest Classifier in this tutorial.	What are the different classifiers in machine learning	7379
2697	the condition or quality of being true, correct, or exact; freedom from error or defect; precision or exactness; correctness. Chemistry, Physics. the extent to which a given measurement agrees with the standard value for that measurement. Compare precision (def. 6).	What do you mean accuracy	2697
9196	"In statistics, self-selection bias arises in any situation in which individuals select themselves into a group, causing a biased sample with nonprobability sampling.  In such fields, a poll suffering from such bias is termed a self-selected listener opinion poll or ""SLOP""."	What does self selection bias mean	9196
7538	A normality test is used to determine whether sample data has been drawn from a normally distributed population (within some tolerance). A number of statistical tests, such as the Student's t-test and the one-way and two-way ANOVA require a normally distributed sample population.	What does a normality test show	7538
3020	Importance sampling is a useful technique for investigating the properties of a distri- bution while only having samples drawn from a different (proposal) distribution.	Whats the advantage of importance sampling	3020
10443	Batch normalization (also known as batch norm) is a method used to make artificial neural networks faster and more stable through normalization of the input layer by re-centering and re-scaling.	What is the purpose of batch normalization	10443
2739	"In machine learning, the hinge loss is a loss function used for training classifiers. The hinge loss is used for ""maximum-margin"" classification, most notably for support vector machines (SVMs). For an intended output t = ±1 and a classifier score y, the hinge loss of the prediction y is defined as."	What is hinge loss in machine learning	2739
8841	Adaptive resonance theory is a type of neural network technique developed by Stephen Grossberg and Gail Carpenter in 1987. The basic ART uses unsupervised learning technique.	What type of learning is involved in Adaptive Resonance Theory	8841
8092	Matrix factorization is a class of collaborative filtering algorithms used in recommender systems. Matrix factorization algorithms work by decomposing the user-item interaction matrix into the product of two lower dimensionality rectangular matrices.	What is the use of matrix factorization	8092
5781	So, a highly significant intercept in your model is generally not a problem. By the same token, if the intercept is not significant you usually would not want to remove it from the model because by doing this you are creating a model that says that the response function must be zero when the predictors are all zero.	What if intercept is not significant in regression	5781
9729	In a nutshell, hierarchical linear modeling is used when you have nested data; hierarchical regression is used to add or remove variables from your model in multiple steps. Knowing the difference between these two seemingly similar terms can help you determine the most appropriate analysis for your study.	When would you use a hierarchical model	9729
269	The true error rate is statistically defined as the error rate of the classifier on a large number of new cases that converge in the limit to the actual population distribution.  It turns out that there are a number of ways of presenting sample cases to a classifier to get better estimates of the true error rate.	What is true error rate	269
74	One-shot learning is a classification task where one example (or a very small number of examples) is given for each class, that is used to prepare a model, that in turn must make predictions about many unknown examples in the future.	How does SHOT learning work	74
10807	Keras is a high-level interface and uses Theano or Tensorflow for its backend. It runs smoothly on both CPU and GPU. Keras supports almost all the models of a neural network – fully connected, convolutional, pooling, recurrent, embedding, etc. Furthermore, these models can be combined to build more complex models.	Is keras a part of TensorFlow	10807
2207	Disadvantages of Sampling Since choice of sampling method is a judgmental task, there exist chances of biasness as per the mindset of the person who chooses it. Improper selection of sampling techniques may cause the whole process to defunct. Selection of proper size of samples is a difficult job.	What are the disadvantages of sampling	2207
8139	Perceptron is a single layer neural network and a multi-layer perceptron is called Neural Networks. Perceptron is a linear classifier (binary). Also, it is used in supervised learning. It helps to classify the given input data.	Is neural network a linear classifier	8139
10682	AUC represents the probability that a random positive (green) example is positioned to the right of a random negative (red) example. AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0.  AUC is scale-invariant.	What is AUC score in machine learning	10682
4884	Def: A uniform random permutation is one in which each of the n! possible permutations are equally likely.  Def Given a set of n elements, a k-permutation is a sequence containing k of the n elements.	What is uniform random permutation	4884
8340	The standard error is also inversely proportional to the sample size; the larger the sample size, the smaller the standard error because the statistic will approach the actual value. The standard error is considered part of descriptive statistics. It represents the standard deviation of the mean within a dataset.	How does sample size effect standard error	8340
3732	Therefore, a low test–retest reliability correlation might be indicative of a measure with low reliability, of true changes in the persons being measured, or both. That is, in the test–retest method of estimating reliability, it is not possible to separate the reliability of measure from its stability.	What does low test retest reliability mean	10385
7169	2.1 Steps of Bayesian Data Analysis Choose a statistical model for the data in relation to the research questions. The model should have good theoretical justification and have parameters that are meaningful for the research questions.  Obtain the posterior distributions for the model parameters.	What are the steps involved in Bayesian data analysis	7169
8678	A regression tree is built through a process known as binary recursive partitioning, which is an iterative process that splits the data into partitions or branches, and then continues splitting each partition into smaller groups as the method moves up each branch.	How does a regression tree work	8678
671	Quality Glossary Definition: Reliability. Reliability is defined as the probability that a product, system, or service will perform its intended function adequately for a specified period of time, or will operate in a defined environment without failure.	What do you mean by reliability	671
9847	You can tell if two random variables are independent by looking at their individual probabilities. If those probabilities don't change when the events meet, then those variables are independent. Another way of saying this is that if the two variables are correlated, then they are not independent.	How do you prove that two distributions are independent	9847
2266	The original AlphaGo demonstrated superhuman Go-playing ability, but needed the expertise of human players to get there. Namely, it used a dataset of more than 100,000 Go games as a starting point for its own knowledge. AlphaGo Zero, by comparison, has only been programmed with the basic rules of Go.	Why was AlphaGo able to play go so well	2266
4142	A false positive means that the results say you have the condition you were tested for, but you really don't. With a false negative, the results say you don't have a condition, but you really do.	What is the difference between false positive and false negative	4142
586	The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement.  It is used in applied machine learning to estimate the skill of machine learning models when making predictions on data not included in the training data.	Why does bootstrap work in machine learning	586
2205	7 Techniques to Handle Imbalanced DataUse the right evaluation metrics.  Resample the training set.  Use K-fold Cross-Validation in the right way.  Ensemble different resampled datasets.  Resample with different ratios.  Cluster the abundant class.  Design your own models.	What do you do with an unbalanced data set	2205
4465	frequency–inverse document frequency	What does TF IDF stand for	4465
4781	Descriptive, prescriptive, and normative are three main areas of decision theory and each studies a different type of decision making.	What are the different theories of decision making	4781
6650	Positive feedback occurs to increase the change or output: the result of a reaction is amplified to make it occur more quickly.  Some examples of positive feedback are contractions in child birth and the ripening of fruit; negative feedback examples include the regulation of blood glucose levels and osmoregulation.	What is an example of positive feedback	6650
802	Moments are are very useful in statistics because they tell you much about your data. There are four commonly used moments in statistics: the mean, variance, skewness, and kurtosis. The mean gives you a measure of center of the data.	What are the uses of moments	802
9222	Kalman filters combine two sources of information, the predicted states and noisy measurements, to produce optimal, unbiased estimates of system states. The filter is optimal in the sense that it minimizes the variance in the estimated states.	Is Kalman filter optimal	9222
5055	AB testing is essentially an experiment where two or more variants of a page are shown to users at random, and statistical analysis is used to determine which variation performs better for a given conversion goal.	What is AB testing in Analytics	5055
6460	The technique of Monte Carlo Simulation (MCS) was originally developed for use in nuclear weapons design. It provides an efficient way to simulate processes involving chance and uncertainty and can be applied in areas as diverse as market sizing, customer lifetime value measurement and customer service management.	What are some interesting applications of Monte Carlo method	6460
10620	Regularized regression is a type of regression where the coefficient estimates are constrained to zero. The magnitude (size) of coefficients, as well as the magnitude of the error term, are penalized. Complex models are discouraged, primarily to avoid overfitting.	What is regularization coefficient	10620
9418	Essentially, the process goes as follows:Select k centroids. These will be the center point for each segment.Assign data points to nearest centroid.Reassign centroid value to be the calculated mean value for each cluster.Reassign data points to nearest centroid.Repeat until data points stay in the same cluster.	How do you find the centroid in K means clustering	9418
4148	Increase Training Dataset Size Leaning on the law of large numbers, perhaps the simplest approach to reduce the model variance is to fit the model on more training data. In those cases where more data is not readily available, perhaps data augmentation methods can be used instead.	How do you reduce variance in machine learning	4148
6504	Conditional probability is the probability of one event occurring with some relationship to one or more other events. For example: Event A is that it is raining outside, and it has a 0.3 (30%) chance of raining today. Event B is that you will need to go outside, and that has a probability of 0.5 (50%).	What is conditional probability examples	6504
3	Eigenvectors can be used to represent a large dimensional matrix. This means that a matrix M and a vector o can be replaced by a scalar n and a vector o. In this instance, o is the eigenvector and n is the eigenvalue and our target is to find o and n.	What do the eigenvectors indicate	3
1000	Singularity enables users to have full control of their environment. Singularity containers can be used to package entire scientific workflows, software and libraries, and even data.  The Singularity software can import your Docker images without having Docker installed or being a superuser.	What is singularity container	1000
420	"An activation function is a function used in artificial neural networks which outputs a small value for small inputs, and a larger value if its inputs exceed a threshold. If the inputs are large enough, the activation function ""fires"", otherwise it does nothing."	What is the definition of squashing function in machine learning	420
5297	The most important difference between deep learning and traditional machine learning is its performance as the scale of data increases. When the data is small, deep learning algorithms don't perform that well. This is because deep learning algorithms need a large amount of data to understand it perfectly.	Which of the following is true with regards to classical machine learning vs deep learning	5297
1734	A CNN has multiple layers. Weight sharing happens across the receptive field of the neurons(filters) in a particular layer. Weights are the numbers within each filter.  These filters act on a certain receptive field/ small section of the image. When the filter moves through the image, the filter does not change.	What is weight sharing in CNN	1734
7747	If we assume that there is some variation in our data, we will be able to disregard the possibility that either of these standard deviations is zero. Therefore the sign of the correlation coefficient will be the same as the sign of the slope of the regression line.	Is there a relationship between the correlation coefficient and the slope of a linear regression line	7747
5177	In General, A Discriminative model ‌models the decision boundary between the classes. A Generative Model ‌explicitly models the actual distribution of each class.  A Discriminative model ‌learns the conditional probability distribution p(y|x). Both of these models were generally used in supervised learning problems.	What is the difference between generative and discriminative models	5177
5230	In signal processing, the Fourier transform can reveal important characteristics of a signal, namely, its frequency components. y k + 1 = ∑ j = 0 n - 1 ω j k x j + 1 . ω = e - 2 π i / n is one of n complex roots of unity where i is the imaginary unit. For x and y , the indices j and k range from 0 to n - 1 .	How do you find the Fourier transform of a signal	5230
4491	Transfer learning is useful when you have insufficient data for a new domain you want handled by a neural network and there is a big pre-existing data pool that can be transferred to your problem.	What is transfer learning and how is it useful	4491
3572	In artificial intelligence, an intelligent agent (IA) refers to an autonomous entity which acts, directing its activity towards achieving goals (i.e. it is an agent), upon an environment using observation through sensors and consequent actuators (i.e. it is intelligent).	What is agent system in artificial intelligence	3572
2452	Lasso Regression Another Tolerant Method for dealing with multicollinearity known as Least Absolute Shrinkage and Selection Operator (LASSO) regression, solves the same constrained optimization problem as ridge regression, but uses the L1 norm rather than the L2 norm as a measure of complexity.	Does Lasso regression take care of Multicollinearity	2452
8250	Classification is one of the most fundamental concepts in data science. Classification algorithms are predictive calculations used to assign data to preset categories by analyzing sets of training data.၂၀၂၀၊ ဩ ၂၆	What are classification algorithms in machine learning	8250
9609	The Loss Function is one of the important components of Neural Networks. Loss is nothing but a prediction error of Neural Net. And the method to calculate the loss is called Loss Function. In simple words, the Loss is used to calculate the gradients. And gradients are used to update the weights of the Neural Net.	What is loss in a neural network	9609
1459	How to train your Deep Neural NetworkTraining data.  Choose appropriate activation functions.  Number of Hidden Units and Layers.  Weight Initialization.  Learning Rates.  Hyperparameter Tuning: Shun Grid Search - Embrace Random Search.  Learning Methods.  Keep dimensions of weights in the exponential power of 2.More items•	How do I train a deep neural network	1459
3925	Model calibration is the process of adjustment of the model parameters and forcing within the margins of the uncertainties (in model parameters and / or model forcing) to obtain a model representation of the processes of interest that satisfies pre-agreed criteria (Goodness-of-Fit or Cost Function).	What does model calibration mean	3925
7754	Statistics is a very good major in terms of job market and salary scale, it also open doors for many graduate courses, unless you are poor at math ,statistics is worth taking.	Is a statistics degree useful	7754
3536	In this module, we have discussed on various data preprocessing methods for Machine Learning such as rescaling, binarizing, standardizing, one hot encoding, and label encoding.	Which method is used for data preprocessing in machine learning	3536
894	KNN algorithm is one of the simplest classification algorithm and it is one of the most used learning algorithms.  KNN is a non-parametric, lazy learning algorithm. Its purpose is to use a database in which the data points are separated into several classes to predict the classification of a new sample point.	Why KNN algorithm is used	894
5195	The Analysis of covariance (ANCOVA) is done by using linear regression. This means that Analysis of covariance (ANCOVA) assumes that the relationship between the independent variable and the dependent variable must be linear in nature.	How is analysis of covariance done	5195
1898	"The difference between quota sampling and stratified sampling is: although both ""group"" participants by an important characteristic, stratified sampling relies on random selection within each group, while quota sampling relies on convenience sampling within each group."	What is the difference between quota sampling and stratified sampling	1898
6463	Support Vector Machine can also be used as a regression method, maintaining all the main features that characterize the algorithm (maximal margin). The Support Vector Regression (SVR) uses the same principles as the SVM for classification, with only a few minor differences.	Can SVM used for regression	6463
1369	Predictive analytics is the use of data, statistical algorithms and machine learning techniques to identify the likelihood of future outcomes based on historical data. The goal is to go beyond knowing what has happened to providing a best assessment of what will happen in the future.	What do you mean by predictive analytics	1369
6938	The Bayesian Optimization algorithm can be summarized as follows:Select a Sample by Optimizing the Acquisition Function.Evaluate the Sample With the Objective Function.Update the Data and, in turn, the Surrogate Function.Go To 1.	How do I implement a Bayesian optimization	6938
4716	Handling overfittingReduce the network's capacity by removing layers or reducing the number of elements in the hidden layers.Apply regularization , which comes down to adding a cost to the loss function for large weights.Use Dropout layers, which will randomly remove certain features by setting them to zero.	How do you deal with Overfitting in deep learning	4716
7184	In summary, model parameters are estimated from data automatically and model hyperparameters are set manually and are used in processes to help estimate model parameters. Model hyperparameters are often referred to as parameters because they are the parts of the machine learning that must be set manually and tuned.	What is the difference between a model parameter and a learning algorithm’s hyper parameter	7184
7479	A Convolutional neural network (CNN) is a neural network that has one or more convolutional layers and are used mainly for image processing, classification, segmentation and also for other auto correlated data. A convolution is essentially sliding a filter over the input.	What is the use of convolutional neural network	7479
8953	Concept shift is closely related to concept drift. This occurs when a model learned from data sampled from one distribution needs to be applied to data drawn from another.	What is Concept shift	8953
614	Null and alternate hypothesis are different and you can't interchange them. Alternate hypothesis is just the opposite of null which means there is a statistical difference in Mean / median of both the data sets.	Can I switch around the null and alternative hypothesis in hypothesis testing	614
4516	Three keys to managing bias when building AIChoose the right learning model for the problem. There's a reason all AI models are unique: Each problem requires a different solution and provides varying data resources.  Choose a representative training data set.  Monitor performance using real data.	How can machine learning overcome bias	4516
746	For a hypothesis test, a researcher collects sample data.  If the statistic falls within a specified range of values, the researcher rejects the null hypothesis . The range of values that leads the researcher to reject the null hypothesis is called the region of rejection.	What is the region of rejection	746
6669	The Purpose of Statistics: Statistics teaches people to use a limited sample to make intelligent and accurate conclusions about a greater population. The use of tables, graphs, and charts play a vital role in presenting the data being used to draw these conclusions.	What is statistics and its purpose	6669
3438	To calculate the similarity between two examples, you need to combine all the feature data for those two examples into a single numeric value. For instance, consider a shoe data set with only one feature: shoe size. You can quantify how similar two shoes are by calculating the difference between their sizes.	How do you calculate similarity	3438
10505	Some of the more common ways to normalize data include:Transforming data using a z-score or t-score.  Rescaling data to have values between 0 and 1.  Standardizing residuals: Ratios used in regression analysis can force residuals into the shape of a normal distribution.Normalizing Moments using the formula μ/σ.More items	How do you normalize data in statistics	10505
9984	If your regression model contains independent variables that are statistically significant, a reasonably high R-squared value makes sense.  Correspondingly, the good R-squared value signifies that your model explains a good proportion of the variability in the dependent variable.	What do you report in a multiple regression to say whether the variables are significant or not	9984
5333	Independent EventsTwo events A and B are said to be independent if the fact that one event has occurred does not affect the probability that the other event will occur.If whether or not one event occurs does affect the probability that the other event will occur, then the two events are said to be dependent.	How do you tell if an event is independent or dependent	5333
1307	3 layers	How many layers are there in deep learning	1307
6972	There is a broad range of opportunities to study optimization problems that cannot be solved with an exact algorithm.  This work proposes the use of neural networks such as heuristics to resolve optimization problems in those cases where the use of linear programming or Lagrange multipliers is not feasible.	Can neural networks be used for optimization	6972
8463	While implementing the decision tree we will go through the following two phases:Building Phase. Preprocess the dataset. Split the dataset from train and test using Python sklearn package. Train the classifier.Operational Phase. Make predictions. Calculate the accuracy.	How do you implement a decision tree	8463
1251	For example, the amount of time (beginning now) until an earthquake occurs has an exponential distribution. Other examples include the length of time, in minutes, of long distance business telephone calls, and the amount of time, in months, a car battery lasts.	What is exponential distribution example	1251
2749	"In machine learning and natural language processing, a topic model is a type of statistical model for discovering the abstract ""topics"" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body."	What is topic Modelling used for	2749
3894	Because the distance function used to find the k nearest neighbors is not linear, so it usually won't lead to a linear decision boundary.  kNN does not build a model of your data, it simply assumes that instances that are close together in space are similar.	Can Knn have linear decision boundary	3894
7457	AlphaGo Zero is a version of DeepMind's Go software AlphaGo.  By playing games against itself, AlphaGo Zero surpassed the strength of AlphaGo Lee in three days by winning 100 games to 0, reached the level of AlphaGo Master in 21 days, and exceeded all the old versions in 40 days.	What is significant about Alpha Go Zero	7457
2407	Control Charts: A discrete distribution is one in which the data can only take on certain values, for example integers. A continuous distribution is one in which data can take on any value within a specified range (which may be infinite).	What is the difference between discrete and continuous distribution	2407
3046	The bits of linguistic information that enter into one person's mind, from another, cause people to entertain a new thought with profound effects on his world knowledge, inferencing, and subsequent behavior. Language neither creates nor distorts conceptual life. Thought comes first, while language is an expression.	What is the relationship between language and thought	3046
4804	Machine learning, a subset of artificial intelligence (AI), depends on the quality, objectivity and size of training data used to teach it.  Machine learning bias generally stems from problems introduced by the individuals who design and/or train the machine learning systems.	Is Machine Learning Biased	4804
7874	TensorFlow Lite inferenceAndroid Platform.iOS Platform.Linux Platform.	Which devices support TensorFlow Lite for inference	7874
7269	Jakob Bernoulli	Who created the law of averages	7269
7175	Simple regression analysis uses a single x variable for each dependent “y” variable. For example: (x1, Y1). Multiple regression uses multiple “x” variables for each independent variable: (x1)1, (x2)1, (x3)1, Y1).	What is a regression model example	7175
2627	Training deep learning neural networks is very challenging. The best general algorithm known for solving this problem is stochastic gradient descent, where model weights are updated each iteration using the backpropagation of error algorithm. Optimization in general is an extremely difficult task.	What are the challenges in training a neural network	2627
4818	In robust statistics, robust regression is a form of regression analysis designed to overcome some limitations of traditional parametric and non-parametric methods. Regression analysis seeks to find the relationship between one or more independent variables and a dependent variable.	What are robust regressions and robust statistics	4818
7133	The term “multivariate statistics” is appropriately used to include all statistics where there are more than two variables simultaneously analyzed. You are already familiar with bivariate statistics such as the Pearson product moment correlation coefficient and the independent groups t-test.	What is multivariate variable	7133
6129	Use regression analysis to describe the relationships between a set of independent variables and the dependent variable. Regression analysis produces a regression equation where the coefficients represent the relationship between each independent variable and the dependent variable.	What does regression analysis tell you	6129
606	The most common hash functions used in digital forensics are Message Digest 5 (MD5), and Secure Hashing Algorithm (SHA) 1 and 2.	What are the two common hash functions	606
6101	Multiclass classification with logistic regression can be done either through the one-vs-rest scheme in which for each class a binary classification problem of data belonging or not to that class is done, or changing the loss function to cross- entropy loss.	How do you use logistic regression for multi class classification	6101
376	Bias can damage research, if the researcher chooses to allow his bias to distort the measurements and observations or their interpretation. When faculty are biased about individual students in their courses, they may grade some students more or less favorably than others, which is not fair to any of the students.	Why is being bias bad	376
10554	Forward chaining starts from known facts and applies inference rule to extract more data unit it reaches to the goal. Backward chaining starts from the goal and works backward through inference rules to find the required facts that support the goal.  Backward chaining reasoning applies a depth-first search strategy.	What is forward and backward chaining in AI	10554
1636	Random error can be reduced by: Using an average measurement from a set of measurements, or. Increasing sample size.	What is random error and how can it be reduced	1636
9277	"An example of pattern recognition is classification, which attempts to assign each input value to one of a given set of classes (for example, determine whether a given email is ""spam"" or ""non-spam"").  This is opposed to pattern matching algorithms, which look for exact matches in the input with pre-existing patterns."	What is an example of pattern recognition	9277
23	In short, Softmax Loss is actually just a Softmax Activation plus a Cross-Entropy Loss. Softmax is an activation function that outputs the probability for each class and these probabilities will sum up to one. Cross Entropy loss is just the sum of the negative logarithm of the probabilities.	Is the softmax loss the same as the cross entropy loss	23
9755	In Convolutional Neural Networks, Filters detect spatial patterns such as edges in an image by detecting the changes in intensity values of the image.	What are filters in neural networks	9755
2999	Covariance Matrix is a measure of how much two random variables gets change together.  The Covariance Matrix is also known as dispersion matrix and variance-covariance matrix. The covariance between two jointly distributed real-valued random variables X and Y with finite second moments is defined as.	What is covariance matrix example	2999
6335	Deconvolution layer is a very unfortunate name and should rather be called a transposed convolutional layer. Visually, for a transposed convolution with stride one and no padding, we just pad the original input (blue entries) with zeroes (white entries) (Figure 1).	What is a deconvolution layer	6335
6883	Examples in natural systems of swarm intelligence include bird flocking, ant foraging, and fish schooling. Inspired by swarm's such behavior, a class of algorithms is proposed for tackling optimization problems, usually under the title of swarm intelligence algorithms (SIAs) [203].	What are the common aspects of swarm intelligence observed in nature	6883
3025	Simple random sampling: By using the random number generator technique, the researcher draws a sample from the population called simple random sampling. Simple random samplings are of two types.  Cluster sampling: Cluster sampling occurs when a random sample is drawn from certain aggregational geographical groups.	Is cluster sampling random or non random	3025
280	The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement. It can be used to estimate summary statistics such as the mean or standard deviation.  That when using the bootstrap you must choose the size of the sample and the number of repeats.	What is bootstrap method in statistics	280
5493	Principal components analysis (PCA) is a statistical technique that allows identifying underlying linear patterns in a data set so it can be expressed in terms of other data set of a significatively lower dimension without much loss of information.	What is PCA in neural network	5493
948	Ridge Regression is a technique for analyzing multiple regression data that suffer from multicollinearity. When multicollinearity occurs, least squares estimates are unbiased, but their variances are large so they may be far from the true value.	What is the use of ridge regression	948
4195	A hypothesis is an approximate explanation that relates to the set of facts that can be tested by certain further investigations. There are basically two types, namely, null hypothesis and alternative hypothesis. A research generally starts with a problem.	What are the two types of hypothesis testing	4195
6969	One major disadvantage of non-probability sampling is that it's impossible to know how well you are representing the population. Plus, you can't calculate confidence intervals and margins of error.	What are the disadvantages of non probability sampling	6969
1768	Univariate analysis is the simplest form of analyzing data. “Uni” means “one”, so in other words your data has only one variable. It doesn't deal with causes or relationships (unlike regression ) and it's major purpose is to describe; It takes data, summarizes that data and finds patterns in the data.	How do you analyze univariate data	1768
8442	Like random forests, gradient boosting is a set of decision trees. The two main differences are: How trees are built: random forests builds each tree independently while gradient boosting builds one tree at a time.	What is the difference between random forest and gradient boosting	8442
492	Bias in Machine Learning is defined as the phenomena of observing results that are systematically prejudiced due to faulty assumptions.  This also results in bias which arises from the choice of training and test data and their representation of the true population.	What are bias in machine learning	492
4536	Categorical variables require special attention in regression analysis because, unlike dichotomous or continuous variables, they cannot by entered into the regression equation just as they are. Instead, they need to be recoded into a series of variables which can then be entered into the regression model.	Can you do multiple regression with categorical variables	4536
6456	The larger the sample size is the smaller the effect size that can be detected. The reverse is also true; small sample sizes can detect large effect sizes.  Thus an appropriate determination of the sample size used in a study is a crucial step in the design of a study.	Is it important to determine the sample size	6456
1820	The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.  The rectified linear activation is the default activation when developing multilayer Perceptron and convolutional neural networks.	What is ReLU function in neural network	1820
4832	A false positive means that the results say you have the condition you were tested for, but you really don't. With a false negative, the results say you don't have a condition, but you really do.	What's the difference between false negative and false positive	4832
617	The mean, expected value, or expectation of a random variable X is writ- ten as E(X) or µX. If we observe N random values of X, then the mean of the N values will be approximately equal to E(X) for large N. The expectation is defined differently for continuous and discrete random variables.	What is the expectation of a random variable	617
783	Noun. optimizer (plural optimizers) A person in a large business whose task is to maximize profits and make the business more efficient. (computing) A program that uses linear programming to optimize a process. (computing) A compiler or assembler that produces optimized code.	What does Optimizer mean	783
9450	It is well known that correlation does not prove causation. What is less well known is that causation can exist when correlation is zero. The upshot of these two facts is that, in general and without additional information, correlation reveals literally nothing about causation.	Is it possible for two things to have a causal relationship but not be correlated	9450
10014	Cost Function It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number. Depending on the problem Cost Function can be formed in many different ways.	What is a cost function in machine learning	10014
8863	Content-based filtering, makes recommendations based on user preferences for product features. Collaborative filtering mimics user-to-user recommendations. It predicts users preferences as a linear, weighted combination of other user preferences. Both methods have limitations.	What is the difference between content based filtering and collaborative filtering	8863
7957	Yes, there are. One example is the WEKA MOA framework [1]. This framework implements standard algorithms in the literature of concept drift detection.  The nice thing about this framework is that it allows users to generate new data streams which contains concept drifts of different types.	Is there a good library for concept drift detection algorithms	7957
4053	The random forest is a model made up of many decision trees. Rather than just simply averaging the prediction of trees (which we could call a “forest”), this model uses two key concepts that gives it the name random: Random sampling of training data points when building trees.	Why is random forest called random	4053
402	Logistic Regression, also known as Logit Regression or Logit Model, is a mathematical model used in statistics to estimate (guess) the probability of an event occurring having been given some previous data. Logistic Regression works with binary data, where either the event happens (1) or the event does not happen (0).	What is logistic regression simple explanation	402
913	Explanation: Entropy (S) by the modern definition is the amount of energy dispersal in a system. Therefore, the system entropy will increase when the amount of motion within the system increases. For example, the entropy increases when ice (solid) melts to give water (liquid).	What does it mean when it says increase or decrease in entropy	913
340	The main difference between Binomial and Poisson Distribution is that the Binomial distribution is only for a certain frame or a probability of success and the Poisson distribution is used for events that could occur a very large number of times.	What is the main difference between the binomial distribution and the Poisson distribution	340
1327	EXC functions both find a requested quartile of a supplied data set. The difference between these two functions is that QUARTILE. INC bases its calculation on a percentile range of 0 to 1 inclusive, whereas QUARTILE. EXC bases its calculation on a percentile range of 0 to 1 exclusive.	What is the difference between quartile exc and quartile inc	1327
8985	"A multi-agent system (MAS or ""self-organized system"") is a computerized system composed of multiple interacting intelligent agents.  Intelligence may include methodic, functional, procedural approaches, algorithmic search or reinforcement learning."	What are multi agents in artificial intelligence	8985
3054	Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them.	What is data augmentation in deep learning	3054
7656	Log loss is used when we have {0,1} response. This is usually because when we have {0,1} response, the best models give us values in terms of probabilities. In simple words, log loss measures the UNCERTAINTY of the probabilities of your model by comparing them to the true labels.	Why do we use log loss in logistic regression	7656
2648	As the formula shows, the standard score is simply the score, minus the mean score, divided by the standard deviation.	How do you work out Standardised scores	2648
1204	A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.  It is a term and set of techniques known in machine learning in the training and operation of deep learning models can be described in terms of tensors.	What is a tensor ML	1204
8775	A negative coefficient suggests that as the independent variable increases, the dependent variable tends to decrease. The coefficient value signifies how much the mean of the dependent variable changes given a one-unit shift in the independent variable while holding other variables in the model constant.	What do negative coefficients mean in regression	8775
6135	In machine learning, multiclass or multinomial classification is the problem of classifying instances into one of three or more classes (classifying instances into one of two classes is called binary classification).	What is multi class classification in machine learning	6135
4936	Bias is a disproportionate weight in favor of or against an idea or thing, usually in a way that is closed-minded, prejudicial, or unfair. Biases can be innate or learned. People may develop biases for or against an individual, a group, or a belief. In science and engineering, a bias is a systematic error.	What does bias mean	4936
8510	Steps for Making decision treeGet list of rows (dataset) which are taken into consideration for making decision tree (recursively at each nodes).Calculate uncertanity of our dataset or Gini impurity or how much our data is mixed up etc.Generate list of all question which needs to be asked at that node.More items•	How do you make a decision in tree machine learning	8510
8643	On each iteration, we update the parameters in the opposite direction of the gradient of the objective function J(w) w.r.t the parameters where the gradient gives the direction of the steepest ascent. The size of the step we take on each iteration to reach the local minimum is determined by the learning rate α.	How are the parameters updates during the gradient descent process	8643
2829	In general, there is no universal rule of thumb indicating that the accuracy of a learner is directly proportional to the number of features used to train it.	Does increasing the number of feature variables of the dataset improve the accuracy of the training model	2829
6836	Hidden Markov models are known for their applications to thermodynamics, statistical mechanics, physics, chemistry, economics, finance, signal processing, information theory, pattern recognition - such as speech, handwriting, gesture recognition, part-of-speech tagging, musical score following, partial discharges and	Where does the hidden Markov model is used	6836
7148	Face detection is a broader term than face recognition. Face detection just means that a system is able to identify that there is a human face present in an image or video.  Face recognition can confirm identity. It is therefore used to control access to sensitive areas.	What is difference between face detection and face recognition	7148
3401	Significance level and p-value α is the maximum probability of rejecting the null hypothesis when the null hypothesis is true. If α = 1 we always reject the null, if α = 0 we never reject the null hypothesis.  If we choose to compare the p-value to α = 0.01, we are insisting on a stronger evidence!	How small of an alpha value can you choose and still have sufficient evidence to reject the null hypothesis	3401
4439	You can use test statistics to determine whether to reject the null hypothesis. The test statistic compares your data with what is expected under the null hypothesis. The test statistic is used to calculate the p-value. A test statistic measures the degree of agreement between a sample of data and the null hypothesis.	What is the appropriate test statistic	4439
2007	"In mathematics, the operator norm is a means to measure the ""size"" of certain linear operators. Formally, it is a norm defined on the space of bounded linear operators between two given normed vector spaces."	What is the operator norm of a matrix	2007
8071	How to Get Started with AIPick a topic you are interested in.Find a quick solution.Improve your simple solution.Share your solution.Repeat steps 1-4 for different problems.Complete a Kaggle competition.Use machine learning professionally.	How do I start learning artificial intelligence	8071
10149	EdgeRank	What is the name for Facebook's ranking algorithm	10149
5579	The distinction between probability and likelihood is fundamentally important: Probability attaches to possible results; likelihood attaches to hypotheses. Explaining this distinction is the purpose of this first column. Possible results are mutually exclusive and exhaustive.	What is difference between probability and likelihood	5579
10952	Random assignment is however a process of randomly assigning subjects to experimental or control groups. This is a standard practice in true experimental research to ensure that treatment groups are similar (equivalent) to each other and to the control group, prior to treatment administration.	Are based on the idea that subjects are randomly assigned to groups	10952
4717	A sampling distribution is a probability distribution of a statistic obtained from a larger number of samples drawn from a specific population. The sampling distribution of a given population is the distribution of frequencies of a range of different outcomes that could possibly occur for a statistic of a population.	What is a normal sample distribution	4717
961	Well labeled dataset can be used to train a custom model.In the Data Labeling Service UI, you create a dataset and import items into it from the same page.Open the Data Labeling Service UI.  Click the Create button in the title bar.On the Add a dataset page, enter a name and description for the dataset.More items	How do I create a labeled dataset	961
6960	"Logic, as per the definition of the Oxford dictionary, is ""the reasoning conducted or assessed according to strict principles and validity"". In Artificial Intelligence also, it carries somewhat the same meaning. Logic can be defined as the proof or validation behind any reason provided."	What is logic in artificial intelligence	6960
9175	Quartile deviation is the difference between “first and third quartiles” in any distribution. Standard deviation measures the “dispersion of the data set” that is relative to its mean.	What is the difference between standard deviation and quartile deviation	9175
2034	Variance: Var(X) To calculate the Variance: square each value and multiply by its probability. sum them up and we get Σx2p. then subtract the square of the Expected Value μ	How do you find a variance of a function	2034
6588	A deep Boltzmann machine (DBM) is a type of binary pairwise Markov random field (undirected probabilistic graphical model) with multiple layers of hidden random variables. It is a network of symmetrically coupled stochastic binary units. It comprises a set of visible units and layers of hidden units .	What is deep Boltzmann machine	6588
5232	According to Bezdek (1994), Computational Intelligence is a subset of Artificial Intelligence. There are two types of machine intelligence: the artificial one based on hard computing techniques and the computational one based on soft computing methods, which enable adaptation to many situations.	What is computational intelligence and how is it related to AI	5232
425	Definition. Predictive analytics is an area of statistics that deals with extracting information from data and using it to predict trends and behavior patterns.  Predictive analytics statistical techniques include data modeling, machine learning, AI, deep learning algorithms and data mining.	How is predictive analytics done	425
9715	It is very much like the exponential distribution, with λ corresponding to 1/p, except that the geometric distribution is discrete while the exponential distribution is continuous.	Is exponential distribution discrete or continuous	9715
549	For most common clustering software, the default distance measure is the Euclidean distance.  Correlation-based distance considers two objects to be similar if their features are highly correlated, even though the observed values may be far apart in terms of Euclidean distance.	What is distance measure in clustering	549
1446	A/B tests are easy and seem harmless, but many consumers become disturbed when they find out they're being tested without knowing it. Some argue that A/B testing tracks along the same ethical lines as a product launch; others believe organizations​ must be transparent about their testing even if it seems harmless.	Is a B testing ethical	1446
4072	From the mathematical point of view, linear regression and ANOVA are identical: both break down the total variance of the data into different “portions” and verify the equality of these “sub-variances” by means of a test (“F” Test).	Is Anova the same as linear regression	4072
7907	1:3610:15Suggested clip · 117 secondsConducting a Multiple Regression using Microsoft Excel Data YouTubeStart of suggested clipEnd of suggested clip	How do you do a regression in Excel with multiple variables	7907
543	The General Linear Model (GLM) is a useful framework for comparing how several variables affect different continuous variables. In it's simplest form, GLM is described as: Data = Model + Error (Rutherford, 2001, p.3) GLM is the foundation for several statistical tests, including ANOVA, ANCOVA and regression analysis.	What is the general linear model GLM Why does it matter	543
892	Word2Vec takes texts as training data for a neural network. The resulting embedding captures whether words appear in similar contexts. GloVe focuses on words co-occurrences over the whole corpus. Its embeddings relate to the probabilities that two words appear together.	What is the difference between GloVe and word2vec	892
262	Principal component analysis (PCA) is a technique for reducing the dimensionality of such datasets, increasing interpretability but at the same time minimizing information loss. It does so by creating new uncorrelated variables that successively maximize variance.	What does principal component analysis do	262
2197	In a positively skewed distribution, the mean is usually greater than the median because the few high scores tend to shift the mean to the right.  In a positively skewed distribution, the mode is always less than the mean and median.	Which is typical of a positively skewed distribution	2197
10822	For years, people have been forecasting weather patterns, economic and political events, sports outcomes, and more.  Because we try to predict so many different events, there are a wide variety of ways in which forecasts can be developed.	What is forecasting in machine learning	10822
3452	Non parametric do not assume that the data is normally distributed.  For example: the Kruskal Willis test is the non parametric alternative to the One way ANOVA and the Mann Whitney is the non parametric alternative to the two sample t test. The main nonparametric tests are: 1-sample sign test.	Which is an example of non parametric statistic	3452
2507	The decision for converting a predicted probability or scoring into a class label is governed by a parameter referred to as the “decision threshold,” “discrimination threshold,” or simply the “threshold.” The default value for the threshold is 0.5 for normalized predicted probabilities or scores in the range between 0	What is threshold machine learning	2507
6030	SummaryWeighted Mean: A mean where some values contribute more than others.When the weights add to 1: just multiply each weight by the matching value and sum it all up.Otherwise, multiply each weight w by its matching value x, sum that all up, and divide by the sum of weights: Weighted Mean = ΣwxΣw.	How do you calculate weighted mean	6030
401	Try a series of runs with different amounts of training data: randomly sample 20% of it, say, 10 times and observe performance on the validation data, then do the same with 40%, 60%, 80%. You should see both greater performance with more data, but also lower variance across the different random samples.	How do you split your data between training and validation	401
10565	The sample standard deviation (s) is a point estimate of the population standard deviation (σ). The sample mean (̄x) is a point estimate of the population mean, μ The sample variance (s2 is a point estimate of the population variance (σ2).	What is the point estimate of the population standard deviation	10565
7193	In a nutshell, the goal of Bayesian inference is to maintain a full posterior probability distribution over a set of random variables.  Sampling algorithms based on Monte Carlo Markov Chain (MCMC) techniques are one possible way to go about inference in such models.	What is Bayesian sampling	7193
10991	The 7 Steps of Machine Learning1 - Data Collection. The quantity & quality of your data dictate how accurate our model is.  2 - Data Preparation. Wrangle data and prepare it for training.  3 - Choose a Model.  4 - Train the Model.  5 - Evaluate the Model.  6 - Parameter Tuning.  7 - Make Predictions.	What are the steps in designing a machine learning problem	10991
8408	A Blob is a group of connected pixels in an image that share some common property ( E.g grayscale value ). In the image above, the dark connected regions are blobs, and the goal of blob detection is to identify and mark these regions.	What is blob in OBject detection	8408
2038	Overall, Sentiment analysis may involve the following types of classification algorithms: Linear Regression. Naive Bayes. Support Vector Machines.	Which algorithm is used for sentiment analysis	2038
9849	One or two of the sections is the “rejection region“; if your test value falls into that region, then you reject the null hypothesis. A one tailed test with the rejection rejection in one tail. The critical value is the red line to the left of that region.	How do you find the critical value and rejection region	9849
10658	Calculation. The formula given in most textbooks is Skew = 3 * (Mean – Median) / Standard Deviation. This is known as an alternative Pearson Mode Skewness. You could calculate skew by hand.	How do you find the skew of a distribution	10658
8689	Class Boundaries. Separate one class in a grouped frequency distribution from another. The boundaries have one more decimal place than the raw data and therefore do not appear in the data. There is no gap between the upper boundary of one class and the lower boundary of the next class.	What is class boundary in frequency distribution	8689
2609	Ambiguity. The main challenge of NLP is the understanding and modeling of elements within a variable context. In a natural language, words are unique but can have different meanings depending on the context resulting in ambiguity on the lexical, syntactic, and semantic levels.	What is the main challenge s of NLP	2609
8164	Deep learning is an AI function that mimics the workings of the human brain in processing data for use in detecting objects, recognizing speech, translating languages, and making decisions. Deep learning AI is able to learn without human supervision, drawing from data that is both unstructured and unlabeled.	What is deep learning and how does it relate to AI	8164
10995	0:294:16Suggested clip · 116 secondsGeometric distribution moment generating function - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you find the moment generating function of a geometric distribution	10995
7280	The biggest negative of transfer learning is that it's very hard to do right and very easy to mess up. Especially in NLP this kind of approach has only been mainstream for about a year, which just isn't enough time when model runs take weeks.	What are the disadvantages of transfer learning	7280
1518	The Monty Hall problem is one of those rare curiosities – a mathematical problem that has made the front pages of national news. Everyone now knows, or thinks they know, the answer but a realistic look at the problem demonstrates that the standard mathematician's answer is wrong.	Is the Monty Hall problem correct	1518
4723	The t distribution is therefore leptokurtic. The t distribution approaches the normal distribution as the degrees of freedom increase.  Since the t distribution is leptokurtic, the percentage of the distribution within 1.96 standard deviations of the mean is less than the 95% for the normal distribution.	Does a t distribution have a normal distribution	4723
1031	Let's explore 5 common techniques used for extracting information from the above text.Named Entity Recognition. The most basic and useful technique in NLP is extracting the entities in the text.  Sentiment Analysis.  Text Summarization.  Aspect Mining.  Topic Modeling.	How do I extract information from a text	1031
7009	Optuna is an automated hyperparameter optimization software framework that is knowingly invented for the machine learning-based tasks. It emphasizes an authoritative, define-by-run approach user API.	What is Optuna	7009
1472	Model fitting is a measure of how well a machine learning model generalizes to similar data to that on which it was trained.  During the fitting process, you run an algorithm on data for which you know the target variable, known as “labeled” data, and produce a machine learning model.	What is fitting in machine learning	1472
9091	The central limit theorem states that the CDF of Zn converges to the standard normal CDF. converges in distribution to the standard normal random variable as n goes to infinity, that is limn→∞P(Zn≤x)=Φ(x), for all x∈R,  The Xi's can be discrete, continuous, or mixed random variables.	Does the central limit theorem apply to discrete random variables	9091
10473	0:315:15Suggested clip · 110 secondsMultinomial Distributions: Examples (Basic Probability and Statistics YouTubeStart of suggested clipEnd of suggested clip	How do you solve a multinomial distribution	10473
10462	The most significant difference between regression vs classification is that while regression helps predict a continuous quantity, classification predicts discrete class labels. There are also some overlaps between the two types of machine learning algorithms.	What is difference between regression and classification	10462
9421	Not only are nose strips bad for those with sensitive skin, they also worsen other skin conditions. Pore strips exacerbate rosacea-prone skin , especially if they contain irritating ingredients like alcohol and astringents. They also aggravate extremely dry skin, eczema and psoriasis .	Is pore strip bad	9421
786	If k is given, the K-means algorithm can be executed in the following steps: Partition of objects into k non-empty subsets. Identifying the cluster centroids (mean point) of the current partition.  Compute the distances from each point and allot points to the cluster where the distance from the centroid is minimum.	What is K means algorithm with example	786
3616	A sampling distribution is where you take a population (N), and find a statistic from that population.  This is repeated for all possible samples from the population. Example: You hold a survey about college student's GRE scores and calculate that the standard deviation is 1.	How do you describe the sampling distribution	3616
2214	A Multi Layer Perceptron (MLP) contains one or more hidden layers (apart from one input and one output layer). While a single layer perceptron can only learn linear functions, a multi layer perceptron can also learn non – linear functions. Figure 4 shows a multi layer perceptron with a single hidden layer.	What is single layer Perceptron and Multilayer Perceptron	2214
1884	A continuous distribution has a range of values that are infinite, and therefore uncountable. For example, time is infinite: you could count from 0 seconds to a billion seconds…a trillion seconds…and so on, forever.	What are some examples of continuous distribution probability	1884
3833	"The binomial distribution model allows us to compute the probability of observing a specified number of ""successes"" when the process is repeated a specific number of times (e.g., in a set of patients) and the outcome for a given patient is either a success or a failure."	What is the importance of binomial distribution	3833
5978	Regression coefficients represent the mean change in the response variable for one unit of change in the predictor variable while holding other predictors in the model constant.  The coefficient indicates that for every additional meter in height you can expect weight to increase by an average of 106.5 kilograms.	What is a coefficient in a regression model	5978
2297	2:107:35Suggested clip · 110 secondsLinear Regression R Program Make Predictions - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How do you predict a value in linear regression in R	2297
903	The nominator is the joint probability and the denominator is the probability of the given outcome.  This is the conditional probability: P(A∣B)=P(A∩B)P(B) This is the Bayes' rule: P(A∣B)=P(B|A)∗P(A)P(B).	What is the difference between Bayes rule and conditional probability	903
3893	The Fourier transform of a function of time is a complex-valued function of frequency, whose magnitude (absolute value) represents the amount of that frequency present in the original function, and whose argument is the phase offset of the basic sinusoid in that frequency.	What does Fourier transform represent	3893
3860	The Four Assumptions of Linear RegressionLinear relationship: There exists a linear relationship between the independent variable, x, and the dependent variable, y.Independence: The residuals are independent.  Homoscedasticity: The residuals have constant variance at every level of x.Normality: The residuals of the model are normally distributed.	What are the four assumptions of linear regression	3860
118	The logarithm is to exponentiation as division is to multiplication: The logarithm is the inverse of the exponent: it undoes exponentiation. When studying logarithms, always remember the following fundamental equivalence: if and only if . Whenever one of these is true, so is the other.	What is the intuition behind the logarithm	118
6701	Batch Normalization during inference During testing or inference phase we can't apply the same batch-normalization as we did during training because we might pass only sample at a time so it doesn't make sense to find mean and variance on a single sample.	Is batch normalization used in inference	6701
4951	(1 p)xp = (1 p)a+1p + ··· + (1 p)bp = (1 p)a+1p (1 p)b+1p 1 (1 p) = (1 p)a+1 (1 p)b+1 We can take a = 0 to find the distribution function for a geometric random variable. The initial d indicates density and p indicates the probability from the distribution function.	How do you find the distribution function of a random variable	4951
8533	If the limit of |a[n+1]/a[n]| is less than 1, then the series (absolutely) converges. If the limit is larger than one, or infinite, then the series diverges.	How do you test for convergence and divergence in a series	8533
5628	Data visualization is a technique that uses an array of static and interactive visuals within a specific context to help people understand and make sense of large amounts of data. The data is often displayed in a story format that visualizes patterns, trends and correlations that may otherwise go unnoticed.	What is visualization in machine learning	5628
5683	Deep Learning is extensively used for Predictive Analytics, NLP, Computer Vision, and Object Recognition.	Does NLP use deep learning	5683
9329	If you see a lowercase x or y, that's the kind of variable you're used to in algebra. It refers to an unknown quantity or quantities. If you see an uppercase X or Y, that's a random variable and it usually refers to the probability of getting a certain outcome.	How do you identify a random variable	9329
3546	Gradient descent is an optimization algorithm that's used when training a machine learning model. It's based on a convex function and tweaks its parameters iteratively to minimize a given function to its local minimum.	How is gradient descent used in machine learning	3546
2552	It is a process of converting a sentence to forms – list of words, list of tuples (where each tuple is having a form (word, tag)). The tag in case of is a part-of-speech tag, and signifies whether the word is a noun, adjective, verb, and so on.	What is part of speech tagging in NLP	2552
2843	Structural equation modeling is a multivariate statistical analysis technique that is used to analyze structural relationships. This technique is the combination of factor analysis and multiple regression analysis, and it is used to analyze the structural relationship between measured variables and latent constructs.	What is structural equation modeling used for	2843
8900	(Note that how a support vector machine classifies points that fall on a boundary line is implementation dependent. In our discussions, we have said that points falling on the line will be considered negative examples, so the classification equation is w . u + b ≤ 0.)	What equations are used for Classificationion in a support vector machine	8900
9037	Matrix theory is a branch of mathematics which is focused on study of matrices. Initially, it was a sub-branch of linear algebra, but soon it grew to cover subjects related to graph theory, algebra, combinatorics and statistics as well.	What is the Matrix theory	9037
4435	"In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs. A standard integrated circuit can be seen as a digital network of activation functions that can be ""ON"" (1) or ""OFF"" (0), depending on input."	What does activation function do in neural network	4435
3753	While the variance and the standard error of the mean are different estimates of variability, one can be derived from the other. Multiply the standard error of the mean by itself to square it. This step assumes that the standard error is a known quantity.	Is variance and standard error the same	3753
10479	Variable screening is the process of filtering out irrelevant variables, with the aim to reduce the dimensionality from ultrahigh to high while retaining all important variables.  The main theme of this thesis is to develop variable screening and variable selection methods for high dimensional data analysis.	What is variable screening	10479
6387	Probability Role of probability in statistics:  Use probability to predict results of experiment under assumptions. Compute probability of error larger than given amount. Compute probability of given departure between prediction and results under assumption.	What is the role of probability to statistic	6387
1385	Probability is the study of random events. It is used in analyzing games of chance, genetics, weather prediction, and a myriad of other everyday events. Statistics is the mathematics we use to collect, organize, and interpret numerical data.	What are statistics and probability	1385
60	Probability density function (PDF) is a statistical expression that defines a probability distribution (the likelihood of an outcome) for a discrete random variable (e.g., a stock or ETF) as opposed to a continuous random variable.	What does probability density function represent	60
3577	Train a neural network with TensorFlowStep 1: Import the data.Step 2: Transform the data.Step 3: Construct the tensor.Step 4: Build the model.Step 5: Train and evaluate the model.Step 6: Improve the model.	How do you train a neural network in TensorFlow	3577
733	Covariance: An Overview. Variance and covariance are mathematical terms frequently used in statistics and probability theory. Variance refers to the spread of a data set around its mean value, while a covariance refers to the measure of the directional relationship between two random variables.	What is the meaning of covariance in statistics	733
3270	"The Random Variable is X = ""The sum of the scores on the two dice"". Let's count how often each value occurs, and work out the probabilities: 2 occurs just once, so P(X = 2) = 1/36. 3 occurs twice, so P(X = 3) = 2/36 = 1/18."	How do you find the random variable	3270
5457	NMF stands for non-negative matrix factorization, a technique for obtaining low rank representation of matrices with non-negative or positive elements.  In information retrieval and text mining, we rely on term-document matrices for representing document collections.	What is NMF machine learning	5457
1691	Error -- subtract the theoretical value (usually the number the professor has as the target value) from your experimental data point. Percent error -- take the absolute value of the error divided by the theoretical value, then multiply by 100.	How do you determine data error	1691
996	In the literal meaning of the terms, a parametric statistical test is one that makes assumptions about the parameters (defining properties) of the population distribution(s) from which one's data are drawn, while a non-parametric test is one that makes no such assumptions.	What is a nonparametric test what is a parametric test	996
975	The Structural Topic Model allows researchers to flexibly estimate a topic model that includes document-level metadata.  The stm package provides many useful features, including rich ways to explore topics, estimate uncertainty, and visualize quantities of interest.	What is structural topic modeling	975
2923	We can interpret the Poisson regression coefficient as follows: for a one unit change in the predictor variable, the difference in the logs of expected counts is expected to change by the respective regression coefficient, given the other predictor variables in the model are held constant.	How do you interpret Poisson regression results	2923
9916	"The obvious difference between ANOVA and a ""Multivariate Analysis of Variance"" (MANOVA) is the “M”, which stands for multivariate. In basic terms, A MANOVA is an ANOVA with two or more continuous response variables. Like ANOVA, MANOVA has both a one-way flavor and a two-way flavor."	What is the difference between Anova and Manova	9916
2742	Humans are error-prone and biased, but that doesn't mean that algorithms are necessarily better.  But these systems can be biased based on who builds them, how they're developed, and how they're ultimately used. This is commonly known as algorithmic bias.	How are algorithms biased	2742
6369	In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.	What is supervised and unsupervised data	6369
5336	Bad Sampling. The data can be misleading due to the sampling method used to obtain data. For instance, the size and the type of sample used in any statistics play a significant role — many polls and questionnaires target certain audiences that provide specific answers, resulting in small and biased sample sizes.	How can statistics be mislead	5336
6027	In the future, artificial intelligence (AI) is likely to substantially change both marketing strategies and customer behaviors.  Finally, the authors suggest AI will be more effective if it augments (rather than replaces) human managers. AI is going to make our lives better in the future.	How AI will change the future	6027
10390	We will run the ANOVA using the five-step approach.Set up hypotheses and determine level of significance. H0: μ1 = μ2 = μ3 = μ4 H1: Means are not all equal α=0.05.Select the appropriate test statistic.  Set up decision rule.  Compute the test statistic.  Conclusion.	What are the steps to carry out analysis of variance	10390
3588	In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.	What are the differences between supervised and unsupervised learning	3588
10242	A heuristic is a mental shortcut that allows people to solve problems and make judgments quickly and efficiently. These rule-of-thumb strategies shorten decision-making time and allow people to function without constantly stopping to think about their next course of action.	How do heuristics affect decision making	10242
1795	A distribution with a single mode is said to be unimodal. A distribution with more than one mode is said to be bimodal, trimodal, etc., or in general, multimodal.	Is the distribution unimodal or multimodal	1795
2352	The least squares method is a statistical procedure to find the best fit for a set of data points by minimizing the sum of the offsets or residuals of points from the plotted curve. Least squares regression is used to predict the behavior of dependent variables.	What are the uses of least square method	2352
4828	The planning problem in Artificial Intelligence is about the decision making performed by intelligent creatures like robots, humans, or computer programs when trying to achieve some goal.  In the following we discuss a number of ways of formalizing planning, and show how the planning problem can be solved automatically.	What is planning problem in AI	4828
114	In order to fit the best intercept line between the points in the above scatter plots, we use a metric called “Sum of Squared Errors” (SSE) and compare the lines to find out the best fit by reducing errors.	What is the metric used by ordinary least squares OLS to determine the best fit line	114
5763	In statistics, a sequence (or a vector) of random variables is homoscedastic /ˌhoʊmoʊskəˈdæstɪk/ if all its random variables have the same finite variance. This is also known as homogeneity of variance. The complementary notion is called heteroscedasticity.	What is Homoscedasticity in statistics	5763
9647	Overall, Sentiment analysis may involve the following types of classification algorithms:Linear Regression.Naive Bayes.Support Vector Machines.RNN derivatives LSTM and GRU.	Which algorithm is best for sentiment analysis	9647
3855	"While measures of central tendency are used to estimate ""normal"" values of a dataset, measures of dispersion are important for describing the spread of the data, or its variation around a central value. A proper description of a set of data should include both of these characteristics."	Why are measures of dispersion used in addition to measures of central tendency	3855
3336	Logistic regression is a model for binary classification predictive modeling.  Under this framework, a probability distribution for the target variable (class label) must be assumed and then a likelihood function defined that calculates the probability of observing the outcome given the input data and the model.	What is likelihood function in logistic regression	3336
5049	The feedforward neural network was the first and simplest type of artificial neural network devised. In this network, the information moves in only one direction—forward—from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network.	How does feedforward neural network work	5049
7850	Increase the sample size. Often, the most practical way to decrease the margin of error is to increase the sample size.  Reduce variability. The less that your data varies, the more precisely you can estimate a population parameter.  Use a one-sided confidence interval.  Lower the confidence level.	How do you reduce the margin of error in statistics	7850
5608	A Bayesian network is a compact, flexible and interpretable representation of a joint probability distribution. It is also an useful tool in knowledge discovery as directed acyclic graphs allow representing causal relations between variables. Typically, a Bayesian network is learned from data.	What is Bayesian network in machine learning	5608
9102	A t score is one form of a standardized test statistic (the other you'll come across in elementary statistics is the z-score). The t score formula enables you to take an individual score and transform it into a standardized form>one which helps you to compare scores.	What is the T score in statistics	9102
414	We can call a Logistic Regression a Linear Regression model but the Logistic Regression uses a more complex cost function, this cost function can be defined as the 'Sigmoid function' or also known as the 'logistic function' instead of a linear function.	What is the cost function used in logistic regression	414
1941	Bayesian inference is a method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available. Bayesian inference is an important technique in statistics, and especially in mathematical statistics.	Why is Bayesian inference	1941
5379	3.2 How to test for differences between samplesDecide on a hypothesis to test, often called the “null hypothesis” (H0 ). In our case, the hypothesis is that there is no difference between sets of samples.  Decide on a statistic to test the truth of the null hypothesis.Calculate the statistic.Compare it to a reference value to establish significance, the P-value.	How do you know if two samples are significantly different	5379
9785	Mean, variance, and standard deviation The mean of the sampling distribution of the sample mean will always be the same as the mean of the original non-normal distribution. In other words, the sample mean is equal to the population mean. where σ is population standard deviation and n is sample size.	Is sample mean equal to population mean	9785
3329	In sampling with replacement the mean of all sample means equals the mean of the population:  Whatever the shape of the population distribution, the distribution of sample means is approximately normal with better approximations as the sample size, n, increases.	What is sampling distribution of mean with replacement	3329
3689	A statistical model is a mathematical representation (or mathematical model) of observed data. When data analysts apply various statistical models to the data they are investigating, they are able to understand and interpret the information more strategically.	What are statistical models used for	3689
6702	If the mean more accurately represents the center of the distribution of your data, and your sample size is large enough, use a parametric test. If the median more accurately represents the center of the distribution of your data, use a nonparametric test even if you have a large sample size.	How do you know whether to use parametric or nonparametric	6702
5921	The Basics of a One-Tailed Test Hypothesis testing is run to determine whether a claim is true or not, given a population parameter. A test that is conducted to show whether the mean of the sample is significantly greater than and significantly less than the mean of a population is considered a two-tailed test.	What is a one sided vs a two sided hypothesis test	5921
4105	The distribution for z is the standard normal distribution; it has a mean of 0 and a standard deviation of 1. For Ha: p ≠ 26, the P-value would be P(z ≤ -1.83) + P(z ≥ 1.83) = 2 * P(z ≤ -1.83). Regardless of Ha, z = (p̂ - p0) / sqrt(p0 * (1 - p0) / n), where z gives the number of standard deviations p̂ is from p0.	How do you find the p value in a normal distribution	4105
1979	A certain continuous random variable has a probability density function (PDF) given by: f ( x ) = C x ( 1 − x ) 2 , f(x) = C x (1-x)^2, f(x)=Cx(1−x)2, where x x x can be any number in the real interval [ 0 , 1 ] [0,1] [0,1]. Compute C C C using the normalization condition on PDFs.	How do you find the probability density function of a continuous random variable	1979
5355	There is no non-parametric form of any regression. Regression means you are assuming that a particular parameterized model generated your data, and trying to find the parameters. Non-parametric tests are test that make no assumptions about the model that generated your data.	What is the non parametric equivalent of the linear regression	5355
5569	How to Deal with MulticollinearityRedesign the study to avoid multicollinearity.  Increase sample size.  Remove one or more of the highly-correlated independent variables.  Define a new variable equal to a linear combination of the highly-correlated variables.	How do you handle multicollinearity in regression modeling	5569
2752	The F ratio is the ratio of two mean square values. If the null hypothesis is true, you expect F to have a value close to 1.0 most of the time. A large F ratio means that the variation among group means is more than you'd expect to see by chance.	What does an F ratio mean	2752
5895	The ability to detect certain types of stimuli, like movements, shape, and angles, requires specialized cells in the brain called feature detectors. Without these, it would be difficult, if not impossible, to detect a round object, like a baseball, hurdling toward you at 90 miles per hour.	What do feature detectors detect	5895
2960	NLP is short for natural language processing while NLU is the shorthand for natural language understanding. Similarly named, the concepts both deal with the relationship between natural language (as in, what we as humans speak, not what computers understand) and artificial intelligence.	What is NLU and NLP	2960
1108	A curve that represents the cumulative frequency distribution of grouped data on a graph is called a Cumulative Frequency Curve or an Ogive.	Which plot is required for cumulative frequency distribution	1108
5749	Depth is the number of filters. Depth column (or fibre) is the set of neurons that are all pointing to the same receptive field. Stride has the objective of producing smaller output volumes spatially. For example, if a stride=2, the filter will shift by the amount of 2 pixels as it convolves around the input volume.	What is depth in CNN	5749
5667	In statistics, the bias (or bias function) of an estimator is the difference between this estimator's expected value and the true value of the parameter being estimated. An estimator or decision rule with zero bias is called unbiased.  When a biased estimator is used, bounds of the bias are calculated.	What is bias function	5667
10573	Normal distribution describes continuous data which have a symmetric distribution, with a characteristic 'bell' shape. Binomial distribution describes the distribution of binary data from a finite sample.  Poisson distribution describes the distribution of binary data from an infinite sample.	What is the difference between binomial Poisson and normal distributions	10573
1039	How To Develop a Machine Learning Model From ScratchDefine adequately our problem (objective, desired outputs…).Gather data.Choose a measure of success.Set an evaluation protocol and the different protocols available.Prepare the data (dealing with missing values, with categorial values…).Spilit correctly the data.More items	How do you make a deep learning model from scratch	1039
7094	We can use MLE in order to get more robust parameter estimates. Thus, MLE can be defined as a method for estimating population parameters (such as the mean and variance for Normal, rate (lambda) for Poisson, etc.) from sample data such that the probability (likelihood) of obtaining the observed data is maximized.	Why do we use maximum likelihood estimation	7094
292	An RNN has a looping mechanism that acts as a highway to allow information to flow from one step to the next. Passing Hidden State to next time step. This information is the hidden state, which is a representation of previous inputs. Let's run through an RNN use case to have a better understanding of how this works.	What is a hidden state in RNN	292
10057	In simple random sampling, each member of a population has an equal chance of being included in the sample. Also, each combination of members of the population has an equal chance of composing the sample. Those two properties are what defines simple random sampling.	What is the probability of a simple random sample	10057
2423	jackknifing is calculation with data sets sampled randomly from the original data.  Bootstrapping is similar to jackknifing except that the position chosen at random may include multiple copies of the same position, to form data sets of the same size as original, to preserve statistical properties of data sampling.	Why is it called bootstrapping statistics	2423
4448	Gradient boosted regression and classification is an additive training tree classification method where trees are build in series (iteratively) and compared to each other based on a mathematically derived score of splits. The trees are compared based on weighted leaf scores within each tree.	How does gradient boosting work for classification	4448
5140	AlphaGo was initially trained to mimic human play by attempting to match the moves of expert players from recorded historical games, using a database of around 30 million moves.	How was AlphaGo trained	5140
1104	Classification accuracy is the ratio of correct predictions to total predictions made. classification accuracy = correct predictions / total predictions. 1. classification accuracy = correct predictions / total predictions. It is often presented as a percentage by multiplying the result by 100.	What is accuracy in confusion matrix	1104
10188	MANOVA is useful in experimental situations where at least some of the independent variables are manipulated. It has several advantages over ANOVA. First, by measuring several dependent variables in a single experiment, there is a better chance of discovering which factor is truly important.	Why use a Manova instead of Anova	10188
1514	Essentially, multivariate analysis is a tool to find patterns and relationships between several variables simultaneously. It lets us predict the effect a change in one variable will have on other variables.	What is multivariate analysis used for	1514
633	7 Best Models for Image Classification using Keras1 Xception. It translates to “Extreme Inception”.  2 VGG16 and VGG19: This is a keras model with 16 and 19 layer network that has an input size of 224X224.  3 ResNet50. The ResNet architecture is another pre-trained model highly useful in Residual Neural Networks.  4 InceptionV3.  5 DenseNet.  6 MobileNet.  7 NASNet.	What is the best model for image classification	633
734	Definition 1. Suppose that events A and B are defined on the same probability space, and the event B is such that P(B) > 0. The conditional probability of A given that B has occurred is given by P(A|B) = P(A ∩ B)/P(B).	How do you prove conditional probability	734
10729	Message passing algorithm which is an iterative decoding algorithm factorizes the global function of many variables into product of simpler local functions, whose arguments are the subset of variables. In order to visualize this factorization we use factor graph.	What is message passing algorithm	10729
6298	This means that the sum of two independent normally distributed random variables is normal, with its mean being the sum of the two means, and its variance being the sum of the two variances (i.e., the square of the standard deviation is the sum of the squares of the standard deviations).	Is the sum of two normal distributions normal	6298
5453	Postprocessing procedures usually include various pruning routines, rule quality processing, rule filtering, rule combination, model combination, or even knowledge integration. All these procedures provide a kind of symbolic filter for noisy, imprecise, or non-user-friendly knowledge derived by an inductive algorithm.	What is post processing in machine learning	5453
9179	Summary: Population variance refers to the value of variance that is calculated from population data, and sample variance is the variance calculated from sample data.  As a result both variance and standard deviation derived from sample data are more than those found out from population data.	What is the difference between population variance and sample variance	9179
9364	Filter methods measure the relevance of features by their correlation with dependent variable while wrapper methods measure the usefulness of a subset of feature by actually training a model on it. Filter methods are much faster compared to wrapper methods as they do not involve training the models.	What is filter method in feature selection	9364
10713	Normal distribution, also known as the Gaussian distribution, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. In graph form, normal distribution will appear as a bell curve.	What does a normal distribution model	10713
10669	Generally, z-tests are used when we have large sample sizes (n > 30), whereas t-tests are most helpful with a smaller sample size (n < 30). Both methods assume a normal distribution of the data, but the z-tests are most useful when the standard deviation is known.	When is the t test preferred to the Z test	10669
1547	Here are 5 common machine learning problems and how you can overcome them.1) Understanding Which Processes Need Automation.  2) Lack of Quality Data.  3) Inadequate Infrastructure.  4) Implementation.  5) Lack of Skilled Resources.	What are the problems of machine learning	1547
3414	Select a File for Image ChangeFrom the Toolbox, select Change Detection > Image Change Workflow. Select an input file from the File Selection dialog.  To apply a mask, select the Input Mask tab in the File Selection panel.  Select the Input Files tab again.Enter the path and filename for the Time 2 File.  Click Next.	How do you do change detection ENVI	3414
4745	The sampling distribution of the sample mean is very useful because it can tell us the probability of getting any specific mean from a random sample.	What is the sampling distribution of the means and why is it useful	4745
2077	While the chi-squared test relies on an approximation, Fisher's exact test is one of exact tests. Especially when more than 20% of cells have expected frequencies < 5, we need to use Fisher's exact test because applying approximation method is inadequate.	When should Fisher's exact test be used	2077
5764	Strictly speaking, a neural network (also called an “artificial neural network”) is a type of machine learning model that is usually used in supervised learning.  A perceptron is a simplified model of a human neuron that accepts an input and performs a computation on that input.	Does machine learning use neural networks	5764
6000	"Here are 25 phases that you can use to increase confidence and self-esteem in your children.“You are capable.""  “That was brave.""  “You've got this.""  “I believe in you.""  “You can do hard things.""  “No matter what happens, I love you.""  “Let's try it together.""  “How'd you do that?""More items"	What words improve your confidence levels	6000
10066	An object detector that uses anchor boxes can process an entire image at once, making real-time object detection systems possible. Because a convolutional neural network (CNN) can process an input image in a convolutional manner, a spatial location in the input can be related to a spatial location in the output.	How do anchor boxes in object detection really work	10066
368	To conclude, the important thing to remember about the odds ratio is that an odds ratio greater than 1 is a positive association (i.e., higher number for the predictor means group 1 in the outcome), and an odds ratio less than 1 is negative association (i.e., higher number for the predictor means group 0 in the outcome	How do you interpret the odds ratio in logistic regression	368
6374	Multinomial Naïve Bayes uses term frequency i.e. the number of times a given term appears in a document.  After normalization, term frequency can be used to compute maximum likelihood estimates based on the training data to estimate the conditional probability.	How does multinomial naive Bayes work	6374
4537	Energy is quantized in some systems, meaning that the system can have only certain energies and not a continuum of energies, unlike the classical case. This would be like having only certain speeds at which a car can travel because its kinetic energy can have only certain values.	Why is energy quantized	4537
9998	The More Formal Formula You can solve these types of problems using the steps above, or you can us the formula for finding the probability for a continuous uniform distribution: P(X) = d – c / b – a. This is also sometimes written as: P(X) = x2 – x1 / b – a.	How do you find the continuous probability of a uniform	9998
1462	The use of sigmoidal nonlinear functions was inspired by the ouputs of biological neurons.  However, this function is not smooth (it fails to be differential at the threshold value). Therefore, the sigmoid class of functions is a differentiable alternative that still captures much of the behavior of biological neurons.	Why is sigmoid nonlinear	1462
8867	Chi-square Test. The Pearson's χ2 test (after Karl Pearson, 1900) is the most commonly used test for the difference in distribution of categorical variables between two or more independent groups.	How do you find the difference between two categorical variables	8867
9568	Regularization is a technique used for tuning the function by adding an additional penalty term in the error function. The additional term controls the excessively fluctuating function such that the coefficients don't take extreme values.	Why is regularization used	9568
9390	2:1510:12Suggested clip · 108 secondsHistograms In Photography - YouTubeYouTubeStart of suggested clipEnd of suggested clip	How are histograms used in photography	9390
5155	Abstract: The dimensionality curse phenomenon states that in high dimensional spaces distances between nearest and farthest points from query points become almost equal. Therefore, nearest neighbor calculations cannot discriminate candidate points.	What is curse of dimensionality in Knn	5155
5276	The following are common methods:Mean imputation. Simply calculate the mean of the observed values for that variable for all individuals who are non-missing.  Substitution.  Hot deck imputation.  Cold deck imputation.  Regression imputation.  Stochastic regression imputation.  Interpolation and extrapolation.	How do you impute missing values	5276
10974	Bagging is a way to decrease the variance in the prediction by generating additional data for training from dataset using combinations with repetitions to produce multi-sets of the original data. Boosting is an iterative technique which adjusts the weight of an observation based on the last classification.	What is the difference between boosting and bagging	10974
5038	There is a popular method known as elbow method which is used to determine the optimal value of K to perform the K-Means Clustering Algorithm. The basic idea behind this method is that it plots the various values of cost with changing k. As the value of K increases, there will be fewer elements in the cluster.	Is a way of finding the K value for K means clustering	5038
6678	Say we want to estimate the mean of a population. While the most used estimator is the average of the sample, another possible estimator is simply the first number drawn from the sample.  In theory, you could have an unbiased estimator whose variance is asymptotically nonzero, and that would be inconsistent.	Can an estimator be unbiased or inconsistent	6678
4943	The term normal score is used with two different meanings in statistics.  A given data point is assigned a value which is either exactly, or an approximation, to the expectation of the order statistic of the same rank in a sample of standard normal random variables of the same size as the observed data set.	What is a normal score in statistics	4943
4534	You can use a generative model. You can also use simple tricks. For example, with photograph image data, you can get big gains by randomly shifting and rotating existing images. It improves the generalization of the model to such transforms in the data if they are to be expected in new data.	How can you improve the generalization of the deep learning model	4534
307	"In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs. A standard integrated circuit can be seen as a digital network of activation functions that can be ""ON"" (1) or ""OFF"" (0), depending on input."	What is activation function used in a neural network	307
8063	The objective of Unsupervised Anomaly Detection is to detect previously unseen rare objects or events without any prior knowledge about these. The only information available is that the percentage of anomalies in the dataset is small, usually less than 1%.	What is unsupervised anomaly detection	8063
5699	Steps for Using ANOVAStep 1: Compute the Variance Between. First, the sum of squares (SS) between is computed:  Step 2: Compute the Variance Within. Again, first compute the sum of squares within.  Step 3: Compute the Ratio of Variance Between and Variance Within. This is called the F-ratio.	How is analysis of variance calculated	5699
8975	Use simple logistic regression when you have one nominal variable and one measurement variable, and you want to know whether variation in the measurement variable causes variation in the nominal variable.	When should you use logistic regression	8975
2097	A multinomial experiment is almost identical with one main difference: a binomial experiment can have two outcomes, while a multinomial experiment can have multiple outcomes.  A binomial experiment will have a binomial distribution.	What is difference between binomial and multinomial distribution	2097
6550	Use regression analysis to describe the relationships between a set of independent variables and the dependent variable. Regression analysis produces a regression equation where the coefficients represent the relationship between each independent variable and the dependent variable.	What are regression models used for	6550
3757	The primary reason skew is important is that analysis based on normal distributions incorrectly estimates expected returns and risk.  Knowing that the market has a 70% probability of going up and a 30% probability of going down may appear helpful if you rely on normal distributions.	Why is skewness important in statistics	3757
9658	What you want is multi-label classification, so you will use Binary Cross-Entropy Loss or Sigmoid Cross-Entropy loss. It is a Sigmoid activation plus a Cross-Entropy loss.	What loss function will you use to measure multi label problems	9658
1881	According to Cohen's original article, values ≤ 0 as indicating no agreement and 0.01–0.20 as none to slight, 0.21–0.40 as fair, 0.41– 0.60 as moderate, 0.61–0.80 as substantial, and 0.81–1.00 as almost perfect agreement.	What is acceptable inter rater reliability	1881
5249	Generative adversarial networks (GANs) are an exciting recent innovation in machine learning. GANs are generative models: they create new data instances that resemble your training data. For example, GANs can create images that look like photographs of human faces, even though the faces don't belong to any real person.	What is Gan in deep learning	5249
1276	Models that are pre-trained on ImageNet are good at detecting high-level features like edges, patterns, etc. These models understand certain feature representations, which can be reused.	Why it is beneficial to use pre trained models	1276
7702	Time series data means that data is in a series of particular time periods or intervals. The data is considered in three types: Time series data: A set of observations on the values that a variable takes at different times. Cross-sectional data: Data of one or more variables, collected at the same point in time.	What is time series data in statistics	7702
10477	There are two types of hierarchical clustering, Divisive and Agglomerative.	What are the two types of hierarchical clustering	10477
6492	In terms of linear regression, variance is a measure of how far observed values differ from the average of predicted values, i.e., their difference from the predicted value mean. The goal is to have a value that is low.	What is variance in multiple regression	6492
5603	PDF according to input X being discrete or continuous generates probability mass functions and CDF does the same but generates cumulative mass function. That means, PDF is derivative of CDF and CDF can be applied at any point where PDF has been applied.  The cumulative function is the integral of the density function.	What is the difference between a probability distribution function and a cumulative	5603
7760	6 Freebies to Help You Increase the Performance of Your Object Detection ModelsVisually Coherent Image Mix-up for Object Detection (+3.55% mAP Boost)Classification Head Label Smoothening (+2.16% mAP Boost)Data Pre-processing (Mixed Results)Training Scheduler Revamping (+1.44% mAP Boost)More items	How can you improve the accuracy of an object detection	7760
9475	The chi-square goodness of fit test is appropriate when the following conditions are met: The sampling method is simple random sampling. The variable under study is categorical. The expected value of the number of sample observations in each level of the variable is at least 5.	What are the conditions for conducting a chi square goodness of fit test	9475
4530	"In this context, correlation only makes sense if the relationship is indeed linear. Second, the slope of the regression line is proportional to the correlation coefficient: slope = r*(SD of y)/(SD of x) Third: the square of the correlation, called ""R-squared"", measures the ""fit"" of the regression line to the data."	Is R the slope of the regression line	4530
3976	Weaknesses. Histograms have many benefits, but there are two weaknesses. A histogram can present data that is misleading. For example, using too many blocks can make analysis difficult, while too few can leave out important data.	What are the disadvantages of using a histogram	3976
10272	The false positive rate is calculated as FP/FP+TN, where FP is the number of false positives and TN is the number of true negatives (FP+TN being the total number of negatives). It's the probability that a false alarm will be raised: that a positive result will be given when the true value is negative.	How do you determine a false positive rate	10272
5797	Statistical Methods for Finding the Best Regression ModelAdjusted R-squared and Predicted R-squared: Generally, you choose the models that have higher adjusted and predicted R-squared values.  P-values for the predictors: In regression, low p-values indicate terms that are statistically significant.More items•	Which regression model is best	5797
323	In statistics, a positively skewed (or right-skewed) distribution is a type of distribution in which most values are clustered around the left tail of the distribution while the right tail of the distribution is longer.	What is a positive skew in statistics	323
7921	Ridge regression has an additional factor called λ (lambda) which is called the penalty factor which is added while estimating beta coefficients. This penalty factor penalizes high value of beta which in turn shrinks beta coefficients thereby reducing the mean squared error and predicted error.	Why does ridge regression reduce variance	7921
1045	Eigenface	Which algorithm is used for face detection	1045
1909	Learning Rate and Gradient Descent Specifically, the learning rate is a configurable hyperparameter used in the training of neural networks that has a small positive value, often in the range between 0.0 and 1.0. The learning rate controls how quickly the model is adapted to the problem.	What is the learning rate in the context of deep learning	1909
2629	Informally, a neural attention mechanism equips a neural network with the ability to focus on a subset of its inputs (or features): it selects specific inputs.	What is Attention neural network	2629
3746	Seriously, the p value is literally a confounded index because it reflects both the size of the underlying effect and the size of the sample. Hence any information included in the p value is ambiguous (Lang et al. 1998).  The smaller the sample, the less likely the result will be statistically significant.	Why are p values considered confounded statistics	3746
4813	"However, experts expect that it won't be until 2060 until AGI has gotten good enough to pass a ""consciousness test"". In other words, we're probably looking at 40 years from now before we see an AI that could pass for a human."	How far away are we from AGI	4813
4228	A two layer (one input layer, one output layer; no hidden layer) neural network can represent the XOR function. We must compose multiple logical operations by using a hidden layer to represent the XOR function.	Can a 2 layer neural network represent the XOR function	4228
841	The F Distribution The distribution of all possible values of the f statistic is called an F distribution, with v1 = n1 - 1 and v2 = n2 - 1 degrees of freedom. The curve of the F distribution depends on the degrees of freedom, v1 and v2.	What is an F distribution in statistics	841
7536	The focus will especially be on applications of stochastic processes as key technologies in various research areas, such as Markov chains, renewal theory, control theory, nonlinear theory, queuing theory, risk theory, communication theory engineering and traffic engineering.	What are the applications of stochastic process	7536
8321	Advantages of Machine LearningContinuous Improvement. Machine Learning algorithms are capable of learning from the data we provide.  Automation for everything.  Trends and patterns identification.  Wide range of applications.  Data Acquisition.  Highly error-prone.  Algorithm Selection.  Time-consuming.	What are the advantages of machine learning	8321
7129	The potential solutions include the following:Remove some of the highly correlated independent variables.Linearly combine the independent variables, such as adding them together.Perform an analysis designed for highly correlated variables, such as principal components analysis or partial least squares regression.	What do you do when a variable is correlated	7129
9530	According to SAS, predictive analytics is “the use of data, statistical algorithms and machine learning techniques to identify the likelihood of future outcomes based on historical data.  In short, predictive intelligence drives marketing decisions.”	Do predictive analytics drive more informed decisions	9530
9254	POS tags make it possible for automatic text processing tools to take into account which part of speech each word is. This facilitates the use of linguistic criteria in addition to statistics.	Why is POS tagging useful	9254
9106	(Example: a test with 90% specificity will correctly return a negative result for 90% of people who don't have the disease, but will return a positive result — a false-positive — for 10% of the people who don't have the disease and should have tested negative.)	What is a good false positive rate	9106
7367	It basically defined on probability estimates and measures the performance of a classification model where the input is a probability value between 0 and 1. It can be understood more clearly by differentiating it with accuracy.	What is performance measure in machine learning	7367
5961	TensorBoard is a suite of web applications for inspecting and understanding your TensorFlow runs and graphs. TensorBoard currently supports five visualizations: scalars, images, audio, histograms, and graphs.	What is tensor board	5961
994	For a discrete random variable, the expected value, usually denoted as or , is calculated using: μ = E ( X ) = ∑ x i f ( x i )	What is the expected value of a discrete distribution	994
10596	The Sobel filter is used for edge detection. It works by calculating the gradient of image intensity at each pixel within the image.  The result shows how abruptly or smoothly the image changes at each pixel, and therefore how likely it is that that pixel represents an edge.	How does Sobel edge detection work	10596
231	Multinomial logistic regression is used when the dependent variable in question is nominal (equivalently categorical, meaning that it falls into any one of a set of categories that cannot be ordered in any meaningful way) and for which there are more than two categories.	When would you use a multinomial	231
3785	A Z score is the number of standard deviations a given result is above (positive score) or below (negative score) the age- and sex-adjusted population mean. Results that are within the IGF-1 reference interval will have a Z score between -2.0 and +2.0.	What is Z score in blood test	3785
4016	Sensitivity is a measure of the proportion of actual positive cases that got predicted as positive (or true positive).  This implies that there will be another proportion of actual positive cases, which would get predicted incorrectly as negative (and, thus, could also be termed as the false negative).	What is sensitivity in machine learning	4016
1724	The eigenvalues and eigenvectors of a matrix are often used in the analysis of financial data and are integral in extracting useful information from the raw data. They can be used for predicting stock prices and analyzing correlations between various stocks, corresponding to different companies.	Where do we use eigen values	1724
6578	IBM SPSS Statistics for Mac is the ultimate tool for managing your statistics data and research. This super-app affords you complete control over your data.	Can you get SPSS on Mac	6578
1890	Despite having similar aims and processes, there are two main differences between them: Machine learning works out predictions and recalibrates models in real-time automatically after design. Meanwhile, predictive analytics works strictly on “cause” data and must be refreshed with “change” data.	What is the difference between analytics and machine learning	1890
2106	The main difference between Independant and Independent is that the Independant is a misspelling of independent and Independent is a Not dependent; free; not subject to control by others; not relying on others.	What is the difference between independent and independant	2106
969	Statistical researchers often use a linear relationship to predict the (average) numerical value of Y for a given value of X using a straight line (called the regression line). If you know the slope and the y-intercept of that regression line, then you can plug in a value for X and predict the average value for Y.	How do you use linear regression to predict future values	969
4080	The binomial theorem is valid more generally for any elements x and y of a semiring satisfying xy = yx. The theorem is true even more generally: alternativity suffices in place of associativity. The binomial theorem can be stated by saying that the polynomial sequence {1, x, x2, x3, } is of binomial type.	What is binomial theorem	4080
2391	In statistics, the Huber loss is a loss function used in robust regression, that is less sensitive to outliers in data than the squared error loss. A variant for classification is also sometimes used.	What is Huber regression	2391
428	The p-value is calculated using the sampling distribution of the test statistic under the null hypothesis, the sample data, and the type of test being done (lower-tailed test, upper-tailed test, or two-sided test).  an upper-tailed test is specified by: p-value = P(TS ts | H 0 is true) = 1 - cdf(ts)	What is the P value formula	428
9307	A unimodal distribution only has one peak in the distribution, a bimodal distribution has two peaks, and a multimodal distribution has three or more peaks. Another way to describe the shape of histograms is by describing whether the data is skewed or symmetric.	How many peaks does a multimodal distribution have	9307
5073	Since this derivation of the LDA direction via least squares does not use a Gaussian assumption for the features, its applicability extends beyond the realm of Gaussian data. However the derivation of the particular intercept or cut-point given in (4.11) does require Gaussian data.	Does Linear Discriminant Analysis work for distributions other than Gaussian	5073
9435	"Consistency refers to logical and numerical coherence. Context: An estimator is called consistent if it converges in probability to its estimand as sample increases (The International Statistical Institute, ""The Oxford Dictionary of Statistical Terms"", edited by Yadolah Dodge, Oxford University Press, 2003)."	What does consistent mean in statistics	9435
9638	For a normal distribution, the average deviation is somewhat less efficient than the standard deviation as a measure of scale, but this advantage quickly reverses for distributions with heavier tails.	What is the advantage of the standard deviation over the average deviation	9638
6580	The principle of maximum likelihood is a method of obtaining the optimum values of the parameters that define a model. And while doing so, you increase the likelihood of your model reaching the “true” model.	What is the principle of maximum likelihood	6580
10511	Loss value implies how poorly or well a model behaves after each iteration of optimization. An accuracy metric is used to measure the algorithm's performance in an interpretable way. The accuracy of a model is usually determined after the model parameters and is calculated in the form of a percentage.	What is loss value	10511
2519	Sampling error is one of two reasons for the difference between an estimate and the true, but unknown, value of the population parameter.  The sampling error for a given sample is unknown but when the sampling is random, the maximum likely size of the sampling error is called the margin of error.	What is the difference between sampling error and margin of error	2519
6411	Below are the different regression techniques: Ridge Regression. Lasso Regression. Polynomial Regression. Bayesian Linear Regression.	What are the types of regression analysis	6411
2766	Support vectors are the elements of the training set that would change the position of the dividing hyperplane if removed. d+ = the shortest distance to the closest positive point d- = the shortest distance to the closest negative point The margin (gutter) of a separating hyperplane is d+ + d–.	How do you find the support vector	2766
1178	Whereas most machine learning based object categorization algorithms require training on hundreds or thousands of samples/images and very large datasets, one-shot learning aims to learn information about object categories from one, or only a few, training samples/images.	What is one shot learning in neural networks	1178
7227	Fine tuning is one approach to transfer learning. In Transfer Learning or Domain Adaptation we train the model with a dataset and after we train the same model with another dataset that has a different distribution of classes, or even with other classes than in the training dataset).	Is fine tuning a pre trained model equivalent to transfer learning	7227
3485	A residual neural network (ResNet) is an artificial neural network (ANN) of a kind that builds on constructs known from pyramidal cells in the cerebral cortex. Residual neural networks do this by utilizing skip connections, or shortcuts to jump over some layers.	What is ResNet neural network	3485
1523	Optimization falls in this category — given an optimization problem, you can, in principle, find a solution to the problem, without any ambiguity whatsoever. Machine learning, on the other hand, falls in the domain of engineering. Problems in engineering are often not mathematically well-defined.	What is the difference between an optimization problem and a machine learning problem	1523
5432	Class limits specify the span of data values that fall within a class. Class boundaries are possible data values. Class boundaries are not possible data values.	What is the difference between class limits and class boundaries in statistics	5432
899	Federated Learning is a machine learning setting where the goal is to train a high-quality centralized model with training data distributed over a large number of clients each with unreliable and relatively slow network connections.	What is a federated learning model	899
4904	In the context of conventional artificial neural networks convergence describes a progression towards a network state where the network has learned to properly respond to a set of training patterns within some margin of error.	What does neural network convergence mean	4904
7347	The mean is an important measure because it incorporates the score from every subject in the research study. The required steps for its calculation are: count the total number of cases—referred in statistics as n; add up all the scores and divide by the total number of cases.	Why is the mean useful in statistics	7347
183	Interpreting. If skewness is positive, the data are positively skewed or skewed right, meaning that the right tail of the distribution is longer than the left. If skewness is negative, the data are negatively skewed or skewed left, meaning that the left tail is longer.	How do you interpret a positively skewed distribution	183
3795	Principal Component Analysis (PCA) is used to explain the variance-covariance structure of a set of variables through linear combinations. It is often used as a dimensionality-reduction technique.	What is the use of principal component analysis	3795
2880	Y hat (written ŷ ) is the predicted value of y (the dependent variable) in a regression equation. It can also be considered to be the average value of the response variable.  The equation is calculated during regression analysis.	What is Y hat in regression	2880
10028	15:3248:19Suggested clip · 37 secondsMotion 5 | How to Use Motion Tracking, Analyze Motion, and Match YouTubeStart of suggested clipEnd of suggested clip	How do you analyze motion	10028
5835	"A parameter is any summary number, like an average or percentage, that describes the entire population. The population mean (the greek letter ""mu"") and the population proportion p are two different population parameters. For example:  The population comprises all likely American voters, and the parameter is p."	What is parameter with example	5835
7000	FP. N. FN. TN. where: P = Positive; N = Negative; TP = True Positive; FP = False Positive; TN = True Negative; FN = False Negative.	What is TP TN FP FN	7000
7571	Epsilon greedy policy is a way of selecting random actions with uniform distribution from a set of available actions.  This policy selects random actions in twice if the value of epsilon is 0.2. Consider a following example, There is a robot with capability to move in 4 direction. Up,down,left,right.	What is Epsilon greedy policy	7571
10525	7 Advantages of Robots in the WorkplaceSafety. Safety is the most obvious advantage of utilizing robotics.  Speed. Robots don't get distracted or need to take breaks.  Consistency. Robots never need to divide their attention between a multitude of things.  Perfection. Robots will always deliver quality.  Happier Employees.  Job Creation.  Productivity.	What are the positive effects of robots	10525
9988	Given any collection of pairs of numbers (except when all the x-values are the same) and the corresponding scatter diagram, there always exists exactly one straight line that fits the data better than any other, in the sense of minimizing the sum of the squared errors. It is called the least squares regression line.	What is special about a least squares regression line	9988
10478	There are two main differences between regression and structural equation modelling. The first is that SEM allows us to develop complex path models with direct and indirect effects. This allows us to more accurately model causal mechanisms we are interested in. The second key difference is to do with measurement.	What is the difference between regression and structural equation modeling	10478
8785	A unit of measurement is some specific quantity that has been chosen as the standard against which other measurements of the same kind are made.  The term standard refers to the physical object on which the unit of measurement is based.	What is unit and standard unit	8785
5807	"Eigenvalues and eigenvectors allow us to ""reduce"" a linear operation to separate, simpler, problems. For example, if a stress is applied to a ""plastic"" solid, the deformation can be dissected into ""principle directions""- those directions in which the deformation is greatest."	What is the application of eigenvalues and eigenvectors	5807
3793	Role of Scaling is mostly important in algorithms that are distance based and require Euclidean Distance. Random Forest is a tree-based model and hence does not require feature scaling.	Is feature scaling required for random forest	3793
7892	2 Multivariate Data. Multivariate data contains, at each sample point, multiple scalar values that represent different simulated or measured quantities.	What is a multivariate data set	7892
1324	Uncertainty is a popular phenomenon in machine learning and a variety of methods to model uncertainty at different levels has been developed.  Different types of uncertainty can be observed: (i) Input data are subject to noise, outliers, and errors.	What is uncertainty in machine learning	1324
4365	In computer vision, the bag-of-words model (BoW model) sometimes called bag-of-visual-words model can be applied to image classification, by treating image features as words. In document classification, a bag of words is a sparse vector of occurrence counts of words; that is, a sparse histogram over the vocabulary.	What is Bag of Words in image processing	4365
10896	The main benefit claimed for feature selection, which is the main focus in this manuscript, is that it increases classification accuracy. It is believed that removing non-informative signal can reduce noise, and can increase the contrast between labelled groups.	Does feature selection improve classification accuracy	10896
6548	When used as nouns, quantile means one of the class of values of a variate which divides the members of a batch or sample into equal-sized subgroups of adjacent values or a probability distribution into distributions of equal probability, whereas quartile means any of the three points that divide an ordered	In statistics what is the difference between a quartile and a quantile	6548
237	A residual neural network (ResNet) is an artificial neural network (ANN) of a kind that builds on constructs known from pyramidal cells in the cerebral cortex. Residual neural networks do this by utilizing skip connections, or shortcuts to jump over some layers.	How does residual network work	237
5217	Thus, the t-statistic measures how many standard errors the coefficient is away from zero. Generally, any t-value greater than +2 or less than – 2 is acceptable. The higher the t-value, the greater the confidence we have in the coefficient as a predictor.	What is a good T stat	5217
748	A facial recognition system uses biometrics to map facial features from a photograph or video. It compares the information with a database of known faces to find a match.  That's because facial recognition has all kinds of commercial applications. It can be used for everything from surveillance to marketing.	How does facial verification work	748
7741	If X takes values in [a, b] and Y takes values in [c, d] then the pair (X, Y ) takes values in the product [a, b] × [c, d]. The joint probability density function (joint pdf) of X and Y is a function f(x, y) giving the probability density at (x, y).	How do you find the joint probability density function	7741
1119	Some common types of problems built on top of classification and regression include recommendation and time series prediction respectively. Some popular examples of supervised machine learning algorithms are: Linear regression for regression problems. Random forest for classification and regression problems.	What problems are suitable for supervised machine learning	1119
575	"In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs. A standard integrated circuit can be seen as a digital network of activation functions that can be ""ON"" (1) or ""OFF"" (0), depending on input."	What is an activation function in machine learning	575
1721	In statistical classification, Bayes error rate is the lowest possible error rate for any classifier of a random outcome (into, for example, one of two categories) and is analogous to the irreducible error. A number of approaches to the estimation of the Bayes error rate exist.	What is the Bayesian probability of an error	1721
9528	A cross-sectional study involves looking at data from a population at one specific point in time.  Cross-sectional studies are observational in nature and are known as descriptive research, not causal or relational, meaning that you can't use them to determine the cause of something, such as a disease.	What is a cross sectional study in statistics	9528
7653	A random forest is simply a collection of decision trees whose results are aggregated into one final result. Their ability to limit overfitting without substantially increasing error due to bias is why they are such powerful models. One way Random Forests reduce variance is by training on different samples of the data.	Is Random Forest a decision tree	7653
4419	Low Pass filtering: It is also known as the smoothing filter. It removes the high-frequency content from the image.  Median Filtering: It is also known as nonlinear filtering. It is used to eliminate salt and pepper noise.	Is median filter a low pass filter	4419
1633	Linear regression is the next step up after correlation. It is used when we want to predict the value of a variable based on the value of another variable. The variable we want to predict is called the dependent variable (or sometimes, the outcome variable).	What is linear regression used for	1633
10880	A person who engages in banditry is known as a bandit and primarily commits crimes such as extortion, robbery, and murder, either as an individual or in groups. Banditry is a vague concept of criminality and in modern usage can be synonymous for gangsterism, brigandage, marauding, and thievery.	What did bandits do	10880
10766	Difference between K Means and Hierarchical clustering Hierarchical clustering can't handle big data well but K Means clustering can. This is because the time complexity of K Means is linear i.e. O(n) while that of hierarchical clustering is quadratic i.e. O(n2).	Which is better K means or hierarchical clustering	10766
2073	"In statistics, the phrase ""correlation does not imply causation"" refers to the inability to legitimately deduce a cause-and-effect relationship between two variables solely on the basis of an observed association or correlation between them."	If correlation does not imply causation what does it do	2073
5285	Tests of Correlation: The validity of a test is measured by the strength of association, or correlation, between the results obtained by the test and by the criterion measure.	How do you measure validity in statistics	5285
9221	Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.	What does gradient mean in Machine Learning	9221
6832	To deal with categorical variables that have more than two levels, the solution is one-hot encoding. This takes every level of the category (e.g., Dutch, German, Belgian, and other), and turns it into a variable with two levels (yes/no).	How do you handle a categorical variable with many levels	6832
6992	Brief Description. The Fourier Transform is an important image processing tool which is used to decompose an image into its sine and cosine components. The output of the transformation represents the image in the Fourier or frequency domain, while the input image is the spatial domain equivalent.	What is Fourier transform of an image	6992
5787	The Bayes theorem describes the probability of an event based on the prior knowledge of the conditions that might be related to the event. If we know the conditional probability , we can use the bayes rule to find out the reverse probabilities .	When can Bayes theorem be used	5787
6495	Type 1 error, in statistical hypothesis testing, is the error caused by rejecting a null hypothesis when it is true. Type II error is the error that occurs when the null hypothesis is accepted when it is not true.	What is the difference between a Type I error and a Type II error	6495
646	Distance MatrixThe proximity between object can be measured as distance matrix.  For example, distance between object A = (1, 1) and B = (1.5, 1.5) is computed as.Another example of distance between object D = (3, 4) and F = (3, 3.5) is calculated as.More items	How do you find the distance of a clustered Matrix	646
10951	What Are Moments in Statistics?Moments About the MeanFirst, calculate the mean of the values.Next, subtract this mean from each value.Then raise each of these differences to the sth power.Now add the numbers from step #3 together.Finally, divide this sum by the number of values we started with.	How do you find the moment in statistics	10951
6508	Additivity is a property pertaining to a set of interdependent index numbers related by definition or by accounting constraints under which an aggregate is defined as the sum of its components; additivity requires this identity to be preserved when the values of both an aggregate and its components in some reference	What is additivity in statistics	6508
9328	The first four are: 1) The mean, which indicates the central tendency of a distribution. 2) The second moment is the variance, which indicates the width or deviation. 3) The third moment is the skewness, which indicates any asymmetric 'leaning' to either left or right.	What are the four moments of statistics	9328
10582	You probably have a numerical stability issue. This may happen due to zero division or any operation that is making a number(s) extremely big.	Why do l get NaN values when l train my neural network with a rectified linear unit	10582
3731	The beta distribution of the first kind, usually written in terms of the incom- plete beta function, can be used to model the distribution of measurements whose values all lie between zero and one. It can also be used to model the distribution for the probability of occurrence of some discrete event.	What is the significance of the beta distribution What are some common applications	3731
2726	Random event/process/variable: an event/process that is not and cannot be made exact and, consequently, whose outcome cannot be predicted, e.g., the sum of the numbers on two rolled dice.	What random events mean	2726
6375	metric system. A system of measurement in which the basic units are the meter, the second, and the kilogram. In this system, the ratios between units of measurement are multiples of ten. For example, a kilogram is a thousand grams, and a centimeter is one-hundredth of a meter.	What is the definition of metric system	6375
10019	A correlation between two variables does not imply causation. On the other hand, if there is a causal relationship between two variables, they must be correlated. Example: A study shows that there is a negative correlation between a student's anxiety before a test and the student's score on the test.	Are there ever any circumstances when a correlation can be interpreted as evidence for a causal connection between two variables	10019
6742	A negative binomial random variable is the number X of repeated trials to produce r successes in a negative binomial experiment. The probability distribution of a negative binomial random variable is called a negative binomial distribution.  Suppose we flip a coin repeatedly and count the number of heads (successes).	What does the negative in negative binomial distribution signify	6742
1492	The standard deviation of this set of mean values is the standard error. In lieu of taking many samples one can estimate the standard error from a single sample. This estimate is derived by dividing the standard deviation by the square root of the sample size.	What is the standard error of the mean difference	1492
2490	An autoregressive model is when a value from a time series is regressed on previous values from that same time series.  The order of an autoregression is the number of immediately preceding values in the series that are used to predict the value at the present time.	What is autoregression time series	2490
3143	Technically, the probability density of variable X , means the probability per unit increment of X . The units of probability density are the reciprocal of the units of X — if the units of X are dollars, the units of probability density are probability per dollar increment.	What are the units of a probability density function	3143
9394	"The term ""running median"" is typically used to refer to the median of a subset of data."	What is a running median	9394
8725	How to calculate margin of errorGet the population standard deviation (σ) and sample size (n).Take the square root of your sample size and divide it into your population standard deviation.Multiply the result by the z-score consistent with your desired confidence interval according to the following table:	How do you calculate the margin of error	8725
8415	Spatiotemporal models arise when data are collected across time as well as space and has at least one spatial and one temporal property. An event in a spatiotemporal dataset describes a spatial and temporal phenomenon that exists at a certain time t and location x.	What is spatio temporal model	8415
5540	In machine learning, the vanishing gradient problem is encountered when training artificial neural networks with gradient-based learning methods and backpropagation.  The problem is that in some cases, the gradient will be vanishingly small, effectively preventing the weight from changing its value.	What is vanishing gradient problem in neural networks	5540
3927	In a box plot, we draw a box from the first quartile to the third quartile. A vertical line goes through the box at the median. The whiskers go from each quartile to the minimum or maximum.	How do you plot a box plot	3927
6202	Inference over a Bayesian network can come in two forms. The first is simply evaluating the joint probability of a particular assignment of values for each variable (or a subset) in the network.  We would calculate P(¬x | e) in the same fashion, just setting the value of the variables in x to false instead of true.	What is inference in Bayesian networks	6202
9100	Decision trees provide an effective method of Decision Making because they: Clearly lay out the problem so that all options can be challenged. Allow us to analyze fully the possible consequences of a decision. Provide a framework to quantify the values of outcomes and the probabilities of achieving them.	How is the decision tree useful	9100
750	There are several ways to check your Linear Regression model accuracy. Usually, you may use Root mean squared error. You may train several Linear Regression models, adding or removing features to your dataset, and see which one has the lowest RMSE - the best one in your case.	How do you find the accuracy of a linear regression model	750
5777	There are two types of factor analyses, exploratory and confirmatory. Exploratory factor analysis (EFA) is method to explore the underlying structure of a set of observed variables, and is a crucial step in the scale development process. The first step in EFA is factor extraction.	What are the types of factor analysis	5777
8111	Advantages and disadvantagesAre simple to understand and interpret.  Have value even with little hard data.  Help determine worst, best and expected values for different scenarios.Use a white box model.  Can be combined with other decision techniques.	What are the advantages and disadvantages of decision tree	8111
9052	If there are other predictor variables, all coefficients will be changed.  All the coefficients are jointly estimated, so every new variable changes all the other coefficients already in the model. This is one reason we do multiple regression, to estimate coefficient B1 net of the effect of variable Xm.	Why do coefficients change in multiple regression	9052
6732	Random errors are statistical fluctuations (in either direction) in the measured data due to the precision limitations of the measurement device. Random errors usually result from the experimenter's inability to take the same measurement in exactly the same way to get exact the same number.	What are random errors	6732
6171	The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output. Since probability of anything exists only between the range of 0 and 1, sigmoid is the right choice. The function is differentiable.	Why is sigmoid a good activation function	6171
1849	Ensemble learning methods are widely used nowadays for its predictive performance improvement. Ensemble learning combines multiple predictions (forecasts) from one or multiple methods to overcome accuracy of simple prediction and to avoid possible overfit.	Is it possible to use ensemble learning for time series forecast	1849
5133	The root-mean-square deviation (RMSD) or root-mean-square error (RMSE) is a frequently used measure of the differences between values (sample or population values) predicted by a model or an estimator and the values observed.	What is the use of finding the root mean square error	5133
7937	The distribution pX (x) is called the target distribution, while qX (x) is the sampling distribution or the proposal distribution.	In importance sampling what is the difference between p x and q x	7937
3713	If there is no relationship between X and Y, the best guess for all values of X is the mean of Y. At any rate, the regression line always passes through the means of X and Y. This means that, regardless of the value of the slope, when X is at its mean, so is Y.	Why does regression line go through mean	3713
5083	How to Calculate a CorrelationFind the mean of all the x-values.Find the standard deviation of all the x-values (call it sx) and the standard deviation of all the y-values (call it sy).  For each of the n pairs (x, y) in the data set, take.Add up the n results from Step 3.Divide the sum by sx ∗ sy.More items	How do you find the correlation coefficient between two sets of data	5083
6570	Selection bias can result when the selection of subjects into a study or their likelihood of being retained in the study leads to a result that is different from what you would have gotten if you had enrolled the entire target population.	How does selection bias affect results	6570
10298	Regression analysis refers to assessing the relationship between the outcome variable and one or more variables.  For example, a correlation of r = 0.8 indicates a positive and strong association among two variables, while a correlation of r = -0.3 shows a negative and weak association.	What is meant by correlation and regression analysis	10298
4063	The standard error of the regression (S), also known as the standard error of the estimate, represents the average distance that the observed values fall from the regression line. Conveniently, it tells you how wrong the regression model is on average using the units of the response variable.	What does standard error of estimate tell you	4063
5228	A sampling frame is a list of all the items in your population. It's a complete list of everyone or everything you want to study. The difference between a population and a sampling frame is that the population is general and the frame is specific.	Can a sampling frame be seen as a population	5228
8898	Fewer than 1,000 steps a day is sedentary. 1,000 to 10,000 steps or about 4 miles a day is Lightly Active. 10,000 to 23,000 steps or 4 to 10 miles a day is considered Active. More than 23,000 steps or 10 miles a day is Highly active.	What is considered active activity level	8898
9732	A series converges uniformly on if the sequence of partial sums defined by. (2) converges uniformly on . To test for uniform convergence, use Abel's uniform convergence test or the Weierstrass M-test.	What is uniform convergence series	9732
2735	Machine learning algorithms are the engines of machine learning, meaning it is the algorithms that turn a data set into a model. Which kind of algorithm works best (supervised, unsupervised, classification, regression, etc.)	What is meant by machine learning algorithms	2735
515	Transfer learning without any labeled data from the target domain is referred to as unsupervised transfer learning.	Is transfer learning unsupervised	515
5743	Bootstrapping is any test or metric that uses random sampling with replacement, and falls under the broader class of resampling methods. Bootstrapping assigns measures of accuracy (bias, variance, confidence intervals, prediction error, etc.) to sample estimates.	What does bootstrapping mean in statistics	5743
3598	: a function (such as y = loga x or y = ln x) that is the inverse of an exponential function (such as y = ax or y = ex) so that the independent variable appears in a logarithm.	What is a logarithmic function definition	3598
10805	Constraint satisfaction problems (CSPs) are mathematical questions defined as a set of objects whose state must satisfy a number of constraints or limitations. CSPs represent the entities in a problem as a homogeneous collection of finite constraints over variables, which is solved by constraint satisfaction methods.	What do you mean by constraint satisfaction problem	10805
5658	A sampling error is a statistical error that occurs when an analyst does not select a sample that represents the entire population of data and the results found in the sample do not represent the results that would be obtained from the entire population.	What is mean by sampling error	5658
884	The simplest solution is to use other activation functions, such as ReLU, which doesn't cause a small derivative. Residual networks are another solution, as they provide residual connections straight to earlier layers.	How do you fix a vanishing gradient problem	884
8447	Fisher's exact test is a statistical test used to determine if there are nonrandom associations between two categorical variables. . For each one, calculate the associated conditional probability using (2), where the sum of these probabilities must be 1.	What is Fisher's exact test used for	8447
3670	: being or having the shape of a normal curve or a normal distribution.	What does Gaussian mean	3670
10830	A low R-squared value indicates that your independent variable is not explaining much in the variation of your dependent variable - regardless of the variable significance, this is letting you know that the identified independent variable, even though significant, is not accounting for much of the mean of your	What does a low R squared value mean	10830
747	A little bit of coding skills is enough, but it's better to have knowledge of data structures, algorithms, and OOPs concept. Some of the popular programming languages to learn machine learning in are Python, R, Java, and C++.	Is coding required in machine learning	747
6316	Natural Language processing is considered a difficult problem in computer science. It's the nature of the human language that makes NLP difficult.  While humans can easily master a language, the ambiguity and imprecise characteristics of the natural languages are what make NLP difficult for machines to implement.	Why is NLP difficult	6316
8878	A high-pass filter (HPF) is an electronic filter that passes signals with a frequency higher than a certain cutoff frequency and attenuates signals with frequencies lower than the cutoff frequency. The amount of attenuation for each frequency depends on the filter design.	How does a high pass RC filter work	8878
867	For example, a two-way ANOVA allows a company to compare worker productivity based on two independent variables, such as salary and skill set. It is utilized to observe the interaction between the two factors and tests the effect of two factors at the same time.	What is analysis of variance example	867
10696	Best practices – Machine Learning models and applicationsIdentify the business problem and the right success metrics.  Begin with it.  Gather correct data.  Move the algorithms instead of your data.  Initiate tests before the actual launch.  Avoid data dropping while machine learning algorithms train.  Keep away from objectives that are unaligned.  Keep using codes.More items•	What are some best practices for training machine learning models	10696
9918	Cosine similarity measures the similarity between two vectors of an inner product space. It is measured by the cosine of the angle between two vectors and determines whether two vectors are pointing in roughly the same direction. It is often used to measure document similarity in text analysis.	How do you find the similarity between two vectors	9918
1284	Train the model using a suitable machine learning algorithm such as SVM (Support Vector Machines), decision trees, random forest, etc. Training is the process through which the model learns or recognizes the patterns in the given data for making suitable predictions. The test set contains already predicted values.	Which machine learning technique is used for pattern recognition	1284
2275	The 2nd moment around the mean = Σ(xi – μx)2. The second is the variance. In practice, only the first two moments are ever used in statistics.	How do you find second moment in statistics	2275
8486	In statistics and research, internal consistency is typically a measure based on the correlations between different items on the same test (or the same subscale on a larger test). It measures whether several items that propose to measure the same general construct produce similar scores.	What is Internal Consistency in testing	8486
5078	Gravity tries to keep things together through attraction and thus tends to lower statistical entropy. The universal law of increasing entropy (2nd law of thermodynamics) states that the entropy of an isolated system which is not in equilibrium will tend to increase with time, approaching a maximum value at equilibrium.	How is gravity related to entropy	5078
452	Connectionism, an approach to artificial intelligence (AI) that developed out of attempts to understand how the human brain works at the neural level and, in particular, how people learn and remember.  (For that reason, this approach is sometimes referred to as neuronlike computing.)	What is connectionist AI	452
4276	An (ordinary) Poisson process is a special Markov process [ref. to Stadje in this volume], in continuous time, in which the only possible jumps are to the next higher state. A Poisson process may also be viewed as a counting process that has particular, desirable, properties.	Is Poisson process a Markov process	4276
6612	Clustering analysis is broadly used in many applications such as market research, pattern recognition, data analysis, and image processing. Clustering can also help marketers discover distinct groups in their customer base. And they can characterize their customer groups based on the purchasing patterns.	Where can cluster analysis be applied	6612
2247	The false alarm probability is the probability that exceeds a certain threshold when there is no signal.	What is probability of false alarm	2247
4510	Classification Accuracy It is the ratio of number of correct predictions to the total number of input samples. It works well only if there are equal number of samples belonging to each class. For example, consider that there are 98% samples of class A and 2% samples of class B in our training set.	How do you know if a classification model is accurate	4510
2553	In a supervised learning model, the algorithm learns on a labeled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data. An unsupervised model, in contrast, provides unlabeled data that the algorithm tries to make sense of by extracting features and patterns on its own.	What is the difference between supervised and unsupervised machine learning	2553
2514	Correlation is the concept of linear relationship between two variables.  Whereas correlation coefficient is a measure that measures linear relationship between two variables.	What is the difference between correlation and correlation coefficient	2514
2871	Decision tree builds regression or classification models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes.	How are decision trees used for regression	2871
6518	Increase the power of your analysis.larger sample size.better data collection (reducing error)better/correct model (more complex model, account for covariates, etc.)use a one-sided test instead of a two-sided test.	How do you decrease P value in regression	6518
10508	In many applications including econometrics and biostatistics a fixed effects model refers to a regression model in which the group means are fixed (non-random) as opposed to a random effects model in which the group means are a random sample from a population.	What are fixed effects in regression	10508
558	Specifical- ly, for periodic signals we can define the Fourier transform as an impulse train with the impulses occurring at integer multiples of the fundamental frequency and with amplitudes equal to 27r times the Fourier series coefficients.	What is the Fourier transform of a periodic signal	558
877	The crucial difference between FIR and IIR filter is that the FIR filter provides an impulse response of finite period. As against IIR is a type of filter that generates impulse response of infinite duration for a dynamic system.	What is difference between FIR and IIR filters	877
3482	Bivariate statistics is a type of inferential statistics that deals with the relationship between two variables.  When bivariate statistics is employed to examine a relationship between two variables, bivariate data is used. Bivariate data consists of data collected from a sample on two different variables.	What is bivariate in statistics	3482
7248	IAT is a popular measure in social psychology to measure the relative strength of association between pairs of concepts (Greenwald, McGhee, & Schwartz, 1998).  Studies have found that racial bias IAT studies have a test-retest reliability score of only 0.44, while the IAT overall is just around 0.5.	Is the Implicit Association Test having poor test retest reliability	7248
10613	Bimodal Distribution: Two Peaks. The bimodal distribution has two peaks.  However, if you think about it, the peaks in any distribution are the most common number(s). The two peaks in a bimodal distribution also represent two local maximums; these are points where the data points stop increasing and start decreasing.	How do you describe bimodal distribution	10613
374	The central limit theorem states that the sampling distribution of the mean approaches a normal distribution, as the sample size increases.  Therefore, as a sample size increases, the sample mean and standard deviation will be closer in value to the population mean μ and standard deviation σ .	What happens if the sample size increases	374
10537	5:1515:11Suggested clip · 109 secondsStatQuest: Linear Discriminant Analysis (LDA) clearly explained YouTubeStart of suggested clipEnd of suggested clip	How do you do linear discriminant analysis	10537
2444	1 Answer. Normalized discounted cumulative gain is one of the standard method of evaluating ranking algorithms. You will need to provide a score to each of the recommendations that you give. If your algorithm assigns a low (better) rank to a high scoring entity, your NDCG score will be higher, and vice versa.	How do you evaluate a rank algorithm	2444
6560	Linear Activation Function A linear activation function takes the form: A = cx. It takes the inputs, multiplied by the weights for each neuron, and creates an output signal proportional to the input. In one sense, a linear function is better than a step function because it allows multiple outputs, not just yes and no.	What is linear activation function in neural network	6560
3368	⏩ optimal policy: the best action to take at each state, for maximum rewards over time. To help our agent do this, we need two things: A way to determine the value of a state in MDP. An estimated value of an action taken at a particular state.	What is optimal policy in reinforcement learning	3368
6152	Classification is a machine learning concept. It is used for categorical dependent variables, where we need to classify into required groups. Logistic regression is a algorithm within classification.	What is the difference between logistic regression and classification	6152
2133	In the mathematical discipline of linear algebra, a matrix decomposition or matrix factorization is a factorization of a matrix into a product of matrices. There are many different matrix decompositions; each finds use among a particular class of problems.	Can you Factorise matrices	2133
5892	The histogram of oriented gradients (HOG) is a feature descriptor used in computer vision and image processing for the purpose of object detection. The technique counts occurrences of gradient orientation in localized portions of an image.	What is Histogram of Oriented Gradients and how does it work	5892
4239	The t‐distribution is used as an alternative to the normal distribution when sample sizes are small in order to estimate confidence or determine critical values that an observation is a given distance from the mean.	Why do we use t distribution	4239
5022	Mixed effects models are useful when we have data with more than one source of random variability. For example, an outcome may be measured more than once on the same person (repeated measures taken over time). When we do that we have to account for both within-person and across-person variability.	When would you use a mixed model	5022
1396	Inverted dropout is a variant of the original dropout technique developed by Hinton et al.  The one difference is that, during the training of a neural network, inverted dropout scales the activations by the inverse of the keep probability q=1−p q = 1 − p .	What is inverted dropout technique	1396
3222	Particle filters or Sequential Monte Carlo (SMC) methods are a set of Monte Carlo algorithms used to solve filtering problems arising in signal processing and Bayesian statistical inference.  Particle filters update their prediction in an approximate (statistical) manner.	What is a particle filter used for	3222
8363	Bias is the simplifying assumptions made by the model to make the target function easier to approximate. Variance is the amount that the estimate of the target function will change given different training data. Trade-off is tension between the error introduced by the bias and the variance.	What do you understand by bias variance trade off	8363
9839	Batch gradient descent is a variation of the gradient descent algorithm that calculates the error for each example in the training dataset, but only updates the model after all training examples have been evaluated. One cycle through the entire training dataset is called a training epoch.	How does batch gradient descent work	9839
8967	Linear filtering is the filtering method in which the value of output pixel is linear combinations of the neighbouring input pixels. it can be done with convolution. For examples, mean/average filters or Gaussian filtering. A non-linear filtering is one that cannot be done with convolution or Fourier multiplication.	What is difference between linear filtersand nonlinear filters	8967
2922	For linear algebra, it's very helpful to prepare by doing simple practice problems with the basic axioms of vector spaces and inner products. I was always mediocre at algebra, but good at visualizing 2D and 3D things.	How do you prepare linear algebra	2922
7841	Joint probability is calculated by multiplying the probability of event A, expressed as P(A), by the probability of event B, expressed as P(B). For example, suppose a statistician wishes to know the probability that the number five will occur twice when two dice are rolled at the same time.	How do you find joint probability	7841
9046	Variance (σ2) in statistics is a measurement of the spread between numbers in a data set. That is, it measures how far each number in the set is from the mean and therefore from every other number in the set.	What is the meaning of variance	9046
9685	3.1. Coreference resolution (or anaphora) is an expression, the interpretation of which depends on another word or phrase presented earlier in the text (antecedent). For example, “Tom has a backache. He was injured.” Here the words “Tom” and “He” refer to the same entity.	How do coreference resolution anaphora resolution algorithms work	9685
9569	Multinomial logistic regression is used to predict categorical placement in or the probability of category membership on a dependent variable based on multiple independent variables. The independent variables can be either dichotomous (i.e., binary) or continuous (i.e., interval or ratio in scale).	What is meant by multinomial logistic regression	9569
1431	Marginal probability: the probability of an event occurring (p(A)), it may be thought of as an unconditional probability. It is not conditioned on another event. Example: the probability that a card drawn is red (p(red) = 0.5).	What is marginal probability in statistics	1431
95	DBSCAN works as such: Divides the dataset into n dimensions. For each point in the dataset, DBSCAN forms an n dimensional shape around that data point, and then counts how many data points fall within that shape. DBSCAN counts this shape as a cluster.	How does Dbscan algorithm work	95
4124	The general procedure for using regression to make good predictions is the following:Research the subject-area so you can build on the work of others.  Collect data for the relevant variables.Specify and assess your regression model.If you have a model that adequately fits the data, use it to make predictions.	How do you predict regression	4124
7932	Q-Learning is a value-based reinforcement learning algorithm which is used to find the optimal action-selection policy using a Q function. Our goal is to maximize the value function Q. The Q table helps us to find the best action for each state.  Initially we explore the environment and update the Q-Table.	What is Q function explain Q learning with suitable example	7932
3694	"A decision tree is a simple representation for classifying examples. For this section, assume that all of the input features have finite discrete domains, and there is a single target feature called the ""classification"". Each element of the domain of the classification is called a class."	What is a class in decision tree learning	3694
7790	A qualitative variable, also called a categorical variable, is a variable that isn't numerical. It describes data that fits into categories. For example: Eye colors (variables include: blue, green, brown, hazel).	Is colour a qualitative variable	7790
968	One-vs-rest (OvR for short, also referred to as One-vs-All or OvA) is a heuristic method for using binary classification algorithms for multi-class classification. It involves splitting the multi-class dataset into multiple binary classification problems.	What is one vs all classification in machine learning	968
3483	Any sum or difference or independent normal random variables is also normally distributed. A binomial setting arises when we perform several independent trials of the same chance process and record the number of times a particular outcome occurs.	What happens if two independent normal random variables are combined	3483
2181	Cluster sampling refers to a type of sampling method . With cluster sampling, the researcher divides the population into separate groups, called clusters. Then, a simple random sample of clusters is selected from the population. The researcher conducts his analysis on data from the sampled clusters.	How does cluster sampling work	2181
8400	According to the realistic conflict theory, ingroup bias arises from competition for resources between groups. Since different groups are all competing for the same available resources, it serves the best interests of the group to favor members while spurning outsiders.	Why does ingroup bias occur	8400
1787	The cosine similarity is the cosine of the angle between two vectors. Figure 1 shows three 3-dimensional vectors and the angles between each pair. In text analysis, each vector can represent a document. The greater the value of θ, the less the value of cos θ, thus the less the similarity between two documents.	How do you find the cosine similarity between two documents	1787
8604	Another view however is that the parameter value used to generate the data that are obtained in your study is just one drawn parameter value, where the draw is from some distribution (the prior).  as parameters, but rather as random or latent effects.	Are parameters random	8604
2579	So here are some signs you're highly intelligent, even if you don't feel like it.You're Empathetic And Compassionate. Andrew Zaeh for Bustle.  You're Curious About The World.  You're Observant.  You Have Self-Control.  You Have A Good Working Memory.  You Like To Go With The Flow.More items•	How can you tell if someone is highly intelligent	2579
9976	In convolutional networks, multiple filters are taken to slice through the image and map them one by one and learn different portions of an input image. Imagine a small filter sliding left to right across the image from top to bottom and that moving filter is looking for, say, a dark edge.	What are convolutional filters	9976
226	Covariance is calculated by analyzing at-return surprises (standard deviations from the expected return) or by multiplying the correlation between the two variables by the standard deviation of each variable.	How do you find the covariance between two variables	226
9322	Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Supervised learning allows you to collect data or produce a data output from the previous experience. Unsupervised machine learning helps you to finds all kind of unknown patterns in data.	Is Machine Learning supervised or unsupervised	9322
10419	You can use tf. function to make graphs out of your programs. It is a transformation tool that creates Python-independent dataflow graphs out of your Python code. This will help you create performant and portable models, and it is required to use SavedModel .  function works under the hood so you can use it effectively.	What is TF function	10419
7267	Frequency distribution in statistics is a representation that displays the number of observations within a given interval. The representation of a frequency distribution can be graphical or tabular so that it is easier to understand.	What is a frequency distribution in statistics	7267
4331	Feature Extraction using Convolution Neural Networks (CNN) and Deep Learning.  It is a process which involves the following tasks of pre-processing the image (normalization), image segmentation, extraction of key features and identification of the class.	What is feature extraction in CNN	4331
9286	Sometimes we want to know the probability of getting one result or another. When events are mutually exclusive and we want to know the probability of getting one event OR another, then we can use the OR rule.  P(A or B) = P(A) + P(B) for mutually exclusive events.	What is the OR rule in probability	9286
3631	K nearest neighbors is a simple algorithm that stores all available cases and predict the numerical target based on a similarity measure (e.g., distance functions). KNN has been used in statistical estimation and pattern recognition already in the beginning of 1970's as a non-parametric technique.	Can Knn be used for prediction	3631
9958	First, logistic regression does not require a linear relationship between the dependent and independent variables. Second, the error terms (residuals) do not need to be normally distributed.  This means that the independent variables should not be too highly correlated with each other.	Should independent variables be normally distributed for ordered logit model	9958
2963	The pdf represents the relative frequency of failure times as a function of time. The cdf is a function, F(x)\,\!, of a random variable X\,\!, and is defined for a number x\,\!	What is the relationship between PDF and CDF	2963
8033	"In regression analysis, the dependent variable is denoted ""Y"" and the independent variables are denoted by ""X""."	How do you identify independent and dependent variables in regression analysis	8033
4374	11 websites to find free, interesting datasetsFiveThirtyEight.  BuzzFeed News.  Kaggle.  Socrata.  Awesome-Public-Datasets on Github.  Google Public Datasets.  UCI Machine Learning Repository.  Data.gov.More items	How do I find datasets	4374
10175	Random error varies unpredictably from one measurement to another, while systematic error has the same value or proportion for every measurement. Random errors are unavoidable, but cluster around the true value.	What is the difference between random errors and non random errors in experimental data	10175
1957	In mathematics, a generating function is a way of encoding an infinite sequence of numbers (an) by treating them as the coefficients of a formal power series.  Generating functions are often expressed in closed form (rather than as a series), by some expression involving operations defined for formal series.	What is meant by generating function	1957
8308	The F-distribution is a skewed distribution of probabilities similar to a chi-squared distribution. But where the chi-squared distribution deals with the degree of freedom with one set of variables, the F-distribution deals with multiple levels of events having different degrees of freedom.	What is af distribution	8308
1094	10:1614:33Suggested clip · 106 secondsPermutation Hypothesis Test in R with Examples | R Tutorial 4.6 YouTubeStart of suggested clipEnd of suggested clip	How do you do permutation test in R	1094
168	Real numbers consist of zero (0), the positive and negative integers (-3, -1, 2, 4), and all the fractional and decimal values in between (0.4, 3.1415927, 1/2). Real numbers are divided into rational and irrational numbers.	Is 0 a real number	168
4457	XGboost is the most widely used algorithm in machine learning, whether the problem is a classification or a regression problem. It is known for its good performance as compared to all other machine learning algorithms.	Is XGBoost good for regression	4457
